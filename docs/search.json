[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Kailyn Hogan is from Delhi, Iowa, and is a senior at Iowa State University majoring in Community and Regional Planning with a minor in Geographic Information Systems. She is also Vice President of the undergraduate Community and Regional Planning Club at Iowa State. Kailyn believes combining data science and urban planning is vital in today’s data-driven world. After college, Kailyn hopes to join the Peace Corps to continue aiding communities and diversifying her cultural education.\nThis blog outlines her time and experience in the Data Science for the Public Good program through Iowa State University Extension and Outreach. During DSPG, she was a part of the housing group charged with creating an AI Model to objectively assess housing values in rural communities."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Kailyn Hogan’s DSPG Blog",
    "section": "",
    "text": "Guide: Performing a Demographic Analysis\n\n\nLast week!\n\n\n\n\nWeek Nine\n\n\nGuide\n\n\nR\n\n\nTableau\n\n\nDemographic Analysis\n\n\n\n\n\n\n\n\n\n\n\nJul 12, 2023\n\n\nKailyn Hogan\n\n\n\n\n\n\n  \n\n\n\n\nGuide: Creating a Demographic Profile\n\n\nLast Week!\n\n\n\n\nWeek Nine\n\n\nGuide\n\n\nR\n\n\nDemographic Profile\n\n\n\n\n\n\n\n\n\n\n\nJul 12, 2023\n\n\nKailyn Hogan\n\n\n\n\n\n\n  \n\n\n\n\nGuide: API Variable Codes\n\n\n\n\n\n\n\nWeek Nine\n\n\nGuide\n\n\nR\n\n\nDemographic Analysis\n\n\n\n\n\n\n\n\n\n\n\nJul 12, 2023\n\n\nKailyn Hogan\n\n\n\n\n\n\n  \n\n\n\n\nWeek Eight of Data Science for the Public Good\n\n\nIt is hustle time!\n\n\n\n\nWeek Eight\n\n\nR\n\n\nDemographic Analysis\n\n\nDemographic Profile\n\n\n\n\n\n\n\n\n\n\n\nJul 7, 2023\n\n\nKailyn Hogan\n\n\n\n\n\n\n  \n\n\n\n\nTeam Blog: Week Seven\n\n\nFinal Presentation Outline\n\n\n\n\nWeek Seven\n\n\nTeam Blog\n\n\n\n\n\n\n\n\n\n\n\nJun 30, 2023\n\n\nKailyn Hogan\n\n\n\n\n\n\n  \n\n\n\n\nWeek Seven of Data Science for the Public Good\n\n\nDemographic Analysis Time\n\n\n\n\nWeek Seven\n\n\nR\n\n\nDemographic Analysis\n\n\n\n\n\n\n\n\n\n\n\nJun 30, 2023\n\n\nKailyn Hogan\n\n\n\n\n\n\n  \n\n\n\n\nWeek Six of Data Science for the Public Good\n\n\nCreating a Demographic Profile\n\n\n\n\nWeek Six\n\n\nR\n\n\nDemographic Analysis\n\n\nWINVEST\n\n\n\n\n\n\n\n\n\n\n\nJun 23, 2023\n\n\nKailyn Hogan\n\n\n\n\n\n\n  \n\n\n\n\nWeek Five of Data Science for the Public Good\n\n\n\n\n\n\n\nWeek Five\n\n\nITAG Conference\n\n\nArcGIS\n\n\nDemographic Analysis\n\n\nAI Models\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nJun 16, 2023\n\n\nKailyn Hogan\n\n\n\n\n\n\n  \n\n\n\n\nTeam Blog: Week Four\n\n\n\n\n\n\n\nWeek Four\n\n\n\n\n\n\n\n\n\n\n\nJun 9, 2023\n\n\nKailyn Hogan\n\n\n\n\n\n\n  \n\n\n\n\nWeek Four of Data Science for the Public Good\n\n\nGathering addresses and images for our AI Models!\n\n\n\n\nWeek Four\n\n\nExcel\n\n\nWeb Scraping\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nJun 9, 2023\n\n\nKailyn Hogan\n\n\n\n\n\n\n  \n\n\n\n\nWeek Three of Data Science for the Public Good\n\n\nI gave a Morning Coffee Talk!\n\n\n\n\nWeek Three\n\n\nAI Models\n\n\nDataCamp\n\n\n\n\n\n\n\n\n\n\n\nJun 2, 2023\n\n\nKailyn Hogan\n\n\n\n\n\n\n  \n\n\n\n\nWeek Two of Data Science for the Public Good\n\n\nRelearning TidyCensus in Vegas!\n\n\n\n\nWeek Two\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nMay 26, 2023\n\n\nKailyn Hogan\n\n\n\n\n\n\n  \n\n\n\n\nWeek One of Data Science for the Public Good\n\n\nDataCamp! DataCamp! DataCamp!\n\n\n\n\nWeek One\n\n\nDataCamp\n\n\n\n\n\n\n\n\n\n\n\nMay 19, 2023\n\n\nKailyn Hogan\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Team_Blog_Week4/Team Blog.html#project-overview",
    "href": "posts/Team_Blog_Week4/Team Blog.html#project-overview",
    "title": "Team Blog: Week Four",
    "section": "Project Overview",
    "text": "Project Overview\nThis is the project plan we came up with the first week of DSPG. This project is intended to span over three years with DPSG, and different interns will be working on it in the coming years. Thus, the project plan is ambitious for this summer."
  },
  {
    "objectID": "posts/Team_Blog_Week4/Team Blog.html#problem-statement",
    "href": "posts/Team_Blog_Week4/Team Blog.html#problem-statement",
    "title": "Team Blog: Week Four",
    "section": "Problem Statement",
    "text": "Problem Statement\nThe absence of a comprehensive and unbiased assessment of housing quality in rural communities poses challenges in identifying financing gaps and effectively allocating resources for housing improvement. Consequently, this hinders the overall well-being and health of residents, impacts workforce stability, diminishes rural vitality, and undermines the economic growth of Iowa. Moreover, the subjective nature of evaluating existing housing conditions and the limited availability of resources for thorough investigations further compound the problem. To address these challenges, there is a pressing need for an AI-driven approach that can provide a more accurate and objective evaluation of housing quality, identify financing gaps, and optimize the allocation of local, state, and federal funds to maximize community benefits.\nUtilizing web scraping techniques to collect images of houses from various assessor websites, an AI model can be developed to analyze and categorize housing features into good or poor quality. This can enable targeted investment strategies. It allows for the identification of houses in need of improvement and determines the areas where financial resources should be directed. By leveraging AI technology in this manner, the project seeks to streamline the housing evaluation process, eliminate subjective biases, and facilitate informed decision-making for housing investment and development initiatives in rural communities"
  },
  {
    "objectID": "posts/Team_Blog_Week4/Team Blog.html#goals-and-objectives",
    "href": "posts/Team_Blog_Week4/Team Blog.html#goals-and-objectives",
    "title": "Team Blog: Week Four",
    "section": "Goals and Objectives",
    "text": "Goals and Objectives\n\nImage Gathering\n\nZillow\nRealtors.com\nCounty Assessor Pages\n\nVangaurd: Independence\nBeacon Schneider: Slater, New Hampton, and Grundy Center\n\n\nBuild, Train, and Test AI Models\n\nVegetation Model\nSiding Model\nGutter Model\n\nCreate Database of Housing Information\n\nZillow\nRealtors.com\nCounty Assessor Pages\n\nVanguard: Independence\nBeacon Schneider: Slater, New Hampton, and Grundy Center"
  },
  {
    "objectID": "posts/Team_Blog_Week4/Team Blog.html#our-progress",
    "href": "posts/Team_Blog_Week4/Team Blog.html#our-progress",
    "title": "Team Blog: Week Four",
    "section": "Our Progress",
    "text": "Our Progress\nWe have been making good progress to complete the goals and objectives we outlined above. Since the beginning of the Data Science for the Public Good Program, we have been expanding our knowledge of data science, particularly in areas that relate to this housing project. We have been learning and covering new concepts through Data Camp. We have also watched two webinars on TidyCensus training, as well as started creating AI Models to practice with.\n\nData Camp Training:\n\nGitHub Concepts\nAI Fundamentals\nIntroduction to R\nIntermediate R\nIntroduction to the Tidyverse\nWeb Scraping in R\nIntroduction to Deep Learning with Keras\n\n\n\nTidyCensus Demographic Data Collection:\nOne of the first steps in our project was to explore the available demographic data in our selected cities and counties. We thought it valuable to understand the demographic data, and we have represented in the plots below:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreating Test AI Models:\nThe next step was creating an AI Model. We decided to create an AI Model early in the project before finishing the housing data collection so that we had a better understanding when it came to putting everything together. The AI Model below tests for vegetation in front of houses.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis Week:\n\nIn-Person Data Collection\nOn Tuesday this week, the entire DSPG program went to Slater to practice data collection in person. The housing group took this as an opportunity to collect some housing photos on the ground to use in our AI Model later on.\n\n\nGoogle Street View and URLs\nWe are getting the majority of our photos for the AI to use from Google Street View. Google has an API key that you can use to generate an image for a specific address. We spent the first half of this week pulling addresses from each of our cities and creating URLs to pull the images from Google Street View.\nWe ran into a couple of problems when doing this, the biggest of which is displayed in the images below. Because we are working with cities in rural areas, there is not Google Street View images available for every street in our cities.\n\n\n\nGoogle Street View information for Grundy Center, Iowa. For reference, population was 2,811 as of 2023.\n\n\n\n\n\nGoogle Street View information for Slater, Iowa. For reference, population was 1,639 as of 2023.\n\n\n\n\n\nGoogle Street View information for Independence, Iowa. For reference, population was 6,307 as of 2023.\n\n\n\n\n\nGoogle Street View information for New Hampton, Iowa. For reference, population was 3,368 as of 2023.\n\n\nBelow is a sample from the tables we created containing the URLs to grab the images from Google Street View.\n\n\n\n\nWeb Scraping\nOnce we were finished collecting addresses and generating URLs, we moved on to scraping the web for more images. We decided to grab images from Zillow, Realtors.com, and the County Assessor pages for our cities. We were able to successfully scrape images from Zillow this week.\n\n\n\n\n\n\n\n\n\n\nWhen web scraping, we ran into a problem with blurred houses. Upon some research, we found out that some home owners pay Google to have their home blurred for Google Street View.\n\n\n\n\n\nThe next websites we are scraping hold the Iowa Assessors housing data for our four cities. We found a webpage that has links to every counties assessor website. The key at the bottom shows where the data is held. Yellow means the data is held by Vanguard. Blue means the data is online. For most of Iowa’s counties, this means that it is held by Beacon Schneider.\n\n\n\n\n\n\n\n\nWeb Scraping Issues\nIndependence had issues where the house number was listed as 100/101 and also had 100 1/2. Thankfully the function to grab the Google images ran all the way but said there were 50 errors including both addresses with two house numbers and with half signs. If you remove one of the address numbers or remove the 1/2 (basically removing the / sign) the image url still brings you to a Google image. We could possibly go back through and grab these URL’s and alter them to try and grab these addresses if necessary.\n\nHappies\n\nhad a great meeting with Erin Olson-Douglas\nfinished collecting and creating URL addresses for Google Street View images\nZillow owns Trulia so we don’t have to web scrape both sites :)\nable to successfully scrape some things from Zillow !\n\n\n\nCrappies\n\nWeb Scraping\nBeacon and Vanguard have anti-web scraping protections\nAngelina’s Excel is stupid"
  },
  {
    "objectID": "posts/Team_Blog_Week4/Team Blog.html#future-plans-and-next-steps",
    "href": "posts/Team_Blog_Week4/Team Blog.html#future-plans-and-next-steps",
    "title": "Team Blog: Week Four",
    "section": "Future Plans and Next Steps",
    "text": "Future Plans and Next Steps\nOnce we are able to scrape enough images off of Zillow, Realtors.com, and the assessor pages, we will be able to move on with creating AI Models. The diagram below outlines how the AI Models will work in the next steps of out project."
  },
  {
    "objectID": "posts/Week 6/Week_6.html",
    "href": "posts/Week 6/Week_6.html",
    "title": "Week Six of Data Science for the Public Good",
    "section": "",
    "text": "On Monday and Tuesday of this week, we traveled to Grundy Center, New Hampton and Independence to do some WINVEST work. Our task was to conduct neighborhood scoring of the communities. I learned on Tuesday that the purpose of our scoring was to get the communities a grant for neighborhood funding. These three communities had all applied to a Housing and Urban Development (HUD) grant, and it was our job to gather evidence of need for each community. Based on the sections of the community that I evaluated, I think Independence should receive the grant.\nWe evaluated the following characteristics of the houses based on a good, fair, poor scale:\n\nhouse condition\nlot condition\nsidewalk\ngutters\nroof\nsiding\nlandscape\n\nWe also wanted to know if there was junk present on the lot, if the image of the house was obstructed, and what was causing the obstruction, if any.\nBelow are some images I took of particularly low quality houses that I thought our AI Models would benefit to train on.\n\n\n\nPoor roof, poor gutter, and fine siding.\n\n\n\n\n\nFine roof, poor siding, and fine landscape.\n\n\n\n\n\nThere are plants growing out of this gutter."
  },
  {
    "objectID": "posts/Week 6/Week_6.html#monday-and-tuesday",
    "href": "posts/Week 6/Week_6.html#monday-and-tuesday",
    "title": "Week Six of Data Science for the Public Good",
    "section": "",
    "text": "On Monday and Tuesday of this week, we traveled to Grundy Center, New Hampton and Independence to do some WINVEST work. Our task was to conduct neighborhood scoring of the communities. I learned on Tuesday that the purpose of our scoring was to get the communities a grant for neighborhood funding. These three communities had all applied to a Housing and Urban Development (HUD) grant, and it was our job to gather evidence of need for each community. Based on the sections of the community that I evaluated, I think Independence should receive the grant.\nWe evaluated the following characteristics of the houses based on a good, fair, poor scale:\n\nhouse condition\nlot condition\nsidewalk\ngutters\nroof\nsiding\nlandscape\n\nWe also wanted to know if there was junk present on the lot, if the image of the house was obstructed, and what was causing the obstruction, if any.\nBelow are some images I took of particularly low quality houses that I thought our AI Models would benefit to train on.\n\n\n\nPoor roof, poor gutter, and fine siding.\n\n\n\n\n\nFine roof, poor siding, and fine landscape.\n\n\n\n\n\nThere are plants growing out of this gutter."
  },
  {
    "objectID": "posts/Week 6/Week_6.html#wednesday",
    "href": "posts/Week 6/Week_6.html#wednesday",
    "title": "Week Six of Data Science for the Public Good",
    "section": "Wednesday",
    "text": "Wednesday\nOn Wednesday, I started the demographic profile of Grundy Center, New Hampton and Independence. Morenike, my project leader had requested them, so she could put them in our final report.\nI looked at the following characteristics of the communities:\n\nHome ownership rate\nPopulation\nMedian income\nAge of houses\nHouse value\n\nI used 5-Year ACS estimates for all of my plots. The ACS gives more detailed information on demographics of communities. I chose 5-Year over 1-Year estimates because 1-Year estimates are not available for communities under 65,000 in population. 5-Year estimates are also more accurate.\nI was able to finish the population plots on Wednesday. I first looked at the total population of each community.\n\n\n\n\n\nThen I was interested in the percent change in population each community had experienced since 1990. Unfortunately, 1990 Census data has been pulled from TidyCensus. There is a way to access it, but that is not something I had time to explore.\nI would like to go back and change this plot so that the 0.0% change for 2000 is not visible.\n\n\n\n\n\nFinally, I calculated a population projection for 2030 using the AAAC method. AAAC stands for average annual absolute change.\n\nAAAC = (population 1 - population 2) / time\nPopulation projection = population + (time * AAAC)"
  },
  {
    "objectID": "posts/Week 6/Week_6.html#thursday",
    "href": "posts/Week 6/Week_6.html#thursday",
    "title": "Week Six of Data Science for the Public Good",
    "section": "Thursday",
    "text": "Thursday\nOn Thursday, I finished the plots for income and housing value.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nI spent some time Thursday afternoon searching the US Census website for API codes.\nLink to 2021 5-Year ACS API codes: https://api.census.gov/data/2021/acs/acs5/variables.html\nYear Structure Built variables\n\n\n\nVariable Name\nAPI Code\n\n\n\n\nTotal\nB25034_001\n\n\n2020 or later\nB25034_002\n\n\n2010-2019\nB25034_003\n\n\n2000-2009\nB25034_004\n\n\n1990-1999\nB25034_005\n\n\n1980-1989\nB25034_006\n\n\n1970-1979\nB25034_007\n\n\n1960-1969\nB25034_008\n\n\n1950-1959\nB25034_009\n\n\n1940-1949\nB25034_010\n\n\n1939 or earlier\nB25034_011\n\n\nMedian structure age\nB25035_001\n\n\n\nNumber of Bedrooms = B25041_001 through B25041_007\nMedian House Value by Year Structure Built = B25107_001 through B25107_011\nTotal Housing Units = B25002_001\nOccupied Housing Units = B25002_002\nVacant Housing Units = B25002_003\nVacancy Status\n\n\n\nVariable Name\nAPI Code\n\n\n\n\nFor rent\nB25004_002\n\n\nRented, not occupied\nB25004_003\n\n\nFor sale\nB25004_004\n\n\nSold, not occupied\nB25004_005\n\n\nSeasonal\nB25004_006\n\n\nMigrant workers\nB25004_007\n\n\nOther\nB25004_008"
  },
  {
    "objectID": "posts/Week 6/Week_6.html#friday",
    "href": "posts/Week 6/Week_6.html#friday",
    "title": "Week Six of Data Science for the Public Good",
    "section": "Friday",
    "text": "Friday\nOn Friday, I finished the rest of the plots for the demographic profile.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n** insert year built plots **\n\n\n\n\n\n\n\n\n\n\nAfter our Friday meeting, I got some notes from Chris and other members of DSPG on my plots. They suggested I change some of my plots to display percentages instead of counts. This change will give a more accurate representation of the data.\nI will be making these changes next week, and I will be starting the demographic analysis to determine which communities in Iowa could benefit from our project."
  },
  {
    "objectID": "posts/Week_1/Week_1.html",
    "href": "posts/Week_1/Week_1.html",
    "title": "Week One of Data Science for the Public Good",
    "section": "",
    "text": "The priority for week one of Data Science for the Public Good was DataCamp training. I completed the following list of DataCamp courses this week."
  },
  {
    "objectID": "posts/Week_1/Week_1.html#datacamp-trainings",
    "href": "posts/Week_1/Week_1.html#datacamp-trainings",
    "title": "Week One of Data Science for the Public Good",
    "section": "DataCamp Trainings",
    "text": "DataCamp Trainings\n\nAI Fundamentals\nGitHub Concepts\nR Programming Assessment\nUnderstanding and Interpreting Data Assessment\nIntroduction to R\nIntroduction to the Tidyverse"
  },
  {
    "objectID": "posts/Week_2/Week_2.html",
    "href": "posts/Week_2/Week_2.html",
    "title": "Week Two",
    "section": "",
    "text": "This week we were introduced to the TidyCensus package via the 2023 webinar series Analyzing 2017-2021 ACS Data in R and Python by Kyle Walker, Associate Professor at Texas Christian University and R developer.\nWe watched the first two videos in the webinar series: Working with the 2021 American Community Survey with R and Tidycensus and Mapping and spatial analysis with ACS data in R.\nI created the following plots using the information I learned from the webinars and previous knowledge:\n\nlibrary(tidycensus)\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.1.3\n\n\nWarning: package 'ggplot2' was built under R version 4.1.3\n\n\nWarning: package 'tibble' was built under R version 4.1.3\n\n\nWarning: package 'tidyr' was built under R version 4.1.3\n\n\nWarning: package 'readr' was built under R version 4.1.3\n\n\nWarning: package 'purrr' was built under R version 4.1.3\n\n\nWarning: package 'dplyr' was built under R version 4.1.3\n\n\nWarning: package 'stringr' was built under R version 4.1.3\n\n\nWarning: package 'forcats' was built under R version 4.1.3\n\n\nWarning: package 'lubridate' was built under R version 4.1.3\n\n\n-- Attaching core tidyverse packages ------------------------ tidyverse 2.0.0 --\nv dplyr     1.1.2     v readr     2.1.4\nv forcats   1.0.0     v stringr   1.5.0\nv ggplot2   3.4.2     v tibble    3.2.1\nv lubridate 1.9.2     v tidyr     1.3.0\nv purrr     1.0.1     \n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\ni Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(ggthemes)\nlibrary(scales)\n\nWarning: package 'scales' was built under R version 4.1.3\n\n\n\nAttaching package: 'scales'\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\n\n\n##ONWER VS. RENTER OCCUPIED FOR EACH CITY\nown_iowa &lt;- get_decennial(geography = \"place\",\n                          state = \"IA\",\n                          year = 2010,\n                          output = \"wide\",\n                          variable = c(\"H017003\",\"H017004\",\"H017005\",\"H017006\",\"H017007\",\"H017008\",\"H017009\",\"H017010\",\"H017011\")) %&gt;% \n  mutate(tenure = \"Owner\") %&gt;% \n  rename(fifteentotwentyfour = H017003, twentyfivetothirtyfour = H017004, thirtyfivetofourtyfour = H017005, fourtyfivetofiftyfour = H017006, fiftyfivetofiftynine = H017007, sixtytosixtyfour = H017008, sixtyfivetoseventyfour = H017009, seventyfivetoeightyfour = H017010, overeightyfive = H017011)\n\nGetting data from the 2010 decennial Census\n\n\nUsing Census Summary File 1\n\n## Getting data from the 2010 decennial Census\n## Using Census Summary File 1\nrent_iowa &lt;- get_decennial(geography = \"place\",\n                           state = \"IA\",\n                           year = 2010,\n                           output = \"wide\",\n                           variable = c(\"H017013\",\"H017014\", \"H017015\", \"H017016\", \"H017017\",\"H017018\",\"H017019\", \"H017020\",\"H017021\")) %&gt;% \n  mutate(tenure = \"Renter\") %&gt;% \n  rename(fifteentotwentyfour = H017013, twentyfivetothirtyfour = H017014, thirtyfivetofourtyfour = H017015, fourtyfivetofiftyfour = H017016, fiftyfivetofiftynine = H017017, sixtytosixtyfour = H017018, sixtyfivetoseventyfour = H017019, seventyfivetoeightyfour = H017020, overeightyfive = H017021)\n\nGetting data from the 2010 decennial Census\nUsing Census Summary File 1\n\n## Getting data from the 2010 decennial Census\n## Using Census Summary File 1\niowa &lt;- rent_iowa %&gt;% \n  bind_rows(own_iowa)%&gt;% \n  pivot_longer(-c(NAME, GEOID, tenure),\n               names_to = \"agegroups\",\n               values_to = \"count\")\n\n###plots for grundy, independence and new hampton for age break downs by housing tenure\niowa %&gt;% \n  filter(NAME == \"New Hampton city, Iowa\") %&gt;% \n  mutate(agegroups = fct_relevel(agegroups, c(\"fifteentotwentyfour\", \"twentyfivetothirtyfour\",\"thirtyfivetofourtyfour\",\"fourtyfivetofiftyfour\",\"fiftyfivetofiftynine\",\"sixtytosixtyfour\",\"sixtyfivetoseventyfour\",\"seventyfivetoeightyfour\",\"overeightyfive\"))) %&gt;% \n  ggplot(aes(x = agegroups, y = if_else(tenure == \"Renter\", count, -count))) +\n  geom_bar(aes(fill = tenure), stat = \"identity\") +\n  geom_text(aes(x = agegroups, y = if_else(tenure == \"Renter\", count +10, -count - 12), label = scales::comma(count))) +\n  coord_flip()+\n  scale_x_discrete(labels = c(\"15 to 24\", \"25 to 34\", \"35 to 44\", \"45 to 54\", \"55 to 59\", \"60 to 64\", \"65 to 74\", \"75 to 84\", \"85 and Older\")) +\n  scale_y_continuous(label = abs)+\n  labs(x = \"\",\n       y = \"Population\",\n       fill = \"\",\n       title = \"Population in New Hampton, IA \\nby Age and Tenure\",\n       subtitle = \"2010 Decennial Census\") +\n  theme_fivethirtyeight()+\n  theme(legend.position = \"bottom\") +\n  scale_fill_wsj()\n\n\n\niowa %&gt;% \n  filter(NAME == \"Grundy Center city, Iowa\") %&gt;% \n  mutate(agegroups = fct_relevel(agegroups, c(\"fifteentotwentyfour\", \"twentyfivetothirtyfour\",\"thirtyfivetofourtyfour\",\"fourtyfivetofiftyfour\",\"fiftyfivetofiftynine\",\"sixtytosixtyfour\",\"sixtyfivetoseventyfour\",\"seventyfivetoeightyfour\",\"overeightyfive\"))) %&gt;% \n  ggplot(aes(x = agegroups, y = if_else(tenure == \"Renter\", count, -count))) +\n  geom_bar(aes(fill = tenure), stat = \"identity\") +\n  geom_text(aes(x = agegroups, y = if_else(tenure == \"Renter\", count +5, -count - 8), label = scales::comma(count))) +\n  coord_flip()+\n  scale_x_discrete(labels = c(\"15 to 24\", \"25 to 34\", \"35 to 44\", \"45 to 54\", \"55 to 59\", \"60 to 64\", \"65 to 74\", \"75 to 84\", \"85 and Older\")) +\n  scale_y_continuous(label = abs)+\n  labs(x = \"\",\n       y = \"Population\",\n       fill = \"\",\n       title = \"Population in Grundy Center, IA \\nby Age and Tenure\",\n       subtitle = \"2010 Decennial Census\") +\n  theme_fivethirtyeight()+\n  theme(legend.position = \"bottom\") +\n  scale_fill_wsj()\n\n\n\niowa %&gt;% \n  filter(NAME == \"Independence city, Iowa\") %&gt;% \n  mutate(agegroups = fct_relevel(agegroups, c(\"fifteentotwentyfour\", \"twentyfivetothirtyfour\",\"thirtyfivetofourtyfour\",\"fourtyfivetofiftyfour\",\"fiftyfivetofiftynine\",\"sixtytosixtyfour\",\"sixtyfivetoseventyfour\",\"seventyfivetoeightyfour\",\"overeightyfive\"))) %&gt;% \n  ggplot(aes(x = agegroups, y = if_else(tenure == \"Renter\", count, -count))) +\n  geom_bar(aes(fill = tenure), stat = \"identity\") +\n  geom_text(aes(x = agegroups, y = if_else(tenure == \"Renter\", count +12, -count - 15), label = scales::comma(count))) +\n  coord_flip()+\n  scale_x_discrete(labels = c(\"15 to 24\", \"25 to 34\", \"35 to 44\", \"45 to 54\", \"55 to 59\", \"60 to 64\", \"65 to 74\", \"75 to 84\", \"85 and Older\")) +\n  scale_y_continuous(label = abs)+\n  labs(x = \"\",\n       y = \"Population\",\n       fill = \"\",\n       title = \"Population in Independence, IA by \\nAge and Tenure\",\n       subtitle = \"2010 Decennial Census\") +\n  theme_fivethirtyeight()+\n  theme(legend.position = \"bottom\") +\n  scale_fill_wsj()\n\n\n\n\n\n##MEDIAN AGE\n\nmedage &lt;- c(\"medage\" = \"B01002_001\")\n\ngrundy &lt;- get_acs(geography = \"place\",\n              state = \"IA\",\n              variable = medage,\n              year = 2021,\n              output = \"tidy\") %&gt;% \n  filter(NAME == \"Grundy Center city, Iowa\") %&gt;% \n  mutate(year = 2021) \n\nGetting data from the 2017-2021 5-year ACS\n\n## Getting data from the 2016-2020 5-year ACS\ninde &lt;- get_acs(geography = \"place\",\n                state = \"IA\",\n                variable = medage,\n                year = 2021,\n                output = \"tidy\") %&gt;% \n  filter(NAME == \"Independence city, Iowa\") %&gt;% \n  mutate(year = 2021)\n\nGetting data from the 2017-2021 5-year ACS\n\nnew &lt;- get_acs(geography = \"place\",\n                state = \"IA\",\n                variable = medage,\n                year = 2021,\n                output = \"tidy\") %&gt;% \n  filter(NAME == \"New Hampton city, Iowa\") %&gt;% \n  mutate(year = 2021)\n\nGetting data from the 2017-2021 5-year ACS\n\n## Getting data from the 2016-2020 5-year ACS\nia &lt;- get_acs(geography = \"state\",\n              state = \"IA\",\n              variable = medage,\n              year = 2021,\n              output = \"tidy\") %&gt;% \n  mutate(year = 2021)\n\nGetting data from the 2017-2021 5-year ACS\n\n## Getting data from the 2016-2020 5-year ACS\nmedage16_20 &lt;- grundy %&gt;% \n  bind_rows(ia,inde, new) %&gt;% \n  mutate(upper = estimate + moe,\n         lower = estimate - moe)\n\nmedage16_20 %&gt;% \n  ggplot() +\n  geom_pointrange(aes(x = NAME, y = estimate, ymin = lower, ymax = upper))+\n  geom_line(aes(x = NAME, y = estimate))+\n  coord_flip()+\n  geom_text(aes(x = NAME, y = estimate, label = estimate), hjust = .5, vjust = -.8)+\n  scale_x_discrete(limits = c(\"Grundy Center city, Iowa\", \"Independence city, Iowa\", \"New Hampton city, Iowa\", \"Iowa\"),labels = c(\"Grundy Center\",\"Independence\",\"New Hampton\",\"Iowa\"))+\n  labs(title = \"Median Age of the Population\",\n       subtitle = \"Data aquired from 2017-2021 5-year ACS estimates.\",\n       x = \"\",\n       y = \" \",)+\n  theme_fivethirtyeight()\n\n`geom_line()`: Each group consists of only one observation.\ni Do you need to adjust the group aesthetic?\n\n\n\n\n\n\n#PERCENT FOREIGN BORN, NON-CITIZENS\nforeign &lt;- c(\"foreign\" = \"B05012_003\",\n             \"pop\" = \"B05012_001\")\n\nforeign &lt;- get_acs(geography = \"place\",\n                   state = \"IA\",\n                   year = 2021,\n                   variable = foreign,\n                   output = \"wide\") %&gt;% \n  filter(NAME %in% c(\"Grundy Center city, Iowa\", \"Independence city, Iowa\", \"New Hampton city, Iowa\"))\n\nGetting data from the 2017-2021 5-year ACS\n\n## Getting data from the 2017-2021 5-year ACS\nforeign &lt;- foreign %&gt;% \n  mutate(pct_foreign = foreignE/popE,\n         pct_foreign_moe = moe_prop(foreignE, popE, foreignM, popM))\n\nforeign %&gt;% \n  ggplot() +\n  geom_pointrange(aes(x = NAME, y = pct_foreign, ymin = pct_foreign - pct_foreign_moe, ymax = pct_foreign + pct_foreign_moe ))+\n  coord_flip() +\n  scale_y_continuous(label = scales::percent) +\n  theme_fivethirtyeight() +\n  labs( x = \" \",\n        y = \"Pct Foreign\",\n        title = \"Percent of Foreign-Born, Non-Citzen\",\n        subtitle = \"2017-2021 5-Year ACS Estimates\")+\n  scale_x_discrete(labels = c(\"Grundy Center\", \"Independence\", \"New Hampton\"))+\n  geom_text(aes(x = NAME, y = pct_foreign, label = percent(pct_foreign)), hjust = .5, vjust = -.8)\n\n\n\n\n\n##MEDIAN INCOME BY HOUSEHOLD\ngrundy_acs &lt;- get_acs(state = \"IA\", \n                       geography = \"place\",\n                       year = 2021,\n                       variable = c(med_house = \"B19013_001\"),\n                       output = \"tidy\") %&gt;% \n  filter(NAME == \"Grundy Center city, Iowa\")\n\nGetting data from the 2017-2021 5-year ACS\n\ninde_acs &lt;- get_acs(state = \"IA\", \n                      geography = \"place\",\n                      year = 2021,\n                      variable = c(med_house = \"B19013_001\"),\n                      output = \"tidy\") %&gt;% \n  filter(NAME == \"Independence city, Iowa\")\n\nGetting data from the 2017-2021 5-year ACS\n\nnew_acs &lt;- get_acs(state = \"IA\", \n                      geography = \"place\",\n                      year = 2021,\n                      variable = c(med_house = \"B19013_001\"),\n                      output = \"tidy\") %&gt;% \n  filter(NAME == \"New Hampton city, Iowa\")\n\nGetting data from the 2017-2021 5-year ACS\n\n## Getting data from the 2016-2020 5-year ACS\nmed_house &lt;- grundy_acs %&gt;% \n  bind_rows(inde_acs,new_acs)\nmed_house %&gt;%  \n  ggplot(aes(x = NAME, y = estimate))+\n  geom_pointrange(aes(ymin = estimate - moe, ymax = estimate +moe))+\n  geom_text(aes(label = scales::dollar(estimate)), hjust = -.2)+\n  scale_x_discrete(labels = c(\"Grundy Center\", \"Independence\", \"New Hampton\"))+\n  scale_y_continuous(label = scales::dollar)+\n  labs(y = \"\",\n       title = \"Estimated Median Income by Household\",\n       subtitle = \"Data acquired from 2017-2021 5-year ACS estimates.\")+\n  theme_fivethirtyeight()\n\n\n\n\n\n# % LABOR FORCE UNEMPLOYED\ngrundy_un &lt;- get_acs(state = \"IA\", \n                      geography = \"place\",\n                      year = 2021,\n                      variable = c(\"total\" = \"B23025_003\",\n                                   \"unemployed\" = \"B23025_005\"),\n                      output = \"wide\") %&gt;% \n  filter(NAME == \"Grundy Center city, Iowa\") %&gt;% \n  mutate(pct = unemployedE / totalE,\n         moe = moe_ratio(unemployedE, totalE, unemployedM, totalM))\n\nGetting data from the 2017-2021 5-year ACS\n\ninde_un &lt;- get_acs(state = \"IA\", \n                     geography = \"place\",\n                     year = 2021,\n                     variable = c(\"total\" = \"B23025_003\",\n                                  \"unemployed\" = \"B23025_005\"),\n                     output = \"wide\") %&gt;% \n  filter(NAME == \"Independence city, Iowa\") %&gt;% \n  mutate(pct = unemployedE / totalE,\n         moe = moe_ratio(unemployedE, totalE, unemployedM, totalM))\n\nGetting data from the 2017-2021 5-year ACS\n\nnew_un &lt;- get_acs(state = \"IA\", \n                     geography = \"place\",\n                     year = 2021,\n                     variable = c(\"total\" = \"B23025_003\",\n                                  \"unemployed\" = \"B23025_005\"),\n                     output = \"wide\") %&gt;% \n  filter(NAME == \"New Hampton city, Iowa\") %&gt;% \n  mutate(pct = unemployedE / totalE,\n         moe = moe_ratio(unemployedE, totalE, unemployedM, totalM))\n\nGetting data from the 2017-2021 5-year ACS\n\n## Getting data from the 2016-2020 5-year ACS\npct_un &lt;- grundy_un %&gt;% \n  bind_rows(inde_un,new_un)\npct_un %&gt;%  \n  ggplot(aes(x = NAME, y = pct))+\n  geom_pointrange(aes(ymin = pct - moe, ymax = pct +moe))+\n  geom_text(aes(label = scales::percent(pct)), hjust = -.2)+\n  scale_y_continuous(label = scales::percent)+\n  scale_x_discrete(labels = c(\"Grundy Center\", \"Independence\", \"New Hampton\"))+\n  labs(y = \"\",\n       x = \"\",\n       title = \"Estimated % of Population Unemployed\",\n       subtitle = \"Data acquired from 2017-2021 5-year ACS estimates.\")+\n  theme_fivethirtyeight()\n\n\n\n\nWe also had our first client meeting for the Housing and AI project this week on Thursday, May 25th. We gained clarity for which direction we should be heading in the project from our stakeholders.\ngit_add\ngit_commit\ngit_push"
  },
  {
    "objectID": "posts/Week_2/Week_2.html#tidycensus-practice",
    "href": "posts/Week_2/Week_2.html#tidycensus-practice",
    "title": "Week Two",
    "section": "",
    "text": "This week we were introduced to the TidyCensus package via the 2023 webinar series Analyzing 2017-2021 ACS Data in R and Python by Kyle Walker, Associate Professor at Texas Christian University and R developer.\nWe watched the first two videos in the webinar series: Working with the 2021 American Community Survey with R and Tidycensus and Mapping and spatial analysis with ACS data in R.\nI created the following plots using the information I learned from the webinars and previous knowledge:\n\nlibrary(tidycensus)\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.1.3\n\n\nWarning: package 'ggplot2' was built under R version 4.1.3\n\n\nWarning: package 'tibble' was built under R version 4.1.3\n\n\nWarning: package 'tidyr' was built under R version 4.1.3\n\n\nWarning: package 'readr' was built under R version 4.1.3\n\n\nWarning: package 'purrr' was built under R version 4.1.3\n\n\nWarning: package 'dplyr' was built under R version 4.1.3\n\n\nWarning: package 'stringr' was built under R version 4.1.3\n\n\nWarning: package 'forcats' was built under R version 4.1.3\n\n\nWarning: package 'lubridate' was built under R version 4.1.3\n\n\n-- Attaching core tidyverse packages ------------------------ tidyverse 2.0.0 --\nv dplyr     1.1.2     v readr     2.1.4\nv forcats   1.0.0     v stringr   1.5.0\nv ggplot2   3.4.2     v tibble    3.2.1\nv lubridate 1.9.2     v tidyr     1.3.0\nv purrr     1.0.1     \n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\ni Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(ggthemes)\nlibrary(scales)\n\nWarning: package 'scales' was built under R version 4.1.3\n\n\n\nAttaching package: 'scales'\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\n\n\n##ONWER VS. RENTER OCCUPIED FOR EACH CITY\nown_iowa &lt;- get_decennial(geography = \"place\",\n                          state = \"IA\",\n                          year = 2010,\n                          output = \"wide\",\n                          variable = c(\"H017003\",\"H017004\",\"H017005\",\"H017006\",\"H017007\",\"H017008\",\"H017009\",\"H017010\",\"H017011\")) %&gt;% \n  mutate(tenure = \"Owner\") %&gt;% \n  rename(fifteentotwentyfour = H017003, twentyfivetothirtyfour = H017004, thirtyfivetofourtyfour = H017005, fourtyfivetofiftyfour = H017006, fiftyfivetofiftynine = H017007, sixtytosixtyfour = H017008, sixtyfivetoseventyfour = H017009, seventyfivetoeightyfour = H017010, overeightyfive = H017011)\n\nGetting data from the 2010 decennial Census\n\n\nUsing Census Summary File 1\n\n## Getting data from the 2010 decennial Census\n## Using Census Summary File 1\nrent_iowa &lt;- get_decennial(geography = \"place\",\n                           state = \"IA\",\n                           year = 2010,\n                           output = \"wide\",\n                           variable = c(\"H017013\",\"H017014\", \"H017015\", \"H017016\", \"H017017\",\"H017018\",\"H017019\", \"H017020\",\"H017021\")) %&gt;% \n  mutate(tenure = \"Renter\") %&gt;% \n  rename(fifteentotwentyfour = H017013, twentyfivetothirtyfour = H017014, thirtyfivetofourtyfour = H017015, fourtyfivetofiftyfour = H017016, fiftyfivetofiftynine = H017017, sixtytosixtyfour = H017018, sixtyfivetoseventyfour = H017019, seventyfivetoeightyfour = H017020, overeightyfive = H017021)\n\nGetting data from the 2010 decennial Census\nUsing Census Summary File 1\n\n## Getting data from the 2010 decennial Census\n## Using Census Summary File 1\niowa &lt;- rent_iowa %&gt;% \n  bind_rows(own_iowa)%&gt;% \n  pivot_longer(-c(NAME, GEOID, tenure),\n               names_to = \"agegroups\",\n               values_to = \"count\")\n\n###plots for grundy, independence and new hampton for age break downs by housing tenure\niowa %&gt;% \n  filter(NAME == \"New Hampton city, Iowa\") %&gt;% \n  mutate(agegroups = fct_relevel(agegroups, c(\"fifteentotwentyfour\", \"twentyfivetothirtyfour\",\"thirtyfivetofourtyfour\",\"fourtyfivetofiftyfour\",\"fiftyfivetofiftynine\",\"sixtytosixtyfour\",\"sixtyfivetoseventyfour\",\"seventyfivetoeightyfour\",\"overeightyfive\"))) %&gt;% \n  ggplot(aes(x = agegroups, y = if_else(tenure == \"Renter\", count, -count))) +\n  geom_bar(aes(fill = tenure), stat = \"identity\") +\n  geom_text(aes(x = agegroups, y = if_else(tenure == \"Renter\", count +10, -count - 12), label = scales::comma(count))) +\n  coord_flip()+\n  scale_x_discrete(labels = c(\"15 to 24\", \"25 to 34\", \"35 to 44\", \"45 to 54\", \"55 to 59\", \"60 to 64\", \"65 to 74\", \"75 to 84\", \"85 and Older\")) +\n  scale_y_continuous(label = abs)+\n  labs(x = \"\",\n       y = \"Population\",\n       fill = \"\",\n       title = \"Population in New Hampton, IA \\nby Age and Tenure\",\n       subtitle = \"2010 Decennial Census\") +\n  theme_fivethirtyeight()+\n  theme(legend.position = \"bottom\") +\n  scale_fill_wsj()\n\n\n\niowa %&gt;% \n  filter(NAME == \"Grundy Center city, Iowa\") %&gt;% \n  mutate(agegroups = fct_relevel(agegroups, c(\"fifteentotwentyfour\", \"twentyfivetothirtyfour\",\"thirtyfivetofourtyfour\",\"fourtyfivetofiftyfour\",\"fiftyfivetofiftynine\",\"sixtytosixtyfour\",\"sixtyfivetoseventyfour\",\"seventyfivetoeightyfour\",\"overeightyfive\"))) %&gt;% \n  ggplot(aes(x = agegroups, y = if_else(tenure == \"Renter\", count, -count))) +\n  geom_bar(aes(fill = tenure), stat = \"identity\") +\n  geom_text(aes(x = agegroups, y = if_else(tenure == \"Renter\", count +5, -count - 8), label = scales::comma(count))) +\n  coord_flip()+\n  scale_x_discrete(labels = c(\"15 to 24\", \"25 to 34\", \"35 to 44\", \"45 to 54\", \"55 to 59\", \"60 to 64\", \"65 to 74\", \"75 to 84\", \"85 and Older\")) +\n  scale_y_continuous(label = abs)+\n  labs(x = \"\",\n       y = \"Population\",\n       fill = \"\",\n       title = \"Population in Grundy Center, IA \\nby Age and Tenure\",\n       subtitle = \"2010 Decennial Census\") +\n  theme_fivethirtyeight()+\n  theme(legend.position = \"bottom\") +\n  scale_fill_wsj()\n\n\n\niowa %&gt;% \n  filter(NAME == \"Independence city, Iowa\") %&gt;% \n  mutate(agegroups = fct_relevel(agegroups, c(\"fifteentotwentyfour\", \"twentyfivetothirtyfour\",\"thirtyfivetofourtyfour\",\"fourtyfivetofiftyfour\",\"fiftyfivetofiftynine\",\"sixtytosixtyfour\",\"sixtyfivetoseventyfour\",\"seventyfivetoeightyfour\",\"overeightyfive\"))) %&gt;% \n  ggplot(aes(x = agegroups, y = if_else(tenure == \"Renter\", count, -count))) +\n  geom_bar(aes(fill = tenure), stat = \"identity\") +\n  geom_text(aes(x = agegroups, y = if_else(tenure == \"Renter\", count +12, -count - 15), label = scales::comma(count))) +\n  coord_flip()+\n  scale_x_discrete(labels = c(\"15 to 24\", \"25 to 34\", \"35 to 44\", \"45 to 54\", \"55 to 59\", \"60 to 64\", \"65 to 74\", \"75 to 84\", \"85 and Older\")) +\n  scale_y_continuous(label = abs)+\n  labs(x = \"\",\n       y = \"Population\",\n       fill = \"\",\n       title = \"Population in Independence, IA by \\nAge and Tenure\",\n       subtitle = \"2010 Decennial Census\") +\n  theme_fivethirtyeight()+\n  theme(legend.position = \"bottom\") +\n  scale_fill_wsj()\n\n\n\n\n\n##MEDIAN AGE\n\nmedage &lt;- c(\"medage\" = \"B01002_001\")\n\ngrundy &lt;- get_acs(geography = \"place\",\n              state = \"IA\",\n              variable = medage,\n              year = 2021,\n              output = \"tidy\") %&gt;% \n  filter(NAME == \"Grundy Center city, Iowa\") %&gt;% \n  mutate(year = 2021) \n\nGetting data from the 2017-2021 5-year ACS\n\n## Getting data from the 2016-2020 5-year ACS\ninde &lt;- get_acs(geography = \"place\",\n                state = \"IA\",\n                variable = medage,\n                year = 2021,\n                output = \"tidy\") %&gt;% \n  filter(NAME == \"Independence city, Iowa\") %&gt;% \n  mutate(year = 2021)\n\nGetting data from the 2017-2021 5-year ACS\n\nnew &lt;- get_acs(geography = \"place\",\n                state = \"IA\",\n                variable = medage,\n                year = 2021,\n                output = \"tidy\") %&gt;% \n  filter(NAME == \"New Hampton city, Iowa\") %&gt;% \n  mutate(year = 2021)\n\nGetting data from the 2017-2021 5-year ACS\n\n## Getting data from the 2016-2020 5-year ACS\nia &lt;- get_acs(geography = \"state\",\n              state = \"IA\",\n              variable = medage,\n              year = 2021,\n              output = \"tidy\") %&gt;% \n  mutate(year = 2021)\n\nGetting data from the 2017-2021 5-year ACS\n\n## Getting data from the 2016-2020 5-year ACS\nmedage16_20 &lt;- grundy %&gt;% \n  bind_rows(ia,inde, new) %&gt;% \n  mutate(upper = estimate + moe,\n         lower = estimate - moe)\n\nmedage16_20 %&gt;% \n  ggplot() +\n  geom_pointrange(aes(x = NAME, y = estimate, ymin = lower, ymax = upper))+\n  geom_line(aes(x = NAME, y = estimate))+\n  coord_flip()+\n  geom_text(aes(x = NAME, y = estimate, label = estimate), hjust = .5, vjust = -.8)+\n  scale_x_discrete(limits = c(\"Grundy Center city, Iowa\", \"Independence city, Iowa\", \"New Hampton city, Iowa\", \"Iowa\"),labels = c(\"Grundy Center\",\"Independence\",\"New Hampton\",\"Iowa\"))+\n  labs(title = \"Median Age of the Population\",\n       subtitle = \"Data aquired from 2017-2021 5-year ACS estimates.\",\n       x = \"\",\n       y = \" \",)+\n  theme_fivethirtyeight()\n\n`geom_line()`: Each group consists of only one observation.\ni Do you need to adjust the group aesthetic?\n\n\n\n\n\n\n#PERCENT FOREIGN BORN, NON-CITIZENS\nforeign &lt;- c(\"foreign\" = \"B05012_003\",\n             \"pop\" = \"B05012_001\")\n\nforeign &lt;- get_acs(geography = \"place\",\n                   state = \"IA\",\n                   year = 2021,\n                   variable = foreign,\n                   output = \"wide\") %&gt;% \n  filter(NAME %in% c(\"Grundy Center city, Iowa\", \"Independence city, Iowa\", \"New Hampton city, Iowa\"))\n\nGetting data from the 2017-2021 5-year ACS\n\n## Getting data from the 2017-2021 5-year ACS\nforeign &lt;- foreign %&gt;% \n  mutate(pct_foreign = foreignE/popE,\n         pct_foreign_moe = moe_prop(foreignE, popE, foreignM, popM))\n\nforeign %&gt;% \n  ggplot() +\n  geom_pointrange(aes(x = NAME, y = pct_foreign, ymin = pct_foreign - pct_foreign_moe, ymax = pct_foreign + pct_foreign_moe ))+\n  coord_flip() +\n  scale_y_continuous(label = scales::percent) +\n  theme_fivethirtyeight() +\n  labs( x = \" \",\n        y = \"Pct Foreign\",\n        title = \"Percent of Foreign-Born, Non-Citzen\",\n        subtitle = \"2017-2021 5-Year ACS Estimates\")+\n  scale_x_discrete(labels = c(\"Grundy Center\", \"Independence\", \"New Hampton\"))+\n  geom_text(aes(x = NAME, y = pct_foreign, label = percent(pct_foreign)), hjust = .5, vjust = -.8)\n\n\n\n\n\n##MEDIAN INCOME BY HOUSEHOLD\ngrundy_acs &lt;- get_acs(state = \"IA\", \n                       geography = \"place\",\n                       year = 2021,\n                       variable = c(med_house = \"B19013_001\"),\n                       output = \"tidy\") %&gt;% \n  filter(NAME == \"Grundy Center city, Iowa\")\n\nGetting data from the 2017-2021 5-year ACS\n\ninde_acs &lt;- get_acs(state = \"IA\", \n                      geography = \"place\",\n                      year = 2021,\n                      variable = c(med_house = \"B19013_001\"),\n                      output = \"tidy\") %&gt;% \n  filter(NAME == \"Independence city, Iowa\")\n\nGetting data from the 2017-2021 5-year ACS\n\nnew_acs &lt;- get_acs(state = \"IA\", \n                      geography = \"place\",\n                      year = 2021,\n                      variable = c(med_house = \"B19013_001\"),\n                      output = \"tidy\") %&gt;% \n  filter(NAME == \"New Hampton city, Iowa\")\n\nGetting data from the 2017-2021 5-year ACS\n\n## Getting data from the 2016-2020 5-year ACS\nmed_house &lt;- grundy_acs %&gt;% \n  bind_rows(inde_acs,new_acs)\nmed_house %&gt;%  \n  ggplot(aes(x = NAME, y = estimate))+\n  geom_pointrange(aes(ymin = estimate - moe, ymax = estimate +moe))+\n  geom_text(aes(label = scales::dollar(estimate)), hjust = -.2)+\n  scale_x_discrete(labels = c(\"Grundy Center\", \"Independence\", \"New Hampton\"))+\n  scale_y_continuous(label = scales::dollar)+\n  labs(y = \"\",\n       title = \"Estimated Median Income by Household\",\n       subtitle = \"Data acquired from 2017-2021 5-year ACS estimates.\")+\n  theme_fivethirtyeight()\n\n\n\n\n\n# % LABOR FORCE UNEMPLOYED\ngrundy_un &lt;- get_acs(state = \"IA\", \n                      geography = \"place\",\n                      year = 2021,\n                      variable = c(\"total\" = \"B23025_003\",\n                                   \"unemployed\" = \"B23025_005\"),\n                      output = \"wide\") %&gt;% \n  filter(NAME == \"Grundy Center city, Iowa\") %&gt;% \n  mutate(pct = unemployedE / totalE,\n         moe = moe_ratio(unemployedE, totalE, unemployedM, totalM))\n\nGetting data from the 2017-2021 5-year ACS\n\ninde_un &lt;- get_acs(state = \"IA\", \n                     geography = \"place\",\n                     year = 2021,\n                     variable = c(\"total\" = \"B23025_003\",\n                                  \"unemployed\" = \"B23025_005\"),\n                     output = \"wide\") %&gt;% \n  filter(NAME == \"Independence city, Iowa\") %&gt;% \n  mutate(pct = unemployedE / totalE,\n         moe = moe_ratio(unemployedE, totalE, unemployedM, totalM))\n\nGetting data from the 2017-2021 5-year ACS\n\nnew_un &lt;- get_acs(state = \"IA\", \n                     geography = \"place\",\n                     year = 2021,\n                     variable = c(\"total\" = \"B23025_003\",\n                                  \"unemployed\" = \"B23025_005\"),\n                     output = \"wide\") %&gt;% \n  filter(NAME == \"New Hampton city, Iowa\") %&gt;% \n  mutate(pct = unemployedE / totalE,\n         moe = moe_ratio(unemployedE, totalE, unemployedM, totalM))\n\nGetting data from the 2017-2021 5-year ACS\n\n## Getting data from the 2016-2020 5-year ACS\npct_un &lt;- grundy_un %&gt;% \n  bind_rows(inde_un,new_un)\npct_un %&gt;%  \n  ggplot(aes(x = NAME, y = pct))+\n  geom_pointrange(aes(ymin = pct - moe, ymax = pct +moe))+\n  geom_text(aes(label = scales::percent(pct)), hjust = -.2)+\n  scale_y_continuous(label = scales::percent)+\n  scale_x_discrete(labels = c(\"Grundy Center\", \"Independence\", \"New Hampton\"))+\n  labs(y = \"\",\n       x = \"\",\n       title = \"Estimated % of Population Unemployed\",\n       subtitle = \"Data acquired from 2017-2021 5-year ACS estimates.\")+\n  theme_fivethirtyeight()\n\n\n\n\nWe also had our first client meeting for the Housing and AI project this week on Thursday, May 25th. We gained clarity for which direction we should be heading in the project from our stakeholders.\ngit_add\ngit_commit\ngit_push"
  },
  {
    "objectID": "posts/Week_3/Week_Three.html",
    "href": "posts/Week_3/Week_Three.html",
    "title": "Week Three of Data Science for the Public Good",
    "section": "",
    "text": "This week my team has been trying to gather resources to use in our AI model. We are trying to scrape data from multiple different sources including Beacon, Vanguard, and Trulia to compile photos and train our AI model.\nI have been learning how to web scrape, and I have completed the following DataCamp trainings:"
  },
  {
    "objectID": "posts/Week_3/Week_Three.html#datacamp-trainings",
    "href": "posts/Week_3/Week_Three.html#datacamp-trainings",
    "title": "Week Three of Data Science for the Public Good",
    "section": "DataCamp Trainings",
    "text": "DataCamp Trainings\n\nIntermediate R\nWeb Scraping in R\n\nI have also created an R Markdown file to document my web scraping practice.\nI did a quick Google search for a web scraper for Beacon before I attempted it myself, and I found a GitHub page dedicated to one:\nhttps://github.com/openaddresses/machine/issues/580\nI am not sure it is relevant to the data I am trying to scrape from Beacon.\nI also learned how to create a quarto blog this week!"
  },
  {
    "objectID": "posts/Week_3/Week_Three.html#ai-modeling",
    "href": "posts/Week_3/Week_Three.html#ai-modeling",
    "title": "Week Three of Data Science for the Public Good",
    "section": "AI Modeling",
    "text": "AI Modeling\nTo better understand the AI model my group is trying to create, I am watching the following YouTube videos:\n\nhttps://www.youtube.com/watch?v=19LQRx78QVU&list=PLgNJO2hghbmiXg5d4X8DURJP9yv9pgjIu&index=1&ab_channel=NicholasRenotte\nhttps://www.youtube.com/watch?v=jztwpsIzEGc&ab_channel=NicholasRenotte"
  },
  {
    "objectID": "posts/Week_3/Week_Three.html#morning-coffee-talk",
    "href": "posts/Week_3/Week_Three.html#morning-coffee-talk",
    "title": "Week Three of Data Science for the Public Good",
    "section": "Morning Coffee Talk",
    "text": "Morning Coffee Talk\nI also gave the Morning Coffee Talk on Thursday this week over the Des Moines Housing Project I was a part of. The Des Moines Housing Project was conducted by czb, a firm located in Bath, Maine. I was hired as a student researcher for them this past spring, and I conducted housing surveys on roughly 6,000 properties in Southwestern Des Moines."
  },
  {
    "objectID": "posts/Week_5/Week_5.html",
    "href": "posts/Week_5/Week_5.html",
    "title": "Week Five of Data Science for the Public Good",
    "section": "",
    "text": "Chris informed us this morning that we need to include a demographic analysis or report in our project. We reviewed the initial project brief, and I realized that my group had skipped to the end of Year 1 when we started with AI Models. Whoops!\nWe need to go back at some point and work with demographics. I started a little bit of it today. We need to include the following:\n\nIdentify communities with populations between 500 and 10,000\nChange in population\nPresence of schools\nMean age of residents (I wonder if we should discuss changing this to median because it is less influenced by outliers)\nIndustry report\nAg Census data:\n\nNumber of Operators\nOperator Owned\netc.\n\nHousing appreciation and depreciation vs. inflation\n\nWe also started sorting the Google Street View images to train our AI Models on Monday. We need to sort based on six different models. We started with our first three.\n\nIs a house present?\n\nYes\nNo\n\nIs it a clear image of a house?\n\nObstructed\nPartially obstructed\nNot obstructed\n\nAre there multiple houses?\n\nOne House\nMore than one house\n\n\nWhen we started sorting the images, I noticed an error with an Independence image. The image on the left below is the one that we downloaded from Google Street View. Because I have been in Independence before, I could tell that this was not a photo of Independence. The photo on the left is from a different place, and the photo on the right is the same address but actually in Independence.\nI checked the URL we used to generate the Google Street View image on the left, and I noticed that we did not specify the city and state. In fact, we didn’t specify the city and state for any of the Independence URLs or the New Hampton URLs. Thankfully this was a quick fix. We just added the city and state to the URL files, and the images downloaded quickly.\n\n\n\nError in Independence Address for Google Image API\n\n\nWhile I was waiting for images to download on Monday, I started working on scraping Realtor.com. NOTE: it is Realtor.com not Realtors.com. I definitely have been misspelling it. From the brief look I took at web scraping Realtor.com, it looks like it might be slightly more complicated than Zillow.\nThe address data is stored differently on Realtor.com, and I was not successful in scraping it. Instead of being on one line of HTML, it is split up on multiple.\n\n\n\nRealtor.com address HTML"
  },
  {
    "objectID": "posts/Week_5/Week_5.html#monday",
    "href": "posts/Week_5/Week_5.html#monday",
    "title": "Week Five of Data Science for the Public Good",
    "section": "",
    "text": "Chris informed us this morning that we need to include a demographic analysis or report in our project. We reviewed the initial project brief, and I realized that my group had skipped to the end of Year 1 when we started with AI Models. Whoops!\nWe need to go back at some point and work with demographics. I started a little bit of it today. We need to include the following:\n\nIdentify communities with populations between 500 and 10,000\nChange in population\nPresence of schools\nMean age of residents (I wonder if we should discuss changing this to median because it is less influenced by outliers)\nIndustry report\nAg Census data:\n\nNumber of Operators\nOperator Owned\netc.\n\nHousing appreciation and depreciation vs. inflation\n\nWe also started sorting the Google Street View images to train our AI Models on Monday. We need to sort based on six different models. We started with our first three.\n\nIs a house present?\n\nYes\nNo\n\nIs it a clear image of a house?\n\nObstructed\nPartially obstructed\nNot obstructed\n\nAre there multiple houses?\n\nOne House\nMore than one house\n\n\nWhen we started sorting the images, I noticed an error with an Independence image. The image on the left below is the one that we downloaded from Google Street View. Because I have been in Independence before, I could tell that this was not a photo of Independence. The photo on the left is from a different place, and the photo on the right is the same address but actually in Independence.\nI checked the URL we used to generate the Google Street View image on the left, and I noticed that we did not specify the city and state. In fact, we didn’t specify the city and state for any of the Independence URLs or the New Hampton URLs. Thankfully this was a quick fix. We just added the city and state to the URL files, and the images downloaded quickly.\n\n\n\nError in Independence Address for Google Image API\n\n\nWhile I was waiting for images to download on Monday, I started working on scraping Realtor.com. NOTE: it is Realtor.com not Realtors.com. I definitely have been misspelling it. From the brief look I took at web scraping Realtor.com, it looks like it might be slightly more complicated than Zillow.\nThe address data is stored differently on Realtor.com, and I was not successful in scraping it. Instead of being on one line of HTML, it is split up on multiple.\n\n\n\nRealtor.com address HTML"
  },
  {
    "objectID": "posts/Week_5/Week_5.html#tuesday",
    "href": "posts/Week_5/Week_5.html#tuesday",
    "title": "Week Five of Data Science for the Public Good",
    "section": "Tuesday",
    "text": "Tuesday\nOn Tuesday, we continued sorting images to train our AI Models. I finished sorting the Slater images for a clear view of the house yesterday, and today I worked on the same sorting for Grundy Center.\nWe need about 200 images for each category to train our model. We are struggling to find enough “bad” images.\nChris came over to talk to us about the app he is creating for the Housing Team. His app is meant to make image sorting easier, so he wants to be able to get it to us as soon as possible. He needed a database created with the house address, Google Street View image URL, and city to finish the app. I created the housing database for all the addresses for Slater, Independence, Grundy Center, and New Hampton.\n\n\n\n\n\nChris also suggested that Angelina and I take a look at spatial graphing in R. He said to try the DataCamp course Geospatial in R, and he said to look up Kyle Walkers TidyCensus book.\nOn Tuesday, I also worked more on the demographics analysis that Chris asked for. I am starting the analysis by looking at total population in Iowa’s communities. The first plot I created plotted the change in population for Iowa as a whole.\n\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.1.3\n\n\nWarning: package 'ggplot2' was built under R version 4.1.3\n\n\nWarning: package 'tibble' was built under R version 4.1.3\n\n\nWarning: package 'tidyr' was built under R version 4.1.3\n\n\nWarning: package 'readr' was built under R version 4.1.3\n\n\nWarning: package 'purrr' was built under R version 4.1.3\n\n\nWarning: package 'dplyr' was built under R version 4.1.3\n\n\nWarning: package 'stringr' was built under R version 4.1.3\n\n\nWarning: package 'forcats' was built under R version 4.1.3\n\n\nWarning: package 'lubridate' was built under R version 4.1.3\n\n\n-- Attaching core tidyverse packages ------------------------ tidyverse 2.0.0 --\nv dplyr     1.1.2     v readr     2.1.4\nv forcats   1.0.0     v stringr   1.5.0\nv ggplot2   3.4.2     v tibble    3.2.1\nv lubridate 1.9.2     v tidyr     1.3.0\nv purrr     1.0.1     \n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\ni Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidycensus)\nlibrary(ggthemes)\n\n# renaming the variables now so I don't have to do it later\npop00 &lt;- c(\"pop\" = \"P001001\")\npop10 &lt;- c(\"pop\" = \"P001001\")\npop20 &lt;- c(\"pop\" = \"P1_001N\")\n\n# iowa 2000 population\niowa00 &lt;- get_decennial(geography = \"state\",\n                        state = \"IA\",\n                        year = 2000,\n                        output = \"wide\",\n                        variable = pop00) %&gt;% \n  mutate(year = 2000)\n\nGetting data from the 2000 decennial Census\nUsing Census Summary File 1\n\n# iowa 2010 population\niowa10 &lt;- get_decennial(geography = \"state\",\n                        state = \"IA\",\n                        variable = pop10,\n                        year = 2010,\n                        output = \"wide\") %&gt;% \n  mutate(year = 2010)\n\nGetting data from the 2010 decennial Census\nUsing Census Summary File 1\n\n# iowa 2020 population\niowa20 &lt;- get_decennial(geography = \"state\",\n                        state = \"IA\",\n                        variable = pop20,\n                        year = 2020,\n                        output = \"wide\") %&gt;% \n  mutate(year = 2020)\n\nGetting data from the 2020 decennial Census\nUsing the PL 94-171 Redistricting Data summary file\nNote: 2020 decennial Census data use differential privacy, a technique that\nintroduces errors into data to preserve respondent confidentiality.\ni Small counts should be interpreted with caution.\ni See https://www.census.gov/library/fact-sheets/2021/protecting-the-confidentiality-of-the-2020-census-redistricting-data.html for additional guidance.\n\n# bind 2000-2020 data together\niowa &lt;- iowa20 %&gt;% \n  bind_rows(iowa10,iowa00)\n\n# plot it\nchange_pop_iowa.jpg &lt;- iowa %&gt;% \n  ggplot(aes(x = year, y = pop))+\n  geom_line()+\n  geom_point(size = 2)+\n  geom_text(aes(label = scales::comma(pop)), hjust = -.25)+  \n  scale_y_continuous(label = scales::comma)+  # how do I change the size of the axis labels?\n  scale_x_continuous(limits = c(1998, 2025),\n                     breaks = c(2000,2010,2020))+\n  theme_fivethirtyeight() +  \n  theme(legend.position = \"bottom\")+\n  labs(title = \"Change in Total Population\",\n       subtitle = \"State of Iowa\",\n       y = \"Population\",\n       x = \"\",\n       color = \"\", \n       caption = \"2000-2020 Decennial Census\")\n\n# save the plot as a .jpg\nchange_pop_iowa.jpg %&gt;% ggsave(filename = \"change_pop_iowa.jpg\",width = 6,height = 6, dpi = 400)\n\n\n\n\n\n\nNext, I pulled the total population for each individual community in Iowa for 2020, 2010, and 2000. Using the 2020 Decennial Census data, I found that there are 408 communities in Iowa that fall within our population parameters. This is 39.69% of all cities in Iowa.\nI also looked at the growth rate for communities in Iowa. Because most of Iowa’s cities are on the smaller size, I don’t think that population is an effective indicator for this project. In fact, the median population for communities in Iowa is 384. I added a column for growth rate to my cities data frame containing the communities in Iowa that fall between our population parameters. Growth rate is calculated by dividing the change in population by the time period the change occurred.\n\nGrowth Rate = N/t\n\nI also plotted the twenty-five lowest growth rates in Iowa.\n\n\n\n\n\nKeokuk really stands out on this plot. Earlier in the Housing project, there was discussion about the deteriorating qualities of Lee County, the county of which Keokuk resides. This anomaly will need further investigated.\nNext, I want to look at which communities are growing, stable, and shrinking. The growth rates column should aid in this analysis."
  },
  {
    "objectID": "posts/Week_5/Week_5.html#wednesday",
    "href": "posts/Week_5/Week_5.html#wednesday",
    "title": "Week Five of Data Science for the Public Good",
    "section": "Wednesday",
    "text": "Wednesday\nBecause I will be doing a lot of data visualization in the coming weeks with my demographics analysis task, I decided it would be a good idea to refresh my data visualization skills. I scored a 116 on the Data Visualization in R assessment I took on DataCamp. I am pretty happy with that score.\nI feel that I have quality skills in terms of data visualization, but I am lacking when it comes to organizing the data for visualizations. I think completely the track for Data Visualization in R would be helpful.\n\n\n\n\n\nWhile I was on DataCamp on Wednesday, I also completed the Introduction to Deep Learning with Keras course so I would be ready to create an AI Model. I am in charge of making the model that identifies clear images of houses. We are using Google Collab to create our models, and all the data is being stored in Google Drive. The “clear images” are sorted into three categories: Obstructed, Partially Obstructed, and Not Obstructed.\n\n\n\n\n\nI was successful in creating the AI Model on Wednesday. Below is the accuracy of my model. There is still a long way to go with it. The Housing team has a lot more photos to gather to train our models on and make them as accurate as possible. Now that our AI Models are created, we can go back to web scraping and gathering images."
  },
  {
    "objectID": "posts/Week_5/Week_5.html#thursday",
    "href": "posts/Week_5/Week_5.html#thursday",
    "title": "Week Five of Data Science for the Public Good",
    "section": "Thursday",
    "text": "Thursday\nITAG Conference\nWork on Data Visualization in R DataCamp track."
  },
  {
    "objectID": "posts/Week_5/Week_5.html#friday",
    "href": "posts/Week_5/Week_5.html#friday",
    "title": "Week Five of Data Science for the Public Good",
    "section": "Friday\\",
    "text": "Friday\\"
  },
  {
    "objectID": "posts/Week_7/Team_Blog_Week_7.html",
    "href": "posts/Week_7/Team_Blog_Week_7.html",
    "title": "Team Blog: Week Seven",
    "section": "",
    "text": "For more detailed information on what each member of the housing team has accomplished thus far, check out their individual blog pages. Links are embedded in their specific sections."
  },
  {
    "objectID": "posts/Week_7/Team_Blog_Week_7.html#week-seven-for-the-housing-team",
    "href": "posts/Week_7/Team_Blog_Week_7.html#week-seven-for-the-housing-team",
    "title": "Team Blog: Week Seven",
    "section": "",
    "text": "For more detailed information on what each member of the housing team has accomplished thus far, check out their individual blog pages. Links are embedded in their specific sections."
  },
  {
    "objectID": "posts/Week_7/Team_Blog_Week_7.html#final-presentation-outline",
    "href": "posts/Week_7/Team_Blog_Week_7.html#final-presentation-outline",
    "title": "Team Blog: Week Seven",
    "section": "Final Presentation Outline",
    "text": "Final Presentation Outline\n\n\n\n\n\n\n\n\nSPEAKER\nSECTION\nTIME\n\n\nMorenike\n Introduction\n\nOverview of the project objectives and goals\nImportance of data collection and analysis in real estate and community analysis\n\n2 min\n\n\nAngelina and Kailyn\nData Collection\nScraping from Beacon and Vanguard\n\nBrief explanation of Beacon and Vanguard as data sources\nScraping process\nImportance of obtaining accurate and reliable data from these sources\n\nAddress Cleaning and Google Links\n\nAddress cleaning and standardization techniques\nUtilizing Google links for Google Street View image retrieval\nReasons for having accurate and complete address data\nScraping from Google Street View\nExtracting street view images for AI model use\nTechniques used for automated data extraction from Google Street View\n\nScraping from Zillow\n\nIntroduction to Zillow as a real estate data source\nExtracting relevant property data from Zillow\nChallenges and limitations of scraping from Zillow\n\n5 min\n\n\nGavin\nAngelina and Kailyn on Manual Image Sorting\nAI Model Creation\nOnly displaying images for one of the models. Note in presentation the ones that do exist, but we are using only one model to refine presentation.\nManual Image Sorting to Train Models\n\nTechniques used for organizing and categorizing the obtained images\nPurpose of image sorting\n\nBuilding AI Models (Binary and Multiple)\n\nKeras and Tensorflow Libraries\nRefining image data\nAI has to be able to easily read the images\nIdentify Labels (Binary vs. Multiple)\nSplit Training, Testing, and Evaluating Data\nBuild Layers\nTrain the AI Models\nEvaluate\nExport\n\n10 min\n\n\nGavin\nThe Thing Gavin Made that Writes to a CSV\n8 min\n\n\nKailyn\nDemographic Analysis and Profiling\nSelect Communities\n\nKey findings and insights regarding population, age groups, etc.\n\nAll Iowa Communities\n\nOverview of the demographic analysis methodology\nComparative analysis of Iowa communities based on demographic factors\nVisualization techniques used to present the analysis results\n\n6 min\n\n\nAngelina\nVisualizing Housing Quality Data from AI Model Outputs (with GIS?)\nGeocoding Addresses\n\nExplanation of geocoding process and its importance\nComparison of geocoding in R\nEvaluation of advantages and limitations of each geocoding approach\n\nMapping AI Model data\n\nApplication of spatial data for visualizing and analyzing house quality\nTechniques used for representing house quality on maps\nInterpretation and insights gained from geographical Analysis of house quality\n\n6 min\n\n\nMorenike\nConclusion\n\nSummary of the project workflow and key findings\nLessons learned and challenges encountered\nFuture possibilities and areas for further improvement\n\n2 min\n\n\n\nQuestions\n10 min"
  },
  {
    "objectID": "posts/Week_7/Week_7.html",
    "href": "posts/Week_7/Week_7.html",
    "title": "Week Seven of Data Science for the Public Good",
    "section": "",
    "text": "On Monday, my group had our final? meeting with our stakeholders, Erin Mullinex and Erin Olson-Douglas. I got some clarification on what they expected from the demographic analysis from the meeting. They wanted me to look further into economic and fiscal conditions of Iowa’s communities.\nErin and Erin’s intention with our project is to improve the housing stock across the state. To do so, we need to identify which communities need improvement based on external factors. The final destination after three years is to create an application that assess housing conditions and generates a map of housing characteristic quality.\nErin and Erin also let me know that thriving communities tend to have an employer of some sort. Communities with an employer do well because the employer may provide grants and funding to improve the community. Thriving communities are also growing in population and sometimes have lending institutions and non-profits.\nSo far, I know to look at the following characteristics in the communities that could benefit from our project:\n\npopulations between 500 and 10,000\npopulation change from 2000-2020: growing, stable, or shrinking?\nmedian age of residents\npresence of ag-related industries\nhome ownership rates\npercent of residents commuting to work\nnumber of jobs\nmedian income\nincome change\nworkforce characteristics (this one is still confusing)\nlocal spending patterns (don’t know where to find this data yet)\n\nAfter the meeting with Erin and Erin, I spent the rest of the day sorting WINVEST photos to train our AI Models. The photos are stored in CyBox under the communities they are associated with. Chris made a CSV file of the WINVEST data that we used to filter for poor roofs, poor siding, poor landscaping, and poor gutter. The CSV has the image name in a column, so we could then manually search for the image names associated with the poor values. I also went to Durham’s GIS lab to create community summary infographics for Independence, New Hampton, and Grundy Center.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCommunity summary infographics are really easy to make.\n\nDownload shapefile for the geography you want to make an infographic for. For me, this was the places geography that I downloaded from the Census’s shapefile directory.\nInsert the geography shapefile into ArcGIS Pro.\nSearch for infographics in the tool bar.\nClick on the geography you want to make an infographic for.\nSelect which type of infographic you would like. There are a lot of pre-loaded infographics available for free on ArcGIS Pro. I chose the Community Summary template to create the infographics above.\n\nSome of the elements on the infographics you can toggle to compare to different geographies. The Iowa community summary had the option to compare to the United States. The city infographics I could choose to compare to the county, state, or nation."
  },
  {
    "objectID": "posts/Week_7/Week_7.html#monday",
    "href": "posts/Week_7/Week_7.html#monday",
    "title": "Week Seven of Data Science for the Public Good",
    "section": "",
    "text": "On Monday, my group had our final? meeting with our stakeholders, Erin Mullinex and Erin Olson-Douglas. I got some clarification on what they expected from the demographic analysis from the meeting. They wanted me to look further into economic and fiscal conditions of Iowa’s communities.\nErin and Erin’s intention with our project is to improve the housing stock across the state. To do so, we need to identify which communities need improvement based on external factors. The final destination after three years is to create an application that assess housing conditions and generates a map of housing characteristic quality.\nErin and Erin also let me know that thriving communities tend to have an employer of some sort. Communities with an employer do well because the employer may provide grants and funding to improve the community. Thriving communities are also growing in population and sometimes have lending institutions and non-profits.\nSo far, I know to look at the following characteristics in the communities that could benefit from our project:\n\npopulations between 500 and 10,000\npopulation change from 2000-2020: growing, stable, or shrinking?\nmedian age of residents\npresence of ag-related industries\nhome ownership rates\npercent of residents commuting to work\nnumber of jobs\nmedian income\nincome change\nworkforce characteristics (this one is still confusing)\nlocal spending patterns (don’t know where to find this data yet)\n\nAfter the meeting with Erin and Erin, I spent the rest of the day sorting WINVEST photos to train our AI Models. The photos are stored in CyBox under the communities they are associated with. Chris made a CSV file of the WINVEST data that we used to filter for poor roofs, poor siding, poor landscaping, and poor gutter. The CSV has the image name in a column, so we could then manually search for the image names associated with the poor values. I also went to Durham’s GIS lab to create community summary infographics for Independence, New Hampton, and Grundy Center.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCommunity summary infographics are really easy to make.\n\nDownload shapefile for the geography you want to make an infographic for. For me, this was the places geography that I downloaded from the Census’s shapefile directory.\nInsert the geography shapefile into ArcGIS Pro.\nSearch for infographics in the tool bar.\nClick on the geography you want to make an infographic for.\nSelect which type of infographic you would like. There are a lot of pre-loaded infographics available for free on ArcGIS Pro. I chose the Community Summary template to create the infographics above.\n\nSome of the elements on the infographics you can toggle to compare to different geographies. The Iowa community summary had the option to compare to the United States. The city infographics I could choose to compare to the county, state, or nation."
  },
  {
    "objectID": "posts/Week_7/Week_7.html#tuesday",
    "href": "posts/Week_7/Week_7.html#tuesday",
    "title": "Week Seven of Data Science for the Public Good",
    "section": "Tuesday",
    "text": "Tuesday\nOn Tuesday, I was able to start the demographic analysis. I worked with population data and housing data from the 2021 5-Year American Community Survey.\n\nlibrary(tidycensus)\nlibrary(tidyverse)\n\n\n## Population Data ##\n# Getting population data from 2000-2020 Decennial Census.\n\n# The 2020 total population API is \"P1_001N.\"\n# The 2010 and 2000 total population API is \"P001001.\"\npop &lt;- get_decennial(geography = \"place\",\n                     state = \"IA\",\n                     variables = c(\"pop20\" = \"P1_001N\"),\n                     year = 2020,\n                     output = \"wide\")\npop10 &lt;- get_decennial(geography = \"place\",\n                state = \"IA\",\n                variable = c(\"pop10\"=\"P001001\"),\n                year = 2010,\n                output = \"wide\")\npop00 &lt;- get_decennial(geography = \"place\",\n                       state = \"IA\",\n                       variable = c(\"pop00\"=\"P001001\"),\n                       year = 2000,\n                       output = \"wide\")\n# Join the 2020, 2010, and 2000 total population data by GEOID and NAME.\npop &lt;- pop %&gt;% \n  left_join(pop10,by = c(\"GEOID\",\"NAME\"))\npop &lt;- pop %&gt;% \n  left_join(pop00,by = c(\"GEOID\",\"NAME\"))\n\n# Next, determine which cities are growing, shrinking, or stable in population.\n# Will need to calculate the percent population change (first pop - second pop / first pop).\n# A stable population is between -2% and 2% population change.\n# An increasing population has a greater than 2% population change.\n# A decreasing population has a less than -2% population change. \npop &lt;- pop %&gt;%\n  mutate(prc_change = ((pop20 - pop00) / pop20)) %&gt;% #calculating percent change over 2000-2020\n  mutate(change_label = ifelse(prc_change &gt; .02, \"Growing\",\n                             ifelse(prc_change &lt; -.02, \"Shrinking\", \"Stable\")))\n\nhead(pop)\n\n\n\n\n\n\n\n\n\n\n\n\n\nGEOID\nNAME\npop20\npop10\npop00\nprc_change\nchange_lable\n\n\n\n\n1900190\nAckley\n1599\n1589\n1809\n-0.131332083\nShrinking\n\n\n1900235\nAckworth\n115\n83\n85\n0.260869565\nGrowing\n\n\n1900370\nAdair\n791\n781\n839\n-0.060682680\nShrinking\n\n\n1900505\nAdel\n6153\n3682\n3435\n0.441735739\nGrowing\n\n\n1900595\nAfton\n874\n845\n917\n-0.049199085\nShrinking\n\n\n\n\n## Housing Data ##\n# Getting housing data from the 2021 5-Year American Community Survey.\n\n# Using the following API codes from the ACS:\n# total housing units = \"B25001_001\"\n# owner occupied units = \"B25003_002\"\n# renter occupied units = \"B25003_003\"\n# total occupied units = \"B25002_002\"\n# total vacant units = \"B25002_003\"\n# median house value = \"B25077_001\" \n# median house age = \"B25035_001\"\n\nhousing &lt;- get_acs(geography = \"place\",\n                   state = \"IA\",\n                   variable = c(\"total_units\" = \"B25001_001\",\n                                \"occupied_units\" = \"B25002_002\",\n                                \"vacant_units\" = \"B25002_003\",\n                                \"owner_occupied\" = \"B25003_002\",\n                                \"renter_occupied\" = \"B25003_003\",\n                                \"median_house_value\" = \"B25007_001\"),\n                   year = 2021,\n                   output = \"wide\")\n# Getting median year built data from ACS.\nmedian_age &lt;- get_acs(geography = \"place\",\n                      state = \"IA\",\n                      variable = c(\"median_year_built\" = \"B25035_001\"),\n                      year = 2021,\n                      output = \"wide\") \n# Calculate the median house age by subtracting the median year built from 2023.\nmedian_age &lt;- median_age %&gt;%\n  mutate(median_year_builtE = ifelse(median_year_builtE == 0, NA, median_year_builtE)) %&gt;%\n  mutate(median_house_ageE = 2023 - median_year_builtE) %&gt;% \n  mutate(median_house_ageM = median_year_builtM) # Don't have to make a new moe because the subtraction didn't introduce new errors to the data.\n\n# Join the median year built data to the larger housing data frame.\nhousing &lt;- housing %&gt;% \n  left_join(median_age, by = c(\"GEOID\",\"NAME\"))\n\n# Calculate home ownership, vacany, and rental rates.\n# ALL RATES ARE PERCENTAGES with these calculations.\nhousing &lt;- housing %&gt;% \n  mutate(home_ownership_rateE = (owner_occupiedE / occupied_unitsE)) %&gt;%  # Divide owner occupied units by total occupied units.\n  mutate(home_ownership_rateM = (sqrt((owner_occupiedM^2) / (occupied_unitsE^2) + ((owner_occupiedE * occupied_unitsM)^2) / (occupied_unitsE^4)))) %&gt;%  # Calculate the new moe.\n  mutate(rental_rateE = (renter_occupiedE / occupied_unitsE)) %&gt;%  # Divide renter occupied units by total occupied units.\n  mutate(rental_rateM = (sqrt((renter_occupiedM^2) / (occupied_unitsE^2) + ((renter_occupiedE * occupied_unitsM)^2) / (occupied_unitsE^4)))) %&gt;% # Calculate the new moe.\n  mutate(vacancy_rateE = (vacant_unitsE / total_unitsE)) %&gt;%  # Divide vacant units by total units.\n  mutate(vacancy_rateM = (sqrt((vacant_unitsM^2) / (total_unitsE^2) + ((vacant_unitsE * total_unitsM)^2) / (total_unitsE^4)))) # Calculate the new moe.\n\nhead(housing)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGEOID\nNAME\ntotal_unitsE\ntotal_unitsM\noccupied_unitsE\noccupied_unitsM\nvacant_unitsE\nvacant_uintsM\nowner_occupiedE\nowner_occupiedM\nrenter_occupiedE\nrenter_occupiedM\nmedian_house_valueE\nmedian_house_valueM\nmedian_year_builtE\nmedian_year_builtM\nmedian_house_ageE\nmedian_house_ageM\nhome_ownership_rateE\nhome_ownership_rateM\nvacancy_rateE\nvacancy_rateM\nrental_rateE\nrental_rateM\n\n\n\n\n1900190\nAckley\n800\n71\n705\n69\n95\n39\n553\n59\n152\n48\n705\n69\n1955\n5\n68\n5\n0.7843972\n0.11356683\n0.118750000\n0.049876190\n0.21560284\n0.07128013\n\n\n1900235\nAckworth\n47\n20\n47\n20\n0\n10\n35\n17\n12\n11\n47\n20\n1999\n11\n24\n11\n0.7446809\n0.48087923\n0.000000000\n0.212765957\n0.25531915\n0.25803094\n\n\n1900370\nAdair\n384\n60\n344\n59\n40\n27\n207\n44\n137\n44\n344\n59\n1960\n8\n63\n8\n0.6017442\n0.16435236\n0.104166667\n0.072171720\n0.39825581\n0.14500288\n\n\n1900505\nAdel\n2312\n151\n2234\n120\n78\n97\n1548\n171\n686\n157\n2234\n120\n1978\n7\n45\n7\n0.6929275\n0.08511417\n0.033737024\n0.042012837\n0.30707252\n0.07218725\n\n\n1900595\nAfton\n382\n56\n357\n53\n25\n16\n251\n40\n106\n36\n357\n53\n1962\n3\n61\n3\n0.7030812\n0.15313072\n0.065445026\n0.042969563\n0.29691877\n0.11005386\n\n\n\n\n## Taxable Property Values ##\n#link to data: https://data.iowa.gov/Local-Government-Finance/Taxable-Property-Values-in-Iowa-by-Tax-District-an/ig9g-pba5\n\ntaxable.csv &lt;- read.csv(\"C:/Users/Kailyn Hogan/OneDrive - Iowa State University/Documents/GitHub/Housing/demographics analysis/Community Profile Datasets/Taxable_Property_Values_in_Iowa_by_Tax_District_and_Year.csv\")\n# The name of the city is stored in City.Name and is in uppercase.\n# For the Census data, only the first letter of the city name is capitalized and \" city, Iowa|, Iowa\" is attached.\n# Need to lowercase taxable property values City.Name and remove \" city, Iowa|, Iowa\" from housing and population data frames before joining them. \n\nhousing &lt;- housing %&gt;% \n  mutate(NAME = str_remove(NAME,\" city, Iowa|, Iowa\"))\npop &lt;- pop %&gt;% \n  mutate(NAME = str_remove(NAME, \" city, Iowa|, Iowa\"))\ntaxable.csv &lt;- taxable.csv %&gt;% \n  mutate(City.Name = str_to_sentence(City.Name)) #str_to_sentence() uses regular sentence formatting where the first letter is capitalized.\n                              # Could have also used str_to_titletext().\n\n# Aggregate the sum of all columns and group by City.Name.\n# Function is set to sum to get the sum of all values.\n# na.rm = TRUE means the NAs get ignored when summing.\nresidential &lt;- aggregate(Residential ~ City.Name, data = taxable.csv, FUN = sum, na.rm = TRUE)\nag_land &lt;- aggregate(Ag.Land ~ City.Name, taxable.csv, FUN = sum, na.rm = TRUE)\nag_building &lt;- aggregate(Ag.Building ~ City.Name, taxable.csv, FUN = sum, na.rm = TRUE)\ncommercial &lt;- aggregate(Commercial ~ City.Name, taxable.csv, FUN = sum, na.rm = TRUE)\nindustrial &lt;- aggregate(Industrial ~ City.Name, taxable.csv, FUN = sum, na.rm = TRUE)\n# Join aggregated dataframes together to reform taxable property values data frame.\ntaxable_prop_values &lt;- residential %&gt;%\n  left_join(ag_land, by = \"City.Name\") %&gt;%\n  left_join(ag_building, by = \"City.Name\") %&gt;%\n  left_join(commercial, by = \"City.Name\") %&gt;%\n  left_join(industrial, by = \"City.Name\")\n  \nhead(taxable_property_values)\n\n\n\n\n\n\n\n\n\n\n\n\nCity.Name\nResidential\nAg.Land\nAg.Building\nCommercial\nIndustrial\n\n\n\n\n\n57582069434\n68289755861\n3756099698\n6892181005\n9990249878\n\n\nAckley\n59077903\n1756505\n61418\n20369025\n2143449\n\n\nAckworth\n10399627\n403117\n7779\n67230\n0\n\n\nAdair\n1151067\n715063\n40676\n5091781\n195604\n\n\nAdel\n257984582\n2651441\n27555\n81299747\n12757527\n\n\nAfton\n24900696\n138605\n38906\n7514181\n1583244\n\n\n\nI also download the LEHD Origin-Destination Employment Statistics (LODES) from the Census website as well. I downloaded the 2020 Residential Area Characteristics and the 2020 Workplace Area Characteristics. They are aggregated by census block. I downloaded the Geography crosswalk for IA as well. The geography is needed to associate the census block codes to their related places in Iowa."
  },
  {
    "objectID": "posts/Week_7/Week_7.html#wednesday",
    "href": "posts/Week_7/Week_7.html#wednesday",
    "title": "Week Seven of Data Science for the Public Good",
    "section": "Wednesday",
    "text": "Wednesday\nLate on Wednesday, my team got more clarification from our boss, Chris, on what the AI Housing project actually is. From our conversation, I interpreted that our project is intended to produces a rapid, hands off, housing quality assessment for policy and grant decision makers.\n\n## Median Age of Residents ##\n\n# Getting the median age of all people in all places in Iowa from 2021 5-Year American Community Survey.\npop_age &lt;- get_acs(geography = \"place\",\n               state = \"IA\",\n               year = 2021,\n               variable = c(\"med_age\" = \"B01002_001\"),\n               output = \"wide\") %&gt;% \n  mutate(NAME = str_remove(NAME, \" city, Iowa|, Iowa\"))\n\n# Get the number of people under 18 and over 65 for all places in Iowa.\n# The age data in the American Community Survey is separated by sex, so you will need to get the data for men and then women and combine the data frames. \nmale &lt;- get_acs(geography = \"place\",\n                  state = \"IA\",\n                  year = 2021,\n                  variable = c(\"under5\" = \"B01001_003\", # Make sure to start the variable names with a letter.\n                               \"a5to9\" = \"B01001_004\",\n                               \"a10to14\" = \"B01001_005\",\n                               \"a15to17\" = \"B01001_006\",\n                               \"a65to66\" = \"B01001_020\",\n                               \"a67to69\" = \"B01001_021\",\n                               \"a70to74\" = \"B01001_022\",\n                               \"a75to79\" = \"B01001_023\",\n                               \"a80to84\" = \"B01001_024\",\n                               \"over85\" = \"B01001_025\",\n                               \"total\" = \"B01001_002\"),\n                output = \"wide\") %&gt;% \n  mutate(NAME = str_remove(NAME, \" city, Iowa|, Iowa\"))\nmale &lt;- male %&gt;% \n  mutate(under18E = under5E + a5to9E + a10to14E + a15to17E) %&gt;%\n  mutate(under18M = sqrt(under5M^2 + a5to9M^2 + a10to14M^2 + a15to17M^2)) %&gt;%\n  #mutate(prc_under18E = under18E / totalE) %&gt;% \n  #mutate(prc_under18M = moe_ratio(under18E, totalE, under18M, totalM)) %&gt;% \n  mutate(over65E = a65to66E + a67to69E + a70to74E + a75to79E + a80to84E + over85E) %&gt;%\n  mutate(over65M =  sqrt(a65to66M^2 + a67to69M^2 + a70to74M^2 + a75to79M^2 + a80to84M^2 + over85M^2)) %&gt;% \n # mutate(prc_over65E = over65E / totalE) %&gt;% \n  #mutate(prc_over65M = moe_ratio(over65E, totalE, over65M, totalM)) \n\n# Now do the same for the female age data.\nfemale &lt;- get_acs(geography = \"place\",\n                state = \"IA\",\n                year = 2021,\n                variable = c(\"under5\" = \"B01001_027\",\n                             \"a5to9\" = \"B01001_028\",\n                             \"a10to14\" = \"B01001_029\",\n                             \"a15to17\" = \"B01001_030\",\n                             \"a65to66\" = \"B01001_044\",\n                             \"a67to69\" = \"B01001_045\",\n                             \"a70to74\" = \"B01001_046\",\n                             \"a75to79\" = \"B01001_047\",\n                             \"a80to84\" = \"B01001_048\",\n                             \"over85\" = \"B01001_049\",\n                             \"total\" = \"B01001_026\"),\n                output = \"wide\") %&gt;% \n  mutate(NAME = str_remove(NAME, \" city, Iowa|, Iowa\"))\nfemale &lt;- female %&gt;% \n  mutate(under18E = under5E + a5to9E + a10to14E + a15to17E) %&gt;%\n  mutate(under18M = sqrt(under5M^2 + a5to9M^2 + a10to14M^2 + a15to17M^2)) %&gt;%\n  #mutate(prc_under18E = under18E / totalE) %&gt;% \n #mutate(prc_under18M = moe_ratio(under18E, totalE, under18M, totalM)) %&gt;% \n  mutate(over65E = a65to66E + a67to69E + a70to74E + a75to79E + a80to84E + over85E) %&gt;%\n  mutate(over65M =  sqrt(a65to66M^2 + a67to69M^2 + a70to74M^2 + a75to79M^2 + a80to84M^2 + over85M^2)) %&gt;% \n  #mutate(prc_over65E = over65E / totalE) %&gt;% \n  #mutate(prc_over65M = moe_ratio(over65E, totalE, over65M, totalM)) \n\n# Combine the data frames.\nage &lt;- female %&gt;% \n  bind_rows(male)\n\n# Aggregate the data by NAME.\n# I am using a different aggregation format here by using the summary() function. \n# This will produce a separate dataframe with just under18E, under18M, over65E, over65M, prc_under18E, prc_under18M, prc_over65E, and prc_over65M.\naggregated_age &lt;- age %&gt;% \n  group_by(NAME) %&gt;% \n             summarize(under18E = sum(under18E),\n                       under18M = sqrt(sum(under18M^2)),\n                       over65E = sum(over65E),\n                       over65M = sqrt(sum(over65M)),\n                       prc_under18E = sum(under18E)/sum(totalE),\n                       prc_under18M = sqrt(sum(under18M^2) / sum(totalE)^2 + (sum(under18E)^2 * sum(totalM^2)) / sum(totalE)^4),\n                       prc_over65E = sum(over65E)/sum(totalE),\n                       prc_over65M = sqrt(sum(over65M^2) / sum(totalE)^2 + (sum(over65E)^2 * sum(totalM^2)) / sum(totalE)^4))\n\n# Add a column that states whether a place is \"aged\", \"stable\" or \"young.\"\n# Using a 2% difference to gauge a stable population.\n# Aged population has a less than -2% difference between the percent under 18 and the percent over 65.\n# Young population has a greater than 2% difference between the percent under 18 and the percent over 65. \naggregated_age &lt;- aggregated_age %&gt;%\n  mutate(age_label = ifelse(prc_under18E - prc_over65E &gt; .02, \"Young\",\n                               ifelse(prc_under18E - prc_over65E &lt; -.02, \"Aging\", \"Stable\")))\n\n## Add the age data to the population dataframe.\npop &lt;- pop %&gt;% \n  left_join(aggregated_age,by = c(\"NAME\")) %&gt;% \n  left_join(pop_age, by = c(\"GEOID\",\"NAME\"))\n\nhead(aggregated_age)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNAME\nunder18E\nunder18M\nover65E\nover65M\nprc_under18E\nprc_under18M\nprc_over65E\nprc_over65M\nage_label\n\n\n\n\nAckley\n402\n68.39591\n349\n9.030714\n0.23563892\n0.044036378\n0.20457210\n0.0166781814\nYoung\n\n\nAckworth\n50\n26.47640\n24\n6.256889\n0.33783784\n0.212313083\n0.16216216\n0.0692779288\nYoung\n\n\nAdair\n206\n67.47592\n144\n7.692109\n0.24065421\n0.088939653\n0.16822430\n0.0301622637\nYoung\n\n\nAdel\n1708\n285.81987\n661\n14.821549\n0.29111982\n0.050896612\n0.11266405\n0.0062375436\nYoung\n\n\nAfton\n208\n60.94260\n189\n8.606830\n0.22757112\n0.073795265\n0.20678337\n0.0302370669\nYoung\n\n\n\n\nlibrary(tidyverse)\n\n## Unemployment ##\n# Getting unemployment data from the 2021 5-Year American Community Survey.\n\n# Get the total number of people in the workforce and the total number of the labor force that is unemployed.\n# Calculate the percent of the workforce that is unemployed. \nunemployment &lt;- get_acs(state = \"IA\", \n                   geography = \"place\",\n                   year = 2021,\n                   variable = c(\"total_workforce\" = \"B23025_003\",\n                                \"unemployed\" = \"B23025_005\"),\n                   output = \"wide\") %&gt;% \n  mutate(prc_unemployed = unemployedE / total_workforceE,\n         unemployed_moe = moe_ratio(unemployedE, total_workforceE, unemployedM, total_workforceM)) %&gt;% \n  mutate(NAME = str_remove(NAME,\" city, Iowa|, Iowa\"))\n\nhead(unemployment)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGEOID\nNAME\ntotal_workforceE\ntotal_workforceM\nunemployedE\nunemployedM\nprc_unemplyed\nunemployed_moe\n\n\n\n\n1900190\nAckley\n828\n88\n25\n17\n0.030193237\n0.020780658\n\n\n1900235\nAckworth\n73\n39\n6\n9\n0.082191781\n0.130873976\n\n\n1900370\nAdair\n440\n101\n25\n25\n0.056818182\n0.058295873\n\n\n1900505\nAdel\n3125\n245\n127\n93\n0.040640000\n0.029930074\n\n\n1900595\nAfton\n480\n100\n42\n31\n0.087500000\n0.067106702\n\n\n\n\n## Commuting ##\nlibrary(tidyverse)\nlibrary(tidycensus)\n\n# Getting commute data from the 2021 5-Year American Community Survey.\n\n# Get the total number of people available for commute data and the total number of people commuting to work. \n# Calculate the percent of people commuting to work. \nprc_travel &lt;- get_acs(geography = \"place\",\n                     state = \"IA\",\n                     variable = c(\"total\" = \"B08008_001\",\n                                  \"travel\" = \"B08008_004\"),\n                     year = 2021,\n                     output = \"wide\") %&gt;% \n  mutate(prc_travel = travelE / totalE,\n         travel_moe = (moe_ratio(travelE, totalE, travelM, totalM))) %&gt;% \n  mutate(NAME = str_remove(NAME, \" city, Iowa|, Iowa\"))\n\nhead(prc_travel)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGEOID\nNAME\ntotalE\ntotalM\ntravelE\ntravelM\nprc_travel\ntravel_moe\n\n\n\n\n1900190\nAckley\n797\n85\n534\n83\n0.6700125\n0.12629855\n\n\n1900235\nAckworth\n67\n38\n64\n39\n0.9552239\n0.79519912\n\n\n1900370\nAdair\n412\n93\n230\n57\n0.5582524\n0.18713615\n\n\n1900505\nAdel\n2924\n229\n2216\n263\n0.7578659\n0.10776390\n\n\n1900595\nAfton\n434\n90\n319\n77\n0.7350230\n0.23390328\n\n\n\nWhen I was working on the demographic analysis on Wednesday, I took a break to do some more research on demographic analyses in general. I found this link on my project leader’s, Liesl Eathington, ISU webpage.\nThe link is to a local news article that Liesl was interviewed for talking about the characteristics of thriving rural, small towns. The article also talked about some demographic analysis that was done on rural communities for grant purposes. Through this analysis, the researchers discovered that it was key to analyze housing, income, and jobs in a community to understand it. The researchers also found that an indicator of a declining small town is deteriorating infrastructure like streets and sewers.\nSmall towns that are thriving have one or more of the following characteristics:\n\nclose healthcare\nlocal day care options\nlocal grocery store\nlocal utilities\nlocal restaurants\nlocal shops\nlocal school(s)\n\nKnowing this information will help me finish the demographic analysis of Iowa’s communities. I want to see if I can find available data on infrastructure conditions to identify communities potentially in need of our AI Model."
  },
  {
    "objectID": "posts/Week_7/Week_7.html#thursday",
    "href": "posts/Week_7/Week_7.html#thursday",
    "title": "Week Seven of Data Science for the Public Good",
    "section": "Thursday",
    "text": "Thursday\nMy group spent all morning working on our team’s teaser video. I worked on this blog and this week’s team blog when I had breaks from that. The team blog can be found on this blog and on the 2023 DSPG blog.\nI compiled the data I currently have for the demographic analysis into a larger data frame called “iowa.” I used the function write.csv() to create a CSV file from the “iowa” dataframe. This still needs updated because I am not done working with the WAC and RAC data, but it is a starting point. Later, I will be putting this CSV file into Tableau to visualize the data.\n\nlibrary(tidyverse)\n\n\niowa # Name of aggregated database.\n\niowa &lt;- pop %&gt;% \n  left_join(housing, by = c(\"GEOID\",\"NAME\")) %&gt;% \n  left_join(taxable_prop_values, by = \"NAME\") %&gt;% \n  left_join(unemployment, by = c(\"GEOID\",\"NAME\")) %&gt;% \n  left_join(prc_travel, by = c(\"GEOID\",\"NAME\"))\n\n# Export as CSV.\nwrite.csv(iowa, \"analysing_iowa_communities.csv\", row.names = FALSE)\n\n# Read the CSV file. \ndata &lt;- read.csv(\"C:/Users/Kailyn Hogan/OneDrive - Iowa State University/Documents/GitHub/Housing/demographics analysis/analysing_iowa_communities.csv\") \n\n# Display the contents of the CSV file.\nknitr::kable(head(arrange(data, NAME)))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGEOID\nNAME\npop20\npop10\npop00\nprc_change\nchange_label\nunder18E\nunder18M\nover65E\nover65M\nprc_under18E\nprc_under18M\nprc_over65E\nprc_over65M\nage_label\nmed_ageE\nmed_ageM\ntotal_unitsE\ntotal_unitsM\noccupied_unitsE\noccupied_unitsM\nvacant_unitsE\nvacant_unitsM\nowner_occupiedE\nowner_occupiedM\nrenter_occupiedE\nrenter_occupiedM\nmedian_house_valueE\nmedian_house_valueM\nmedian_year_builtE\nmedian_year_builtM\nmedian_house_ageE\nmedian_house_ageM\nhome_ownership_rateE\nhome_ownership_rateM\nvacancy_rateE\nvacancy_rateM\nrental_rateE\nrental_rateM\nResidential\nAg.Land\nAg.Building\nCommercial\nIndustrial\ntotal_workforceE\ntotal_workforceM\nunemployedE\nunemployedM\nprc_unemployed\nunemployed_moe\ntotalE\ntotalM\ntravelE\ntravelM\nprc_travel\ntravel_moe\n\n\n\n\n1900190\nAckley\n1599\n1589\n1809\n-0.1313321\nShrinking\n402\n68.39591\n349\n9.030714\n0.2356389\n0.0440364\n0.2045721\n0.0166782\nYoung\n41.5\n3.0\n800\n71\n705\n69\n95\n39\n553\n59\n152\n48\n705\n69\n1955\n5\n68\n5\n0.7843972\n0.1135668\n0.1187500\n0.0498762\n0.2156028\n0.0712801\n59077903\n1756505\n61418\n20369025\n2143449\n828\n88\n25\n17\n0.0301932\n0.0207807\n797\n85\n534\n83\n0.6700125\n0.1262985\n\n\n1900235\nAckworth\n115\n83\n85\n0.2608696\nGrowing\n50\n26.47640\n24\n6.256889\n0.3378378\n0.2123131\n0.1621622\n0.0692779\nYoung\n38.1\n30.8\n47\n20\n47\n20\n0\n10\n35\n17\n12\n11\n47\n20\n1999\n11\n24\n11\n0.7446809\n0.4808792\n0.0000000\n0.2127660\n0.2553191\n0.2580309\n10399627\n403117\n7779\n67230\n0\n73\n39\n6\n9\n0.0821918\n0.1308740\n67\n38\n64\n39\n0.9552239\n0.7951991\n\n\n1900370\nAdair\n791\n781\n839\n-0.0606827\nShrinking\n206\n67.47592\n144\n7.692109\n0.2406542\n0.0889397\n0.1682243\n0.0301623\nYoung\n37.7\n8.6\n384\n60\n344\n59\n40\n27\n207\n44\n137\n44\n344\n59\n1960\n8\n63\n8\n0.6017442\n0.1643524\n0.1041667\n0.0721717\n0.3982558\n0.1450029\n1151067\n715063\n40676\n5091781\n195604\n440\n101\n25\n25\n0.0568182\n0.0582959\n412\n93\n230\n57\n0.5582524\n0.1871361\n\n\n1900505\nAdel\n6153\n3682\n3435\n0.4417357\nGrowing\n1708\n285.81987\n661\n14.821549\n0.2911198\n0.0508966\n0.1126641\n0.0062375\nYoung\n36.8\n1.5\n2312\n151\n2234\n120\n78\n97\n1548\n171\n686\n157\n2234\n120\n1978\n7\n45\n7\n0.6929275\n0.0851142\n0.0337370\n0.0420128\n0.3070725\n0.0721873\n257984582\n2651441\n27555\n81299747\n12757527\n3125\n245\n127\n93\n0.0406400\n0.0299301\n2924\n229\n2216\n263\n0.7578659\n0.1077639\n\n\n1900595\nAfton\n874\n845\n917\n-0.0491991\nShrinking\n208\n60.94260\n189\n8.606830\n0.2275711\n0.0737953\n0.2067834\n0.0302371\nYoung\n39.0\n9.2\n382\n56\n357\n53\n25\n16\n251\n40\n106\n36\n357\n53\n1962\n3\n61\n3\n0.7030812\n0.1531307\n0.0654450\n0.0429696\n0.2969188\n0.1100539\n24900696\n138605\n38906\n7514181\n1583244\n480\n100\n42\n31\n0.0875000\n0.0671067\n434\n90\n319\n77\n0.7350230\n0.2339033\n\n\n1900640\nAgency\n620\n638\n622\n-0.0032258\nStable\n71\n29.79933\n123\n6.383032\n0.1501057\n0.0678777\n0.2600423\n0.0458014\nAging\n49.6\n10.8\n233\n41\n211\n38\n22\n22\n154\n29\n57\n25\n211\n38\n1959\n6\n64\n6\n0.7298578\n0.1901772\n0.0944206\n0.0958713\n0.2701422\n0.1280830\n82024799\n119286\n70\n2742290\n2872782\n240\n63\n7\n7\n0.0291667\n0.0301548\n232\n63\n219\n63\n0.9439655\n0.3734276"
  },
  {
    "objectID": "posts/Week_7/Week_7.html#friday",
    "href": "posts/Week_7/Week_7.html#friday",
    "title": "Week Seven of Data Science for the Public Good",
    "section": "Friday",
    "text": "Friday\nOn Friday, I gave the weekly wrap up presentation."
  },
  {
    "objectID": "posts/Week_8/Week_8.html",
    "href": "posts/Week_8/Week_8.html",
    "title": "Week Eight of Data Science for the Public Good",
    "section": "",
    "text": "I began editing the Demographic Profile I made two weeks ago this week. I went back and added comments to my code, added regional and national context to the plots, and started converting some of the data into percentages. Below is the work I completed.\n\n\n\nlibrary(tidyverse)\nlibrary(tidycensus)\nlibrary(ggthemes)\nlibrary(scales)\n\n\n### The first thing we want to visualize is population change.\n\n# 1. Population Change                                                          \n\n# Define the variables before getting the data.\n# The Census API code for total population for 2000 and 2010 is P001001.\npop00 &lt;- c(\"pop\" = \"P001001\")\npop10 &lt;- c(\"pop\" = \"P001001\")\n# The API code for total population changed for 2020.\n# The Census API code for total population is P1_001N for 2020. \npop20 &lt;- c(\"pop\" = \"P1_001N\")\n\n###\n## National Context: nationPop\n# Getting 2000 total population data for the USA.\nnation00 &lt;- get_decennial(geography = \"us\",\n                          year = 2000,\n                          variable = pop00,\n                          output = \"wide\") %&gt;% \n  mutate(year = 2000)\n# Getting 2010 total population data for the USA.\nnation10 &lt;- get_decennial(geography = \"us\",\n                          year = 2010,\n                          variable = pop10,\n                          output = \"wide\") %&gt;% \n  mutate(year = 2010)\n# Getting 2020 total population data for the USA.\nnation20 &lt;- get_decennial(geography = \"us\",\n                          year = 2020,\n                          variable = pop20,\n                          output = \"wide\") %&gt;% \n  mutate(year = 2020)\n# Bind the years together using bind_rows to create data frame for national context. \nnationPop &lt;- nation20 %&gt;% \n  bind_rows(nation10,nation00) %&gt;% \n  mutate(geography = \"Nation\") \n\n\n###\n## Regional Context: regionPop\n# Getting 2000 total population data from the Midwest.\nregion00 &lt;- get_decennial(geography = \"region\",\n                          year = 2000,\n                          variable = pop00,\n                          output = \"wide\") %&gt;% \n  mutate(year = 2000)\n# Getting 2010 total population data for the Midwest.\nregion10 &lt;- get_decennial(geography = \"region\",\n                          year = 2010,\n                          variable = pop10,\n                          output = \"wide\") %&gt;% \n  mutate(year = 2010)\n# Getting 2020 total population data for the Midwest.\nregion20 &lt;- get_decennial(geography = \"region\",\n                          year = 2020,\n                          variable = pop20,\n                          output = \"wide\") %&gt;% \n  mutate(year = 2020)\n# Bind the years together using bind_rows to create data frame for regional context. \n# Filter to keep just the Midwest Region. \nregionPop &lt;- region20 %&gt;% \n  bind_rows(region10,region00) %&gt;% \n  filter(NAME == \"Midwest Region\") %&gt;% \n  mutate(NAME = str_remove(NAME, \" Region\")) %&gt;% # Use str_remove() to remove \" Region\" from Midwest. \n  mutate(geography = \"Region\")\n\n\n###\n## State Context: statePop\n# Getting the 2000 total population data for the state of Iowa from the Decennial Census.\niowa00 &lt;- get_decennial(geography = \"state\",\n                        state = \"IA\",\n                        year = 2000,\n                        output = \"wide\",\n                        variable = pop00) %&gt;% \n  mutate(year = 2000)\n# Getting the 2010 total population data for the state of Iowa from the Decennial Census.\niowa10 &lt;- get_decennial(geography = \"state\",\n                        state = \"IA\",\n                        variable = pop10,\n                        year = 2010,\n                        output = \"wide\") %&gt;% \n  mutate(year = 2010)\n# Getting the 2020 total population data for the state of Iowa from the Decennial Census.\niowa20 &lt;- get_decennial(geography = \"state\",\n                        state = \"IA\",\n                        variable = pop20,\n                        year = 2020,\n                        output = \"wide\") %&gt;% \n  mutate(year = 2020)\n\n# Bind the years together using bind_rows to create data frame for state context. \nstatePop &lt;- iowa20 %&gt;% \n  bind_rows(iowa10,iowa00) %&gt;% \n  mutate(geography = \"State\")\n\n\n###\n## Places: \n# Getting 2000 total population data for all places in Iowa.\nplace00 &lt;- get_decennial(geography = \"place\",\n                         state = \"IA\",\n                         year = 2000,\n                         output = \"wide\",\n                         variables = pop00) %&gt;% \n  mutate(year = 2000)\nplace10 &lt;- get_decennial(geography = \"place\",\n                         state = \"IA\",\n                         year = 2010,\n                         output = \"wide\",\n                         variables = pop10) %&gt;% \n  mutate(year = 2010)\nplace20 &lt;- get_decennial(geography = \"place\",\n                         state = \"IA\",\n                         variable = pop20,\n                         year = 2020,\n                         output = \"wide\") %&gt;% \n  mutate(year = 2020)\n# Bind the years together using bind_rows() to create data frame for all places in Iowa. \nplacePop &lt;- place20 %&gt;% \n  bind_rows(place10,place00) %&gt;% \n  mutate(geography = \"Place\")\n\n# Filter for Independence, Grundy Center, and New Hampton. \nplacePop &lt;- placePop[placePop$NAME %in% c(\"Grundy Center city, Iowa\", \"Independence city, Iowa\", \"New Hampton city, Iowa\"), ] %&gt;% \n  mutate(NAME = str_remove(NAME, \" city, Iowa|, Iowa\")) # Use str_remove() to remove \"city, Iowa\" from behind the place names. \n\n# Combine nationPop, regionPop, statePop, and placePop using bind_rows().\npopulation &lt;- nationPop %&gt;% \n  bind_rows(regionPop,statePop,placePop)\n\n# Calculate the change in population.\npopulation &lt;- population %&gt;%\n  group_by(NAME) %&gt;%\n  arrange(year) %&gt;%\n  mutate(pop_change = pop - lag(pop)) \n\n\n\n\n# Start visualizing total population now that master data frame is created. \n\n\n# Plot the change in total population for Independence.                           PLOT\n# Filter population for Independence.\npopulation %&gt;% \n  filter(NAME == \"Independence\") %&gt;% \n  ggplot(aes(x = year, y = pop))+\n  geom_line()+\n  geom_point(size = 2)+\n  geom_text(aes(label = scales::comma(pop)), hjust = -.31)+\n  scale_y_continuous(label = scales::comma)+\n  scale_x_continuous(limits = c(1997, 2023),\n                     breaks = c(2000,2010,2020))+\n  theme_fivethirtyeight()+\n  theme(legend.position = \"bottom\")+\n  labs(title = \"Change in Total Population\",\n       subtitle = \"Independence, Iowa\",\n       y = \"Population\",\n       x = \"\",\n       color = \"\", \n       caption = \"2000-2020 Decennial Census\")\n\n\n\n# Plot the change in total population for New Hampton.                           PLOT\n# Filter population for New Hampton.\npopulation %&gt;% \n  filter(NAME == \"New Hampton\") %&gt;% \n  ggplot(aes(x = year, y = pop))+\n  geom_line()+\n  geom_point(size = 2)+\n  geom_text(aes(label = scales::comma(pop)),hjust = -.3)+ \n  scale_y_continuous(label = scales::comma)+\n  scale_x_continuous(limits = c(1997, 2023),\n                     breaks = c(2000,2010,2020))+\n  theme_fivethirtyeight()+\n  theme(legend.position = \"bottom\")+\n  labs(title = \"Change in Total Population\",\n       subtitle = \"New Hampton, Iowa\",\n       y = \"Population\",\n       x = \"\",\n       color = \"\", \n       caption = \"2000-2020 Decennial Census\")\n\n\n\n# Plot the change in total population Grundy Center.                              PLOT\n# Filter population for Grundy Center.\npopulation %&gt;% \n  filter(NAME == \"Grundy Center\") %&gt;% \n  ggplot(aes(x = year, y = pop))+\n  geom_line()+\n  geom_point(size = 2)+\n  geom_text(aes(label = scales::comma(pop)),hjust = -.3)+\n  scale_y_continuous(label = scales::comma)+\n  scale_x_continuous(limits = c(1997, 2023),\n                     breaks = c(2000,2010,2020))+\n  theme_fivethirtyeight()+\n  theme(legend.position = \"bottom\")+\n  labs(title = \"Change in Total Population\",\n       subtitle = \"Grundy Center, Iowa\",\n       y = \"Population\",\n       x = \"\",\n       color = \"\", \n       caption = \"2000-2020 Decennial Census\")\n\n\n\n# Plot total population for all cities.                                           PLOT    \n# Filter for the cities. \n# Assign the plot to an object.\npopulation[population$NAME %in% c(\"Grundy Center\", \"Independence\", \"New Hampton\"), ] %&gt;% \n  ggplot(aes(x = year, y = pop, group = NAME))+\n  geom_line(aes(color = NAME), linewidth = 1)+\n  geom_point(size = 2)+\n  geom_text(aes(label = scales::comma(pop_change)),vjust = -1)+\n  scale_y_continuous(label = scales::comma,\n                     limits = c(2500,6300))+\n  scale_x_continuous(limits = c(1998, 2022),\n                     breaks = c(2000,2010,2020))+\n  theme_fivethirtyeight()+\n  theme(legend.position = \"bottom\")+\n  labs(title = \"Change in Total Population\",\n       subtitle = \"2000-2020 Decennial Census\",\n       y = \"Population\",\n       x = \"\",\n       color = \"\", \n       caption = \"Variables: P1_001N and P001001\")\n\n\n\n## Plot change in total population with line type = NAME.                           PLOT\npopulation[population$NAME %in% c(\"Grundy Center\", \"Independence\", \"New Hampton\"), ] %&gt;% \n  ggplot(aes(x = year, y = pop, group = NAME, linetype = NAME))+\n  geom_line()+\n  geom_point(size = 2)+\n  geom_text(aes(label = scales::comma(pop)),vjust = -1)+  \n  scale_y_continuous(label = scales::comma,\n                     limits = c(2500,6500))+\n  scale_x_continuous(limits = c(1998, 2022),\n                     breaks = c(2000,2010,2020))+\n  theme_fivethirtyeight()+\n  theme(legend.position = \"bottom\")+\n  labs(title = \"Change in Total Population\",\n       subtitle = \"Comparison between Grundy Center, Independence,\\nand New Hampton\",\n       y = \"Population\",\n       x = \"\",\n       color = \"\", \n       linetype = \"\",\n       caption = \"2000-2020 Decennial Census\")\n\n\n\n# Plot total population for all geographies.                                      PLOT\n# Assign the plot to an object.\npopulation %&gt;% \n  ggplot(aes(x = year, y = pop, group = NAME)) +\n  geom_line(aes(linetype = geography, color = NAME), linewidth = 1)+\n  geom_point(size = 2)+\n  scale_y_log10(label = scales::comma) +\n  scale_x_continuous(limits = c(2000, 2020),\n                     breaks = c(2000,2010,2020))+\n  theme_fivethirtyeight()+\n  theme(legend.position = \"bottom\")+\n  labs(title = \"Change in Total Population\",\n       y = \"Population (log scale)\",\n       subtitle = \"2000-2020 Decennial Census\",\n       x = \"\",\n       color = \"\", \n       linetype = \"\",\n       caption = \"Variables: P1_001N and P001001\")\n\n\n\n# The next thing we want to visualize is the PERCENT CHANGE in population.\n# 2. Percent Population Change                                                  \n\n# Create anew column called prc_change.\n# Group by \"NAME\" so that the calculations occur individually for each place. \n# Percent change is calculated by subtracting year2 from year1 and dividing by year2. \npopulation &lt;- population %&gt;%\n  group_by(NAME) %&gt;%\n  mutate(prc_change = case_when(\n    year == 2000 ~ NA,\n    year == 2010 ~ (pop - lag(pop, n = 10, default = last(pop))) / lag(pop, n = 10, default = last(pop)),\n    year == 2020 ~ (pop - lag(pop, n = 20, default = last(pop))) / lag(pop, n = 20, default = last(pop))\n  ))\n\n# Create a grouping column in the population data\npopulation &lt;- population %&gt;%\n  mutate(grouping = ifelse(NAME %in% c(\"United States\", \"Midwest\", \"Iowa\"), \"Contextual Area\", \"Places\"))\n\n\n## Plot the percent change in population for all geographies.                    PLOT\n# Assign the plot to an object.\npopulation %&gt;% \n  ggplot(aes(x = year, y = prc_change, group = NAME)) +\n  geom_line(aes(color = NAME, linetype = grouping), linewidth = 1) +\n  geom_text(aes(x= 2020.65, y = .1777, label = \"17.77%\"), size = 3.5) +\n  geom_text(aes(x= 2020.65, y = .09023, label = \"9.02%\"), vjust = -.2, size = 3.5) +\n  geom_text(aes(x= 2020.65, y = .07132, label = \"7.13%\"), vjust = 1.2, size = 3.5) +\n  geom_text(aes(x= 2020.65, y = .0770416, label = \"7.70%\"), size = 3.5, vjust = -.000002) +\n  geom_text(aes(x= 2020.65, y = .0083139, label = \"0.83%\"), size = 3.5) +\n  geom_text(aes(x= 2020.65, y = -.053629, label = \"-5.36%\"), size = 3.5) +\n  geom_point(size = 2) +\n  scale_y_continuous(label = scales::percent) +\n  scale_x_continuous(breaks = c(2010, 2015,2020), limits = c(2010,2021)) +\n  theme_fivethirtyeight() +\n  theme(strip.text = element_text(face = \"bold\"))+\n  labs(title = \"Percent Change in Total Population\",\n       subtitle = \"2000-2020 Decennial Census\",\n       color = \"\",\n       caption = \"Variables: P1_001N and P001001\",\n       linetype = \"\") \n\n\n\n## Plot the percent change in total population for just the places.\n# Filter the population data frame for places. \n# Assign the plot to an object.\npopulation[population$NAME %in% c(\"Grundy Center\", \"Independence\", \"New Hampton\"), ] %&gt;% \n  ggplot(aes(x = year, y = prc_change, group = NAME)) +\n  geom_line(aes(color = NAME), linewidth = 1) +\n  geom_point(size = 2) +\n  geom_text(aes(label = scales::percent(prc_change)), hjust = .5,vjust = -.75 )+\n  scale_y_continuous(label = scales::percent, limits = c(-.06,.085)) +\n  scale_x_continuous(breaks = c(2010,2015, 2020), limits = c(2008, 2022)) +\n  theme_fivethirtyeight() +\n  theme(strip.text = element_text(face = \"bold\"),\n        legend.position = \"bottom\")+  # Align legend to the right\n  labs(title = \"Percent Change in Total Population\",\n       subtitle = \"2000-2020 Decennial Census\",\n       color = \"\",\n       caption = \"Variables: P1_001N and P001001\",\n       linetype = \"\")\n\n\n\n# Finally, we want to visualize the population estimates. \n# In this case, we will be estimated the 2030 population.\n# 3. Population Estimates                                                       \n\n# Calculate AAAC for each geography.\n# AAAC = 2020 population - 2000 population / 20\n# AKA. AAAC = population - population / time\npopulation &lt;- population %&gt;%\n  group_by(NAME) %&gt;%\n  mutate(AAAC = (pop[year == 2020] - pop[year == 2000]) / 20)\n\n# Create a new data frame for the projected population in 2030.\nproj_2030 &lt;- population %&gt;%\n  filter(year == 2020) %&gt;%\n  mutate(year = 2030, pop = pop + (AAAC*10))\n\n# Combine the original data frame and the projected population data for 2030.\npopulation &lt;- bind_rows(population, proj_2030)\n\n# Remove the AAAC column.\npopulation &lt;- population %&gt;%\n  select(-AAAC)\n\n# Add a new column specifying if the population is actual or a projection.\npopulation &lt;- population %&gt;% \n  mutate(type = if_else(year == 2030, \"Projection\", \"Actual\"))\n\n\n# Plot the actual and projected total population from 2000 to 2030               PLOT \npopulation[population$NAME %in% c(\"Grundy Center\", \"Independence\", \"New Hampton\"), ] %&gt;% \n  ggplot(aes(x = year, y = pop, group = NAME, linetype = NAME)) +\n  geom_line(linewidth = 1)+\n  geom_point(aes(color = type), size = 2)+\n  geom_text(aes(label = scales::comma(round(pop))),\n            vjust = -1)+\n  theme_fivethirtyeight()+\n  scale_y_continuous(labels = scales::comma,\n                     limits = c(2500,6500))+\n  scale_x_continuous(limits = c(1998,2032),\n                     labels = c(\"2000\",\"2010\",\"2020\", \"2030 Est.\"))+\n  theme(legend.position = \"bottom\")+\n  labs(x = \"\",\n       color = \"\",\n       linetype = \"\",\n       title = \"Total Population\",\n       caption = \"2030 Population Estimated with AAAC\\nVariables: P1_001N and P001001\",\n       subtitle = \"2000-2020 Decennial Census\")\n\n\n\n\n\n\n\n\n# Median Income\n\n# Getting median income data from the 5-Year American Community Survey. \n# The median income variable is \"B19013_001.\"\n\n# Create an object called \"years\" that lists the years you want to pull data from. \n# We want all of the years the ACS data is available. \nyears &lt;- 2009:2021\nnames(years) &lt;- years\n\n# Use get_acs() to pull median income data at the place level.\nplaceIncome &lt;- map_dfr(years, ~{\n  get_acs(\n    geography = \"place\",\n    variables = c(\"median_income\" = \"B19013_001\"),\n    state = \"IA\",\n    year = .x,\n    survey = \"acs5\",\n    output = \"wide\"\n  )\n}, .id = \"year\") \n\n# Remove the \" city, Iowa|, Iowa\" from the end of the place names.\nplaceIncome &lt;- placeIncome %&gt;% \n  mutate(NAME = str_remove(NAME, \" city, Iowa|, Iowa\"))\n\n# Filter placeIncome for desired cities.\n# Add a geography column.\nplaceIncome &lt;- placeIncome %&gt;%\n  filter(NAME %in% c(\"Grundy Center\", \"Independence\", \"New Hampton\")) %&gt;% \n  mutate(geography = \"Place\")\n\n\n# Use get_acs() to pull median income data at the state level.\nstateIncome &lt;- map_dfr(years, ~{\n  get_acs(\n    geography = \"state\",\n    variables = c(\"median_income\" = \"B19013_001\"),\n    state = \"IA\",\n    year = .x,\n    survey = \"acs5\",\n    output = \"wide\"\n  )\n}, .id = \"year\") \n\n# Add a geography column. \nstateIncome &lt;- stateIncome %&gt;% \n  mutate(geography = \"State\")\n\n\n# Use get_acs() to pull median income data at the regional level.\nregionIncome &lt;- map_dfr(years, ~{\n  get_acs(\n    geography = \"region\",\n    variables = c(\"median_income\" = \"B19013_001\"),\n    year = .x,\n    survey = \"acs5\",\n    output = \"wide\"\n  )\n}, .id = \"year\") \n\n# Remove the \" Region\" from the end of the region names.\nregionIncome &lt;- regionIncome %&gt;% \n  mutate(NAME = str_remove(NAME, \" Region\"))\n\n# Filter regionIncome for Midwest.\n# Add a geography column.\nregionIncome &lt;- regionIncome %&gt;%\n  filter(NAME %in% \"Midwest\") %&gt;% \n  mutate(geography = \"Region\")\n\n\n# Use get_acs() to pull median income data at the national level.\nnationIncome &lt;- map_dfr(years, ~{\n  get_acs(\n    geography = \"us\",\n    variables = c(\"median_income\" = \"B19013_001\"),\n    year = .x,\n    survey = \"acs5\",\n    output = \"wide\"\n  )\n}, .id = \"year\")\n\n# Add a geography column.\nnationIncome &lt;- nationIncome %&gt;% \n  mutate(geography = \"Nation\")\n\n# Bind all geographies together with bind_rows().\nincome &lt;- nationIncome %&gt;% \n  bind_rows(regionIncome, stateIncome, placeIncome)\n\n# Add a new column specifying if the geography is a nation, region, state, or place. \nincome &lt;- income %&gt;% \n  mutate(grouping = ifelse(NAME %in% c(\"United States\", \"Midwest\", \"Iowa\"), \"Contextual Area\", NAME))\n\n# Create three separate plots for Grundy Center, Independence and New Hampton.\n# Combine plots together using patchwork library. \n#install.packages(\"patchwork\")\nlibrary(patchwork)\n\n# Plot the median income for Grundy Center and its contextual geographies.       PLOT\nplot1 &lt;- income[income$NAME %in% c(\"Grundy Center\", \"United States\", \"Midwest\", \"Iowa\"), ] %&gt;% \n  ggplot(aes(x = year, y = median_incomeE, group = NAME)) +\n  geom_ribbon(aes(ymax = median_incomeE + median_incomeM, ymin = median_incomeE - median_incomeM, fill = geography),\n              alpha = 0.3) + \n  geom_line(aes(color = geography), linewidth = 1)+\n  theme_fivethirtyeight()+\n  scale_y_continuous(labels = label_dollar(scale = .001, suffix = \"k\"),\n                     limits = c(32250,80000))+\n  theme(legend.position = \"none\", \n        axis.text.x = element_text(angle = 45, hjust = 1)) +\n  labs(x = \"\",\n       color = \"\",\n       linetype = \"\",\n       subtitle = \"2009-2021 5-Year ACS Estimates\\nGrundy Center\",\n       fill = \"\",\n       title = \"Median Income\") \n\n# Plot the median income for Independence and its contextual geographies.        PLOT \nplot2 &lt;- income[income$NAME %in% c(\"Independence\", \"United States\", \"Midwest\", \"Iowa\"), ] %&gt;% \n  ggplot(aes(x = year, y = median_incomeE, group = NAME)) +\n  geom_ribbon(aes(ymax = median_incomeE + median_incomeM, ymin = median_incomeE - median_incomeM, fill = geography),\n              alpha = 0.3) + \n  geom_line(aes(color = geography), linewidth = 1)+\n  theme_fivethirtyeight()+\n  scale_y_continuous(labels = label_dollar(scale = .001, suffix = \"k\"),\n                     limits = c(32250,80000))+\n  theme(legend.position = \"none\", axis.text.x = element_text(angle = 45, hjust = 1))+\n  labs(x = \"\",\n       color = \"\",\n       linetype = \"\",\n       subtitle = \"\\nIndependence\",\n       caption = \"\",\n       fill = \"\")\n\n# Plot the median income for New Hampton and its contextual geographies.         PLOT \nplot3 &lt;- income[income$NAME %in% c(\"New Hampton\", \"United States\", \"Midwest\", \"Iowa\"), ] %&gt;% \n  ggplot(aes(x = year, y = median_incomeE, group = NAME)) +\n  geom_ribbon(aes(ymax = median_incomeE + median_incomeM, ymin = median_incomeE - median_incomeM, fill = geography),\n              alpha = 0.3) + \n  geom_line(aes(color = geography), linewidth = 1)+\n  theme_fivethirtyeight()+\n  scale_y_continuous(labels = label_dollar(scale = .001, suffix = \"k\"),\n                     limits = c(32250,80000))+\n  theme(legend.position = \"bottom\",\n        axis.text.x = element_text(angle = 45, hjust = 1))+\n  labs(x = \"\",\n       color = \"\",\n       linetype = \"\",\n       subtitle = \"\\nNew Hampton\",\n       fill = \"\",\n       caption = \"Shaded area represents margin of error around the ACS estimate\\nVariable: B19013_001\")\n\n# Combine plots. \ncombined_plots &lt;- wrap_plots(plot1, plot2, plot3)\n\n\n\n\n\n# House Age                                                               \n\n# Want to plot Year Built data as percentages to standardize that data over different geography sizes.\n# Get Year Built data and Total Structure data from 2021 5-year American Community Survey (ACS) for all places in Iowa.\nplaceAge &lt;- get_acs(\n  geography = \"place\", \n  state = \"IA\", \n  variables = c(\"2020 or later\" = \"B25034_002\", \n                \"2010 to 2019\" = \"B25034_003\", \n                \"2000 to 2009\" = \"B25034_004\",\n                \"1990 to 1999\" = \"B25034_005\",\n                \"1980 to 1989\" = \"B25034_006\",\n                \"1970 to 1979\" = \"B25034_007\",\n                \"1960 to 1969\" = \"B25034_008\",\n                \"1950 to 1959\" = \"B25034_009\",\n                \"1940 to 1949\" = \"B25034_010\",\n                \"1939 or earlier\" = \"B25034_011\",\n                \"total\" = \"B25034_001\"), \n  year = 2021)\n# Filter for desired cities. \nplaceAge &lt;- placeAge %&gt;% \n  filter(NAME %in% c(\"Grundy Center city, Iowa\", \"Independence city, Iowa\", \"New Hampton city, Iowa\"))\n# Remove \" city, Iowa\" using str_remove().\nplaceAge &lt;- placeAge %&gt;% \n  mutate(NAME = str_remove(NAME, \"city, Iowa\"))\n# Group the house age data frame by NAME and calculate the percent by dividing the estimate value by the total value. \nplaceAge &lt;- placeAge %&gt;% \n  group_by(NAME) %&gt;% \n  mutate(percent = estimate/ first(estimate)) %&gt;% \n  filter(variable != \"total\") # Removes rows containing the total.\n\n# Get Year Built data and Total Structure data from 2021 5-year American Community Survey (ACS) for Iowa.\nstateAge &lt;- get_acs(\n  geography = \"state\", \n  state = \"IA\", \n  variables = c(\"2020 or later\" = \"B25034_002\", \n                \"2010 to 2019\" = \"B25034_003\", \n                \"2000 to 2009\" = \"B25034_004\",\n                \"1990 to 1999\" = \"B25034_005\",\n                \"1980 to 1989\" = \"B25034_006\",\n                \"1970 to 1979\" = \"B25034_007\",\n                \"1960 to 1969\" = \"B25034_008\",\n                \"1950 to 1959\" = \"B25034_009\",\n                \"1940 to 1949\" = \"B25034_010\",\n                \"1939 or earlier\" = \"B25034_011\",\n                \"total\" = \"B25034_001\"), \n  year = 2021)\n# Calculate the percent by dividing the estimate value by the total value. \nstateAge &lt;- stateAge %&gt;% \n  mutate(percent = estimate/ first(estimate)) %&gt;% \n  filter(variable != \"total\") # Removes rows containing the total.\n\n# Get Year Built data and Total Structure data from 2021 5-year American Community Survey (ACS) for the Midwest.\nregionAge &lt;- get_acs(\n  geography = \"region\", \n  variables = c(\"2020 or later\" = \"B25034_002\", \n                \"2010 to 2019\" = \"B25034_003\", \n                \"2000 to 2009\" = \"B25034_004\",\n                \"1990 to 1999\" = \"B25034_005\",\n                \"1980 to 1989\" = \"B25034_006\",\n                \"1970 to 1979\" = \"B25034_007\",\n                \"1960 to 1969\" = \"B25034_008\",\n                \"1950 to 1959\" = \"B25034_009\",\n                \"1940 to 1949\" = \"B25034_010\",\n                \"1939 or earlier\" = \"B25034_011\",\n                \"total\" = \"B25034_001\"), \n  year = 2021)\n# Filter for desired cities. \nregionAge &lt;- regionAge %&gt;% \n  filter(NAME == \"Midwest Region\")\n# Remove \" city, Iowa\" using str_remove().\nregionAge &lt;- regionAge %&gt;% \n  mutate(NAME = str_remove(NAME, \" Region\"))\n# Group the house age data frame by NAME and calculate the percent by dividing the estimate value by the total value. \nregionAge &lt;- regionAge %&gt;% \n  mutate(percent = estimate/ first(estimate)) %&gt;% \n  filter(variable != \"total\") # Removes rows containing the total.\n\n# Get Year Built data and Total Structure data from 2021 5-year American Community Survey (ACS) for the United States.\nnationAge &lt;- get_acs(\n  geography = \"us\", \n  variables = c(\"2020 or later\" = \"B25034_002\", \n                \"2010 to 2019\" = \"B25034_003\", \n                \"2000 to 2009\" = \"B25034_004\",\n                \"1990 to 1999\" = \"B25034_005\",\n                \"1980 to 1989\" = \"B25034_006\",\n                \"1970 to 1979\" = \"B25034_007\",\n                \"1960 to 1969\" = \"B25034_008\",\n                \"1950 to 1959\" = \"B25034_009\",\n                \"1940 to 1949\" = \"B25034_010\",\n                \"1939 or earlier\" = \"B25034_011\",\n                \"total\" = \"B25034_001\"), \n  year = 2021)\n# Calculate the percent by dividing the estimate value by the total value. \nnationAge &lt;- nationAge %&gt;% \n  mutate(percent = estimate/ first(estimate)) %&gt;% \n  filter(variable != \"total\") # Removes rows containing the total.\n\n# Bind contextual data together using bind_rows().\ncontextAge &lt;- stateAge %&gt;% \n  bind_rows(regionAge, nationAge)\n\n# Plot the Year Built data.                                                      PLOT\n# Group by name. Set geom_col() position to dodge to get the data displayed side by side. \nhouse_age &lt;- ggplot() +\n  geom_line(data = contextAge, aes(x = variable, y = percent, group = NAME, linetype = NAME), linewidth = 1, alpha = .6) +\n  geom_col(data = placeAge, aes(x = variable, y = percent, group = NAME, fill = NAME), position = \"dodge\", alpha = .9) +\n  scale_y_continuous(labels = scales::percent) +\n  theme_fivethirtyeight() +\n  theme(legend.position = \"none\") +\n  labs(title = \"Year Structure Built\",\n       subtitle = \"2017-2021 5-Year ACS Estimates\",\n       x = \"\",\n       y = \"ACS estimate\",\n       fill = \"\",\n       linetype = \"\")+\n  #  caption = \"Variables: B25034_002, B25034_003, B25034_004, B25034_005, B25034_006,\\nB25034_007, B25034_008, B25034_009,B25034_010, B25034_011, B25034_001\")+\n  theme(axis.text.x = element_text(angle = 30, hjust = 1))\n\n\n# Median Home Value by Year Structure Built                                \n\n# Get data from 2021 5-year American Community Survey for all places in Iowa.\nplaceValueAge &lt;- get_acs(\n  geography = \"place\", \n  state = \"IA\", \n  variables = c(\"2020 or later\" = \"B25107_002\", \n                \"2010 to 2019\" = \"B25107_003\", \n                \"2000 to 2009\" = \"B25107_004\",\n                \"1990 to 1999\" = \"B25107_005\",\n                \"1980 to 1989\" = \"B25107_006\",\n                \"1970 to 1979\" = \"B25107_007\",\n                \"1960 to 1969\" = \"B25107_008\",\n                \"1950 to 1959\" = \"B25107_009\",\n                \"1940 to 1949\" = \"B25107_010\",\n                \"1939 or earlier\" = \"B25107_011\"), \n  year = 2021)\n# Filter for desired cities. \nplaceValueAge &lt;- placeValueAge %&gt;% \n  filter(NAME %in% c(\"Grundy Center city, Iowa\", \"Independence city, Iowa\", \"New Hampton city, Iowa\")) %&gt;% \n  mutate(NAME = str_remove(NAME, \" city, Iowa\"))\n\n# Get data from 2021 5-year American Community Survey for Iowa.\nstateValueAge &lt;- get_acs(\n  geography = \"state\", \n  state = \"IA\", \n  variables = c(\"2020 or later\" = \"B25107_002\", \n                \"2010 to 2019\" = \"B25107_003\", \n                \"2000 to 2009\" = \"B25107_004\",\n                \"1990 to 1999\" = \"B25107_005\",\n                \"1980 to 1989\" = \"B25107_006\",\n                \"1970 to 1979\" = \"B25107_007\",\n                \"1960 to 1969\" = \"B25107_008\",\n                \"1950 to 1959\" = \"B25107_009\",\n                \"1940 to 1949\" = \"B25107_010\",\n                \"1939 or earlier\" = \"B25107_011\"), \n  year = 2021)\n\n# Get data from 2021 5-year American Community Survey for the Midwest.\nregionValueAge &lt;- get_acs(\n  geography = \"region\", \n  variables = c(\"2020 or later\" = \"B25107_002\", \n                \"2010 to 2019\" = \"B25107_003\", \n                \"2000 to 2009\" = \"B25107_004\",\n                \"1990 to 1999\" = \"B25107_005\",\n                \"1980 to 1989\" = \"B25107_006\",\n                \"1970 to 1979\" = \"B25107_007\",\n                \"1960 to 1969\" = \"B25107_008\",\n                \"1950 to 1959\" = \"B25107_009\",\n                \"1940 to 1949\" = \"B25107_010\",\n                \"1939 or earlier\" = \"B25107_011\"), \n  year = 2021)\n# Filter for the Midwest. \nregionValueAge &lt;- regionValueAge %&gt;% \n  filter(NAME == \"Midwest Region\") %&gt;% \n  mutate(NAME = str_remove(NAME, \" Region\"))\n\n# Get data from 2021 5-year American Community Survey for the United States.\nnationValueAge &lt;- get_acs(\n  geography = \"us\", \n  variables = c(\"2020 or later\" = \"B25107_002\", \n                \"2010 to 2019\" = \"B25107_003\", \n                \"2000 to 2009\" = \"B25107_004\",\n                \"1990 to 1999\" = \"B25107_005\",\n                \"1980 to 1989\" = \"B25107_006\",\n                \"1970 to 1979\" = \"B25107_007\",\n                \"1960 to 1969\" = \"B25107_008\",\n                \"1950 to 1959\" = \"B25107_009\",\n                \"1940 to 1949\" = \"B25107_010\",\n                \"1939 or earlier\" = \"B25107_011\"), \n  year = 2021)\n\n# Join all geographies.\ncontextValueAge &lt;- stateValueAge %&gt;% \n  bind_rows(regionValueAge, nationValueAge)\n\n# plot median home value by year structure built                                  PLOT\nhouse_value_by_year &lt;- ggplot() +\n  geom_line(data = contextValueAge, aes(x = variable, y = estimate, group = NAME, linetype = NAME), linewidth = 1, alpha = .6) +\n  geom_col(data = placeValueAge, aes(x = variable, y = estimate, group = NAME, fill = NAME), position = \"dodge\", alpha = .9) +\n  scale_y_continuous(labels = scales::dollar) +\n  theme_fivethirtyeight() +\n  labs(title = \"Median Home Value by Year Structure Built\",\n       subtitle = \"2017-2021 5-Year ACS Estimates\",\n       x = \"\",\n       y = \"ACS estimate\",\n       fill = \"\",\n       linetype = \"\",\n       caption = \"Variables: B25034_002, B25034_003, B25034_004, B25034_005, B25034_006,\\nB25034_007, B25034_008, B25034_009,B25034_010, B25034_011, B25034_001\") +\n  theme(axis.text.x = element_text(angle = 30, hjust = 1))\n\n#Use patchwork library to parse together year built and median value by year built plots.\n\nlibrary(patchwork)\n\nvalue_and_year_built &lt;- house_age +house_value_by_year +\n  plot_layout(ncol = 1)\n\n\n\n\n\n# Median House Value                                                         \n\n# Getting housing value data from the 5-year 2020 American Community Survey.\n# Specify county for just Chickasaw, Grundy, and Buchanan County.\n# The API Code for median home value is \"B25077_001.\"\nhousing_val &lt;- get_acs(\n  geography = \"tract\", \n  variables = \"B25077_001\", \n  state = \"IA\", \n  county = c(\"Chickasaw\",\"Grundy\",\"Buchanan\"\n  ),\n  year = 2020\n)\n# Separate the median home value data into three separate geographies: tract, county, and state.\nhousing_val2 &lt;- separate(\n  housing_val, \n  NAME, \n  into = c(\"tract\", \"county\", \"state\"), \n  sep = \", \"\n)  \n\n# Filter median home value data by census tract. \n# The city of Independence falls into two census tracts: 9505 and 9504.\n# Grundy Center is in tract 9603.\n# New Hampton is in tract 704.\n# Add a new column called \"city\" with the associated city name. \nind_house_val &lt;- housing_val2 %&gt;% \n  filter(tract == c(\"Census Tract 9505\", \"Census Tract 9504\")) %&gt;% \n  mutate(city = \"Independence\")\nhampton_house_val &lt;- housing_val2 %&gt;% \n  filter(tract == \"Census Tract 704\") %&gt;% \n  mutate(city = \"New Hampton\")\ngrundy_house_val &lt;- housing_val2 %&gt;% \n  filter(tract == \"Census Tract 9603\") %&gt;% \n  mutate(city = \"Grundy Center\")\n\n# Bind individual data frames together with bind_rows().\ncities_house_val &lt;- ind_house_val %&gt;% \n  bind_rows(hampton_house_val,grundy_house_val)\n\n# Use the summarize function to find the minimum, maximum, median and mean of the median home value estimates. \ncities_house_val %&gt;%\n  group_by(city) %&gt;%\n  summarize(min = min(estimate, na.rm = TRUE), \n            mean = mean(estimate, na.rm = TRUE), \n            median = median(estimate, na.rm = TRUE), \n            max = max(estimate, na.rm = TRUE)) \n\n# A tibble: 3 x 5\n  city             min   mean median    max\n  &lt;chr&gt;          &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 Grundy Center 135900 135900 135900 135900\n2 Independence  133200 136400 136400 139600\n3 New Hampton   117500 117500 117500 117500\n\n# Cannot visualize cities_house_val using this ggplot method because Grundy Center and New Hampton only have one value.\n# Plot housing value by county instead.\n# Add in a point that displays the median for each city from the 2020 5-Year ACS.\nhousing_val3 &lt;- get_acs(\n  geography = \"place\", \n  variables = \"B25077_001\", \n  state = \"IA\",\n  year = 2020) %&gt;% \n  filter(NAME %in% c(\"Grundy Center city, Iowa\",\"New Hampton city, Iowa\", \"Independence city, Iowa\"))\n\n# grundy center = $130,600\n# new hampton = $112,200\n# independence = $129,900\n\n# Create a density plot for median home value.                                   PLOT\nggplot(housing_val2, aes(x = estimate, fill = county)) + \n  geom_density(alpha = 0.3, linewidth = 1) +\n  geom_point(aes(y = 0.00002074, x = 112200), size = 2) + # New Hampton\n  geom_point(aes(x = 129900, y = .00001405), size = 2) + # Independence\n  geom_point(aes(x = 130600, y = .0000227), size = 2) + # Grundy Center\n  geom_text(aes(y = 0.00002074, x = 112200, label = \"New Hampton\\n$112,200\"), hjust = -.1, vjust = 1) +\n  geom_text(aes(x = 129900, y = .00001405, label = \"Independence\\n$129,900\"), hjust = -.1, vjust = 1) +\n  geom_text(aes(x = 130600, y = .0000227, label = \"Grundy Center\\n$130,600\"), hjust = 1.1, vjust = -.15) +\n  labs(title = \"Median House Values by Census Tract\",\n       subtitle = \"2016-2020 5-Year ACS Estimates\",\n       y = \"\",\n       x = \"Median House Value\",\n       caption = \"Points represent median house value for each city\\nVariable: B25077_001\",\n       fill = \"\")+\n  scale_x_continuous(labels = dollar_format()) +\n  scale_y_continuous(labels = scales::comma,\n                     limits = c(0,.000026))+\n  theme_fivethirtyeight()\n\n\n\n# Now, want to plot all available data for median home value. \n# Getting median home value data from the 5-Year American Community Survey. \n# The median home value code is \"B25077_001.\"\n\n# Create an object called \"years\" that lists the years you want to pull data from. \n# We want all of the years the ACS data is available. \nyears &lt;- 2009:2021\nnames(years) &lt;- years\n\n# Use get_acs() to pull median home value data at the place level.\nplaceValue &lt;- map_dfr(years, ~{\n  get_acs(\n    geography = \"place\",\n    variables = c(\"median_value\" = \"B25077_001\"),\n    state = \"IA\",\n    year = .x,\n    survey = \"acs5\",\n    output = \"wide\"\n  )\n}, .id = \"year\") \n\n# Remove the \" city, Iowa|, Iowa\" from the end of the place names.\nplaceValue &lt;- placeValue %&gt;% \n  mutate(NAME = str_remove(NAME, \" city, Iowa|, Iowa\"))\n\n# Filter placeValue for desired cities.\n# Add a geography column.\nplaceValue &lt;- placeValue %&gt;%\n  filter(NAME %in% c(\"Grundy Center\", \"Independence\", \"New Hampton\")) %&gt;% \n  mutate(geography = \"Place\")\n\n\n# Use get_acs() to pull median home value data at the state level.\nstateValue &lt;- map_dfr(years, ~{\n  get_acs(\n    geography = \"state\",\n    variables = c(\"median_value\" = \"B25077_001\"),\n    state = \"IA\",\n    year = .x,\n    survey = \"acs5\",\n    output = \"wide\"\n  )\n}, .id = \"year\") \n\n# Add a geography column. \nstateValue &lt;- stateValue %&gt;% \n  mutate(geography = \"State\")\n\n\n# Use get_acs() to pull median home value data at the regional level.\nregionValue &lt;- map_dfr(years, ~{\n  get_acs(\n    geography = \"region\",\n    variables = c(\"median_value\" = \"B25077_001\"),\n    year = .x,\n    survey = \"acs5\",\n    output = \"wide\"\n  )\n}, .id = \"year\") \n\n# Remove the \" Region\" from the end of the region names\nregionValue&lt;- regionValue %&gt;% \n  mutate(NAME = str_remove(NAME, \" Region\"))\n\n# Filter regionValue for Midwest.\n# Add a geography column.\nregionValue &lt;- regionValue %&gt;%\n  filter(NAME %in% \"Midwest\") %&gt;% \n  mutate(geography = \"Region\")\n\n\n# Use get_acs() to pull median home value data at the national level.\nnationValue &lt;- map_dfr(years, ~{\n  get_acs(\n    geography = \"us\",\n    variables = c(\"median_value\" = \"B25077_001\"),\n    year = .x,\n    survey = \"acs5\",\n    output = \"wide\"\n  )\n}, .id = \"year\")\n\n# Add a geography column.\nnationValue &lt;- nationValue %&gt;% \n  mutate(geography = \"Nation\")\n\n# Bind all geographies together with bind_rows().\nvalue &lt;- nationValue %&gt;% \n  bind_rows(regionValue, stateValue, placeValue)\n\n# Add a new column specifying if the geography is a nation, region, state, or place. \nvalue &lt;- value %&gt;% \n  mutate(grouping = ifelse(NAME %in% c(\"United States\", \"Midwest\", \"Iowa\"), \"Contextual Area\", NAME))\n\n# Create three separate plots for Grundy Center, Independence and New Hampton.\n# Combine plots together using patchwork library. \n#install.packages(\"patchwork\")\nlibrary(patchwork)\n\n# Plot the median home value for Grundy Center and its contextual geographies.       PLOT\nplot1 &lt;- value[value$NAME %in% c(\"Grundy Center\", \"United States\", \"Midwest\", \"Iowa\"), ] %&gt;% \n  ggplot(aes(x = year, y = median_valueE, group = NAME)) +\n  geom_ribbon(aes(ymax = median_valueE + median_valueM, ymin = median_valueE - median_valueM, fill = geography),\n              alpha = 0.3) + \n  geom_line(aes(color = geography), linewidth = 1)+\n  theme_fivethirtyeight()+\n  scale_y_continuous(labels = label_dollar(scale = .001, suffix = \"k\"),\n                     limits = c(85000,250000))+\n  theme(legend.position = \"none\",\n        axis.text.x = element_text(angle = 45, hjust = 1))+\n  labs(x = \"\",\n       color = \"\",\n       linetype = \"\",\n       subtitle = \"2009-2021 5-Year ACS Estimates\\nGrundy Center\",\n       fill = \"\",\n       title = \"Median Home Value\")\n\n# Plot the median home value for Independence and its contextual geographies.        PLOT \nplot2 &lt;- value[value$NAME %in% c(\"Independence\", \"United States\", \"Midwest\", \"Iowa\"), ] %&gt;% \n  ggplot(aes(x = year, y = median_valueE, group = NAME)) +\n  geom_ribbon(aes(ymax = median_valueE + median_valueM, ymin = median_valueE - median_valueM, fill = geography),\n              alpha = 0.3) + \n  geom_line(aes(color = geography), linewidth = 1)+\n  theme_fivethirtyeight()+\n  scale_y_continuous(labels = label_dollar(scale = .001, suffix = \"k\"),\n                     limits = c(85000,250000))+\n  theme(legend.position = \"none\",\n        axis.text.x = element_text(angle = 45, hjust = 1))+\n  labs(x = \"\",\n       color = \"\",\n       linetype = \"\",\n       subtitle = \"\\nIndependence\",\n       fill = \"\")\n\n# Plot the median value for New Hampton and its contextual geographies.         PLOT \nplot3 &lt;- value[value$NAME %in% c(\"New Hampton\", \"United States\", \"Midwest\", \"Iowa\"), ] %&gt;% \n  ggplot(aes(x = year, y = median_valueE, group = NAME)) +\n  geom_ribbon(aes(ymax = median_valueE + median_valueM, ymin = median_valueE - median_valueM, fill = geography),\n              alpha = 0.3) + \n  geom_line(aes(color = geography), linewidth = 1)+\n  theme_fivethirtyeight()+\n  scale_y_continuous(labels = label_dollar(scale = .001, suffix = \"k\"),\n                     limits = c(85000,250000))+\n  theme(legend.position = \"bottom\",\n        axis.text.x = element_text(angle = 45, hjust = 1))+\n  labs(x = \"\",\n       color = \"\",\n       linetype = \"\",\n       subtitle = \"\\nNew Hampton\",\n       fill = \"\",\n       caption = \"Shaded area represents margin of error around the ACS estimate\\nVariable: B25077_001\")\n\n# Combine plots. \ncombined_plots1 &lt;- wrap_plots(plot1, plot2, plot3)\n\n\n# Plot just the city median home value data.                                     PLOT\nvalue[value$NAME %in% c(\"Grundy Center\", \"New Hampton\", \"Independence\"), ] %&gt;% \n  ggplot(aes(x = year, y = median_valueE, group = NAME, fill = NAME)) + \n  geom_ribbon(aes(ymax = median_valueE + median_valueM, ymin = median_valueE - median_valueM),\n              alpha = 0.3) + \n  geom_line(aes(color = NAME), linewidth = 1) + \n  theme_fivethirtyeight() + \n  scale_y_continuous(labels = label_dollar(scale = .001, suffix = \"k\")) +\n  labs(title = \"Median Home Value\",\n       subtitle = \"2009-2021 5-Year ACS Estimates\",\n       x = \"Year\",\n       y = \"ACS estimate\",\n       fill = \"\",\n       color = \"\",\n       caption = \"Shaded area represents margin of error around the ACS estimate\\nVariable: B25077_001\") +\n  geom_text(aes(x = \"2021\", y =137100, label = \"$137,000\"), vjust = -1)+\n  geom_text(aes(x = \"2021\", y = 133300, label = \"$133,300\"), vjust = 2) +\n  geom_text(aes(x = \"2021\", y = 122600, label = \"$122,600\"), vjust = -1)\n\n\n\n\n\n\n\n```{r}, warning = FALSE, message = FALSE} # Home Ownership, Rental, and Vacancy Rates"
  },
  {
    "objectID": "posts/Week_8/Week_8.html#demographic-profile",
    "href": "posts/Week_8/Week_8.html#demographic-profile",
    "title": "Week Eight of Data Science for the Public Good",
    "section": "",
    "text": "I began editing the Demographic Profile I made two weeks ago this week. I went back and added comments to my code, added regional and national context to the plots, and started converting some of the data into percentages. Below is the work I completed.\n\n\n\nlibrary(tidyverse)\nlibrary(tidycensus)\nlibrary(ggthemes)\nlibrary(scales)\n\n\n### The first thing we want to visualize is population change.\n\n# 1. Population Change                                                          \n\n# Define the variables before getting the data.\n# The Census API code for total population for 2000 and 2010 is P001001.\npop00 &lt;- c(\"pop\" = \"P001001\")\npop10 &lt;- c(\"pop\" = \"P001001\")\n# The API code for total population changed for 2020.\n# The Census API code for total population is P1_001N for 2020. \npop20 &lt;- c(\"pop\" = \"P1_001N\")\n\n###\n## National Context: nationPop\n# Getting 2000 total population data for the USA.\nnation00 &lt;- get_decennial(geography = \"us\",\n                          year = 2000,\n                          variable = pop00,\n                          output = \"wide\") %&gt;% \n  mutate(year = 2000)\n# Getting 2010 total population data for the USA.\nnation10 &lt;- get_decennial(geography = \"us\",\n                          year = 2010,\n                          variable = pop10,\n                          output = \"wide\") %&gt;% \n  mutate(year = 2010)\n# Getting 2020 total population data for the USA.\nnation20 &lt;- get_decennial(geography = \"us\",\n                          year = 2020,\n                          variable = pop20,\n                          output = \"wide\") %&gt;% \n  mutate(year = 2020)\n# Bind the years together using bind_rows to create data frame for national context. \nnationPop &lt;- nation20 %&gt;% \n  bind_rows(nation10,nation00) %&gt;% \n  mutate(geography = \"Nation\") \n\n\n###\n## Regional Context: regionPop\n# Getting 2000 total population data from the Midwest.\nregion00 &lt;- get_decennial(geography = \"region\",\n                          year = 2000,\n                          variable = pop00,\n                          output = \"wide\") %&gt;% \n  mutate(year = 2000)\n# Getting 2010 total population data for the Midwest.\nregion10 &lt;- get_decennial(geography = \"region\",\n                          year = 2010,\n                          variable = pop10,\n                          output = \"wide\") %&gt;% \n  mutate(year = 2010)\n# Getting 2020 total population data for the Midwest.\nregion20 &lt;- get_decennial(geography = \"region\",\n                          year = 2020,\n                          variable = pop20,\n                          output = \"wide\") %&gt;% \n  mutate(year = 2020)\n# Bind the years together using bind_rows to create data frame for regional context. \n# Filter to keep just the Midwest Region. \nregionPop &lt;- region20 %&gt;% \n  bind_rows(region10,region00) %&gt;% \n  filter(NAME == \"Midwest Region\") %&gt;% \n  mutate(NAME = str_remove(NAME, \" Region\")) %&gt;% # Use str_remove() to remove \" Region\" from Midwest. \n  mutate(geography = \"Region\")\n\n\n###\n## State Context: statePop\n# Getting the 2000 total population data for the state of Iowa from the Decennial Census.\niowa00 &lt;- get_decennial(geography = \"state\",\n                        state = \"IA\",\n                        year = 2000,\n                        output = \"wide\",\n                        variable = pop00) %&gt;% \n  mutate(year = 2000)\n# Getting the 2010 total population data for the state of Iowa from the Decennial Census.\niowa10 &lt;- get_decennial(geography = \"state\",\n                        state = \"IA\",\n                        variable = pop10,\n                        year = 2010,\n                        output = \"wide\") %&gt;% \n  mutate(year = 2010)\n# Getting the 2020 total population data for the state of Iowa from the Decennial Census.\niowa20 &lt;- get_decennial(geography = \"state\",\n                        state = \"IA\",\n                        variable = pop20,\n                        year = 2020,\n                        output = \"wide\") %&gt;% \n  mutate(year = 2020)\n\n# Bind the years together using bind_rows to create data frame for state context. \nstatePop &lt;- iowa20 %&gt;% \n  bind_rows(iowa10,iowa00) %&gt;% \n  mutate(geography = \"State\")\n\n\n###\n## Places: \n# Getting 2000 total population data for all places in Iowa.\nplace00 &lt;- get_decennial(geography = \"place\",\n                         state = \"IA\",\n                         year = 2000,\n                         output = \"wide\",\n                         variables = pop00) %&gt;% \n  mutate(year = 2000)\nplace10 &lt;- get_decennial(geography = \"place\",\n                         state = \"IA\",\n                         year = 2010,\n                         output = \"wide\",\n                         variables = pop10) %&gt;% \n  mutate(year = 2010)\nplace20 &lt;- get_decennial(geography = \"place\",\n                         state = \"IA\",\n                         variable = pop20,\n                         year = 2020,\n                         output = \"wide\") %&gt;% \n  mutate(year = 2020)\n# Bind the years together using bind_rows() to create data frame for all places in Iowa. \nplacePop &lt;- place20 %&gt;% \n  bind_rows(place10,place00) %&gt;% \n  mutate(geography = \"Place\")\n\n# Filter for Independence, Grundy Center, and New Hampton. \nplacePop &lt;- placePop[placePop$NAME %in% c(\"Grundy Center city, Iowa\", \"Independence city, Iowa\", \"New Hampton city, Iowa\"), ] %&gt;% \n  mutate(NAME = str_remove(NAME, \" city, Iowa|, Iowa\")) # Use str_remove() to remove \"city, Iowa\" from behind the place names. \n\n# Combine nationPop, regionPop, statePop, and placePop using bind_rows().\npopulation &lt;- nationPop %&gt;% \n  bind_rows(regionPop,statePop,placePop)\n\n# Calculate the change in population.\npopulation &lt;- population %&gt;%\n  group_by(NAME) %&gt;%\n  arrange(year) %&gt;%\n  mutate(pop_change = pop - lag(pop)) \n\n\n\n\n# Start visualizing total population now that master data frame is created. \n\n\n# Plot the change in total population for Independence.                           PLOT\n# Filter population for Independence.\npopulation %&gt;% \n  filter(NAME == \"Independence\") %&gt;% \n  ggplot(aes(x = year, y = pop))+\n  geom_line()+\n  geom_point(size = 2)+\n  geom_text(aes(label = scales::comma(pop)), hjust = -.31)+\n  scale_y_continuous(label = scales::comma)+\n  scale_x_continuous(limits = c(1997, 2023),\n                     breaks = c(2000,2010,2020))+\n  theme_fivethirtyeight()+\n  theme(legend.position = \"bottom\")+\n  labs(title = \"Change in Total Population\",\n       subtitle = \"Independence, Iowa\",\n       y = \"Population\",\n       x = \"\",\n       color = \"\", \n       caption = \"2000-2020 Decennial Census\")\n\n\n\n# Plot the change in total population for New Hampton.                           PLOT\n# Filter population for New Hampton.\npopulation %&gt;% \n  filter(NAME == \"New Hampton\") %&gt;% \n  ggplot(aes(x = year, y = pop))+\n  geom_line()+\n  geom_point(size = 2)+\n  geom_text(aes(label = scales::comma(pop)),hjust = -.3)+ \n  scale_y_continuous(label = scales::comma)+\n  scale_x_continuous(limits = c(1997, 2023),\n                     breaks = c(2000,2010,2020))+\n  theme_fivethirtyeight()+\n  theme(legend.position = \"bottom\")+\n  labs(title = \"Change in Total Population\",\n       subtitle = \"New Hampton, Iowa\",\n       y = \"Population\",\n       x = \"\",\n       color = \"\", \n       caption = \"2000-2020 Decennial Census\")\n\n\n\n# Plot the change in total population Grundy Center.                              PLOT\n# Filter population for Grundy Center.\npopulation %&gt;% \n  filter(NAME == \"Grundy Center\") %&gt;% \n  ggplot(aes(x = year, y = pop))+\n  geom_line()+\n  geom_point(size = 2)+\n  geom_text(aes(label = scales::comma(pop)),hjust = -.3)+\n  scale_y_continuous(label = scales::comma)+\n  scale_x_continuous(limits = c(1997, 2023),\n                     breaks = c(2000,2010,2020))+\n  theme_fivethirtyeight()+\n  theme(legend.position = \"bottom\")+\n  labs(title = \"Change in Total Population\",\n       subtitle = \"Grundy Center, Iowa\",\n       y = \"Population\",\n       x = \"\",\n       color = \"\", \n       caption = \"2000-2020 Decennial Census\")\n\n\n\n# Plot total population for all cities.                                           PLOT    \n# Filter for the cities. \n# Assign the plot to an object.\npopulation[population$NAME %in% c(\"Grundy Center\", \"Independence\", \"New Hampton\"), ] %&gt;% \n  ggplot(aes(x = year, y = pop, group = NAME))+\n  geom_line(aes(color = NAME), linewidth = 1)+\n  geom_point(size = 2)+\n  geom_text(aes(label = scales::comma(pop_change)),vjust = -1)+\n  scale_y_continuous(label = scales::comma,\n                     limits = c(2500,6300))+\n  scale_x_continuous(limits = c(1998, 2022),\n                     breaks = c(2000,2010,2020))+\n  theme_fivethirtyeight()+\n  theme(legend.position = \"bottom\")+\n  labs(title = \"Change in Total Population\",\n       subtitle = \"2000-2020 Decennial Census\",\n       y = \"Population\",\n       x = \"\",\n       color = \"\", \n       caption = \"Variables: P1_001N and P001001\")\n\n\n\n## Plot change in total population with line type = NAME.                           PLOT\npopulation[population$NAME %in% c(\"Grundy Center\", \"Independence\", \"New Hampton\"), ] %&gt;% \n  ggplot(aes(x = year, y = pop, group = NAME, linetype = NAME))+\n  geom_line()+\n  geom_point(size = 2)+\n  geom_text(aes(label = scales::comma(pop)),vjust = -1)+  \n  scale_y_continuous(label = scales::comma,\n                     limits = c(2500,6500))+\n  scale_x_continuous(limits = c(1998, 2022),\n                     breaks = c(2000,2010,2020))+\n  theme_fivethirtyeight()+\n  theme(legend.position = \"bottom\")+\n  labs(title = \"Change in Total Population\",\n       subtitle = \"Comparison between Grundy Center, Independence,\\nand New Hampton\",\n       y = \"Population\",\n       x = \"\",\n       color = \"\", \n       linetype = \"\",\n       caption = \"2000-2020 Decennial Census\")\n\n\n\n# Plot total population for all geographies.                                      PLOT\n# Assign the plot to an object.\npopulation %&gt;% \n  ggplot(aes(x = year, y = pop, group = NAME)) +\n  geom_line(aes(linetype = geography, color = NAME), linewidth = 1)+\n  geom_point(size = 2)+\n  scale_y_log10(label = scales::comma) +\n  scale_x_continuous(limits = c(2000, 2020),\n                     breaks = c(2000,2010,2020))+\n  theme_fivethirtyeight()+\n  theme(legend.position = \"bottom\")+\n  labs(title = \"Change in Total Population\",\n       y = \"Population (log scale)\",\n       subtitle = \"2000-2020 Decennial Census\",\n       x = \"\",\n       color = \"\", \n       linetype = \"\",\n       caption = \"Variables: P1_001N and P001001\")\n\n\n\n# The next thing we want to visualize is the PERCENT CHANGE in population.\n# 2. Percent Population Change                                                  \n\n# Create anew column called prc_change.\n# Group by \"NAME\" so that the calculations occur individually for each place. \n# Percent change is calculated by subtracting year2 from year1 and dividing by year2. \npopulation &lt;- population %&gt;%\n  group_by(NAME) %&gt;%\n  mutate(prc_change = case_when(\n    year == 2000 ~ NA,\n    year == 2010 ~ (pop - lag(pop, n = 10, default = last(pop))) / lag(pop, n = 10, default = last(pop)),\n    year == 2020 ~ (pop - lag(pop, n = 20, default = last(pop))) / lag(pop, n = 20, default = last(pop))\n  ))\n\n# Create a grouping column in the population data\npopulation &lt;- population %&gt;%\n  mutate(grouping = ifelse(NAME %in% c(\"United States\", \"Midwest\", \"Iowa\"), \"Contextual Area\", \"Places\"))\n\n\n## Plot the percent change in population for all geographies.                    PLOT\n# Assign the plot to an object.\npopulation %&gt;% \n  ggplot(aes(x = year, y = prc_change, group = NAME)) +\n  geom_line(aes(color = NAME, linetype = grouping), linewidth = 1) +\n  geom_text(aes(x= 2020.65, y = .1777, label = \"17.77%\"), size = 3.5) +\n  geom_text(aes(x= 2020.65, y = .09023, label = \"9.02%\"), vjust = -.2, size = 3.5) +\n  geom_text(aes(x= 2020.65, y = .07132, label = \"7.13%\"), vjust = 1.2, size = 3.5) +\n  geom_text(aes(x= 2020.65, y = .0770416, label = \"7.70%\"), size = 3.5, vjust = -.000002) +\n  geom_text(aes(x= 2020.65, y = .0083139, label = \"0.83%\"), size = 3.5) +\n  geom_text(aes(x= 2020.65, y = -.053629, label = \"-5.36%\"), size = 3.5) +\n  geom_point(size = 2) +\n  scale_y_continuous(label = scales::percent) +\n  scale_x_continuous(breaks = c(2010, 2015,2020), limits = c(2010,2021)) +\n  theme_fivethirtyeight() +\n  theme(strip.text = element_text(face = \"bold\"))+\n  labs(title = \"Percent Change in Total Population\",\n       subtitle = \"2000-2020 Decennial Census\",\n       color = \"\",\n       caption = \"Variables: P1_001N and P001001\",\n       linetype = \"\") \n\n\n\n## Plot the percent change in total population for just the places.\n# Filter the population data frame for places. \n# Assign the plot to an object.\npopulation[population$NAME %in% c(\"Grundy Center\", \"Independence\", \"New Hampton\"), ] %&gt;% \n  ggplot(aes(x = year, y = prc_change, group = NAME)) +\n  geom_line(aes(color = NAME), linewidth = 1) +\n  geom_point(size = 2) +\n  geom_text(aes(label = scales::percent(prc_change)), hjust = .5,vjust = -.75 )+\n  scale_y_continuous(label = scales::percent, limits = c(-.06,.085)) +\n  scale_x_continuous(breaks = c(2010,2015, 2020), limits = c(2008, 2022)) +\n  theme_fivethirtyeight() +\n  theme(strip.text = element_text(face = \"bold\"),\n        legend.position = \"bottom\")+  # Align legend to the right\n  labs(title = \"Percent Change in Total Population\",\n       subtitle = \"2000-2020 Decennial Census\",\n       color = \"\",\n       caption = \"Variables: P1_001N and P001001\",\n       linetype = \"\")\n\n\n\n# Finally, we want to visualize the population estimates. \n# In this case, we will be estimated the 2030 population.\n# 3. Population Estimates                                                       \n\n# Calculate AAAC for each geography.\n# AAAC = 2020 population - 2000 population / 20\n# AKA. AAAC = population - population / time\npopulation &lt;- population %&gt;%\n  group_by(NAME) %&gt;%\n  mutate(AAAC = (pop[year == 2020] - pop[year == 2000]) / 20)\n\n# Create a new data frame for the projected population in 2030.\nproj_2030 &lt;- population %&gt;%\n  filter(year == 2020) %&gt;%\n  mutate(year = 2030, pop = pop + (AAAC*10))\n\n# Combine the original data frame and the projected population data for 2030.\npopulation &lt;- bind_rows(population, proj_2030)\n\n# Remove the AAAC column.\npopulation &lt;- population %&gt;%\n  select(-AAAC)\n\n# Add a new column specifying if the population is actual or a projection.\npopulation &lt;- population %&gt;% \n  mutate(type = if_else(year == 2030, \"Projection\", \"Actual\"))\n\n\n# Plot the actual and projected total population from 2000 to 2030               PLOT \npopulation[population$NAME %in% c(\"Grundy Center\", \"Independence\", \"New Hampton\"), ] %&gt;% \n  ggplot(aes(x = year, y = pop, group = NAME, linetype = NAME)) +\n  geom_line(linewidth = 1)+\n  geom_point(aes(color = type), size = 2)+\n  geom_text(aes(label = scales::comma(round(pop))),\n            vjust = -1)+\n  theme_fivethirtyeight()+\n  scale_y_continuous(labels = scales::comma,\n                     limits = c(2500,6500))+\n  scale_x_continuous(limits = c(1998,2032),\n                     labels = c(\"2000\",\"2010\",\"2020\", \"2030 Est.\"))+\n  theme(legend.position = \"bottom\")+\n  labs(x = \"\",\n       color = \"\",\n       linetype = \"\",\n       title = \"Total Population\",\n       caption = \"2030 Population Estimated with AAAC\\nVariables: P1_001N and P001001\",\n       subtitle = \"2000-2020 Decennial Census\")\n\n\n\n\n\n\n\n\n# Median Income\n\n# Getting median income data from the 5-Year American Community Survey. \n# The median income variable is \"B19013_001.\"\n\n# Create an object called \"years\" that lists the years you want to pull data from. \n# We want all of the years the ACS data is available. \nyears &lt;- 2009:2021\nnames(years) &lt;- years\n\n# Use get_acs() to pull median income data at the place level.\nplaceIncome &lt;- map_dfr(years, ~{\n  get_acs(\n    geography = \"place\",\n    variables = c(\"median_income\" = \"B19013_001\"),\n    state = \"IA\",\n    year = .x,\n    survey = \"acs5\",\n    output = \"wide\"\n  )\n}, .id = \"year\") \n\n# Remove the \" city, Iowa|, Iowa\" from the end of the place names.\nplaceIncome &lt;- placeIncome %&gt;% \n  mutate(NAME = str_remove(NAME, \" city, Iowa|, Iowa\"))\n\n# Filter placeIncome for desired cities.\n# Add a geography column.\nplaceIncome &lt;- placeIncome %&gt;%\n  filter(NAME %in% c(\"Grundy Center\", \"Independence\", \"New Hampton\")) %&gt;% \n  mutate(geography = \"Place\")\n\n\n# Use get_acs() to pull median income data at the state level.\nstateIncome &lt;- map_dfr(years, ~{\n  get_acs(\n    geography = \"state\",\n    variables = c(\"median_income\" = \"B19013_001\"),\n    state = \"IA\",\n    year = .x,\n    survey = \"acs5\",\n    output = \"wide\"\n  )\n}, .id = \"year\") \n\n# Add a geography column. \nstateIncome &lt;- stateIncome %&gt;% \n  mutate(geography = \"State\")\n\n\n# Use get_acs() to pull median income data at the regional level.\nregionIncome &lt;- map_dfr(years, ~{\n  get_acs(\n    geography = \"region\",\n    variables = c(\"median_income\" = \"B19013_001\"),\n    year = .x,\n    survey = \"acs5\",\n    output = \"wide\"\n  )\n}, .id = \"year\") \n\n# Remove the \" Region\" from the end of the region names.\nregionIncome &lt;- regionIncome %&gt;% \n  mutate(NAME = str_remove(NAME, \" Region\"))\n\n# Filter regionIncome for Midwest.\n# Add a geography column.\nregionIncome &lt;- regionIncome %&gt;%\n  filter(NAME %in% \"Midwest\") %&gt;% \n  mutate(geography = \"Region\")\n\n\n# Use get_acs() to pull median income data at the national level.\nnationIncome &lt;- map_dfr(years, ~{\n  get_acs(\n    geography = \"us\",\n    variables = c(\"median_income\" = \"B19013_001\"),\n    year = .x,\n    survey = \"acs5\",\n    output = \"wide\"\n  )\n}, .id = \"year\")\n\n# Add a geography column.\nnationIncome &lt;- nationIncome %&gt;% \n  mutate(geography = \"Nation\")\n\n# Bind all geographies together with bind_rows().\nincome &lt;- nationIncome %&gt;% \n  bind_rows(regionIncome, stateIncome, placeIncome)\n\n# Add a new column specifying if the geography is a nation, region, state, or place. \nincome &lt;- income %&gt;% \n  mutate(grouping = ifelse(NAME %in% c(\"United States\", \"Midwest\", \"Iowa\"), \"Contextual Area\", NAME))\n\n# Create three separate plots for Grundy Center, Independence and New Hampton.\n# Combine plots together using patchwork library. \n#install.packages(\"patchwork\")\nlibrary(patchwork)\n\n# Plot the median income for Grundy Center and its contextual geographies.       PLOT\nplot1 &lt;- income[income$NAME %in% c(\"Grundy Center\", \"United States\", \"Midwest\", \"Iowa\"), ] %&gt;% \n  ggplot(aes(x = year, y = median_incomeE, group = NAME)) +\n  geom_ribbon(aes(ymax = median_incomeE + median_incomeM, ymin = median_incomeE - median_incomeM, fill = geography),\n              alpha = 0.3) + \n  geom_line(aes(color = geography), linewidth = 1)+\n  theme_fivethirtyeight()+\n  scale_y_continuous(labels = label_dollar(scale = .001, suffix = \"k\"),\n                     limits = c(32250,80000))+\n  theme(legend.position = \"none\", \n        axis.text.x = element_text(angle = 45, hjust = 1)) +\n  labs(x = \"\",\n       color = \"\",\n       linetype = \"\",\n       subtitle = \"2009-2021 5-Year ACS Estimates\\nGrundy Center\",\n       fill = \"\",\n       title = \"Median Income\") \n\n# Plot the median income for Independence and its contextual geographies.        PLOT \nplot2 &lt;- income[income$NAME %in% c(\"Independence\", \"United States\", \"Midwest\", \"Iowa\"), ] %&gt;% \n  ggplot(aes(x = year, y = median_incomeE, group = NAME)) +\n  geom_ribbon(aes(ymax = median_incomeE + median_incomeM, ymin = median_incomeE - median_incomeM, fill = geography),\n              alpha = 0.3) + \n  geom_line(aes(color = geography), linewidth = 1)+\n  theme_fivethirtyeight()+\n  scale_y_continuous(labels = label_dollar(scale = .001, suffix = \"k\"),\n                     limits = c(32250,80000))+\n  theme(legend.position = \"none\", axis.text.x = element_text(angle = 45, hjust = 1))+\n  labs(x = \"\",\n       color = \"\",\n       linetype = \"\",\n       subtitle = \"\\nIndependence\",\n       caption = \"\",\n       fill = \"\")\n\n# Plot the median income for New Hampton and its contextual geographies.         PLOT \nplot3 &lt;- income[income$NAME %in% c(\"New Hampton\", \"United States\", \"Midwest\", \"Iowa\"), ] %&gt;% \n  ggplot(aes(x = year, y = median_incomeE, group = NAME)) +\n  geom_ribbon(aes(ymax = median_incomeE + median_incomeM, ymin = median_incomeE - median_incomeM, fill = geography),\n              alpha = 0.3) + \n  geom_line(aes(color = geography), linewidth = 1)+\n  theme_fivethirtyeight()+\n  scale_y_continuous(labels = label_dollar(scale = .001, suffix = \"k\"),\n                     limits = c(32250,80000))+\n  theme(legend.position = \"bottom\",\n        axis.text.x = element_text(angle = 45, hjust = 1))+\n  labs(x = \"\",\n       color = \"\",\n       linetype = \"\",\n       subtitle = \"\\nNew Hampton\",\n       fill = \"\",\n       caption = \"Shaded area represents margin of error around the ACS estimate\\nVariable: B19013_001\")\n\n# Combine plots. \ncombined_plots &lt;- wrap_plots(plot1, plot2, plot3)\n\n\n\n\n\n# House Age                                                               \n\n# Want to plot Year Built data as percentages to standardize that data over different geography sizes.\n# Get Year Built data and Total Structure data from 2021 5-year American Community Survey (ACS) for all places in Iowa.\nplaceAge &lt;- get_acs(\n  geography = \"place\", \n  state = \"IA\", \n  variables = c(\"2020 or later\" = \"B25034_002\", \n                \"2010 to 2019\" = \"B25034_003\", \n                \"2000 to 2009\" = \"B25034_004\",\n                \"1990 to 1999\" = \"B25034_005\",\n                \"1980 to 1989\" = \"B25034_006\",\n                \"1970 to 1979\" = \"B25034_007\",\n                \"1960 to 1969\" = \"B25034_008\",\n                \"1950 to 1959\" = \"B25034_009\",\n                \"1940 to 1949\" = \"B25034_010\",\n                \"1939 or earlier\" = \"B25034_011\",\n                \"total\" = \"B25034_001\"), \n  year = 2021)\n# Filter for desired cities. \nplaceAge &lt;- placeAge %&gt;% \n  filter(NAME %in% c(\"Grundy Center city, Iowa\", \"Independence city, Iowa\", \"New Hampton city, Iowa\"))\n# Remove \" city, Iowa\" using str_remove().\nplaceAge &lt;- placeAge %&gt;% \n  mutate(NAME = str_remove(NAME, \"city, Iowa\"))\n# Group the house age data frame by NAME and calculate the percent by dividing the estimate value by the total value. \nplaceAge &lt;- placeAge %&gt;% \n  group_by(NAME) %&gt;% \n  mutate(percent = estimate/ first(estimate)) %&gt;% \n  filter(variable != \"total\") # Removes rows containing the total.\n\n# Get Year Built data and Total Structure data from 2021 5-year American Community Survey (ACS) for Iowa.\nstateAge &lt;- get_acs(\n  geography = \"state\", \n  state = \"IA\", \n  variables = c(\"2020 or later\" = \"B25034_002\", \n                \"2010 to 2019\" = \"B25034_003\", \n                \"2000 to 2009\" = \"B25034_004\",\n                \"1990 to 1999\" = \"B25034_005\",\n                \"1980 to 1989\" = \"B25034_006\",\n                \"1970 to 1979\" = \"B25034_007\",\n                \"1960 to 1969\" = \"B25034_008\",\n                \"1950 to 1959\" = \"B25034_009\",\n                \"1940 to 1949\" = \"B25034_010\",\n                \"1939 or earlier\" = \"B25034_011\",\n                \"total\" = \"B25034_001\"), \n  year = 2021)\n# Calculate the percent by dividing the estimate value by the total value. \nstateAge &lt;- stateAge %&gt;% \n  mutate(percent = estimate/ first(estimate)) %&gt;% \n  filter(variable != \"total\") # Removes rows containing the total.\n\n# Get Year Built data and Total Structure data from 2021 5-year American Community Survey (ACS) for the Midwest.\nregionAge &lt;- get_acs(\n  geography = \"region\", \n  variables = c(\"2020 or later\" = \"B25034_002\", \n                \"2010 to 2019\" = \"B25034_003\", \n                \"2000 to 2009\" = \"B25034_004\",\n                \"1990 to 1999\" = \"B25034_005\",\n                \"1980 to 1989\" = \"B25034_006\",\n                \"1970 to 1979\" = \"B25034_007\",\n                \"1960 to 1969\" = \"B25034_008\",\n                \"1950 to 1959\" = \"B25034_009\",\n                \"1940 to 1949\" = \"B25034_010\",\n                \"1939 or earlier\" = \"B25034_011\",\n                \"total\" = \"B25034_001\"), \n  year = 2021)\n# Filter for desired cities. \nregionAge &lt;- regionAge %&gt;% \n  filter(NAME == \"Midwest Region\")\n# Remove \" city, Iowa\" using str_remove().\nregionAge &lt;- regionAge %&gt;% \n  mutate(NAME = str_remove(NAME, \" Region\"))\n# Group the house age data frame by NAME and calculate the percent by dividing the estimate value by the total value. \nregionAge &lt;- regionAge %&gt;% \n  mutate(percent = estimate/ first(estimate)) %&gt;% \n  filter(variable != \"total\") # Removes rows containing the total.\n\n# Get Year Built data and Total Structure data from 2021 5-year American Community Survey (ACS) for the United States.\nnationAge &lt;- get_acs(\n  geography = \"us\", \n  variables = c(\"2020 or later\" = \"B25034_002\", \n                \"2010 to 2019\" = \"B25034_003\", \n                \"2000 to 2009\" = \"B25034_004\",\n                \"1990 to 1999\" = \"B25034_005\",\n                \"1980 to 1989\" = \"B25034_006\",\n                \"1970 to 1979\" = \"B25034_007\",\n                \"1960 to 1969\" = \"B25034_008\",\n                \"1950 to 1959\" = \"B25034_009\",\n                \"1940 to 1949\" = \"B25034_010\",\n                \"1939 or earlier\" = \"B25034_011\",\n                \"total\" = \"B25034_001\"), \n  year = 2021)\n# Calculate the percent by dividing the estimate value by the total value. \nnationAge &lt;- nationAge %&gt;% \n  mutate(percent = estimate/ first(estimate)) %&gt;% \n  filter(variable != \"total\") # Removes rows containing the total.\n\n# Bind contextual data together using bind_rows().\ncontextAge &lt;- stateAge %&gt;% \n  bind_rows(regionAge, nationAge)\n\n# Plot the Year Built data.                                                      PLOT\n# Group by name. Set geom_col() position to dodge to get the data displayed side by side. \nhouse_age &lt;- ggplot() +\n  geom_line(data = contextAge, aes(x = variable, y = percent, group = NAME, linetype = NAME), linewidth = 1, alpha = .6) +\n  geom_col(data = placeAge, aes(x = variable, y = percent, group = NAME, fill = NAME), position = \"dodge\", alpha = .9) +\n  scale_y_continuous(labels = scales::percent) +\n  theme_fivethirtyeight() +\n  theme(legend.position = \"none\") +\n  labs(title = \"Year Structure Built\",\n       subtitle = \"2017-2021 5-Year ACS Estimates\",\n       x = \"\",\n       y = \"ACS estimate\",\n       fill = \"\",\n       linetype = \"\")+\n  #  caption = \"Variables: B25034_002, B25034_003, B25034_004, B25034_005, B25034_006,\\nB25034_007, B25034_008, B25034_009,B25034_010, B25034_011, B25034_001\")+\n  theme(axis.text.x = element_text(angle = 30, hjust = 1))\n\n\n# Median Home Value by Year Structure Built                                \n\n# Get data from 2021 5-year American Community Survey for all places in Iowa.\nplaceValueAge &lt;- get_acs(\n  geography = \"place\", \n  state = \"IA\", \n  variables = c(\"2020 or later\" = \"B25107_002\", \n                \"2010 to 2019\" = \"B25107_003\", \n                \"2000 to 2009\" = \"B25107_004\",\n                \"1990 to 1999\" = \"B25107_005\",\n                \"1980 to 1989\" = \"B25107_006\",\n                \"1970 to 1979\" = \"B25107_007\",\n                \"1960 to 1969\" = \"B25107_008\",\n                \"1950 to 1959\" = \"B25107_009\",\n                \"1940 to 1949\" = \"B25107_010\",\n                \"1939 or earlier\" = \"B25107_011\"), \n  year = 2021)\n# Filter for desired cities. \nplaceValueAge &lt;- placeValueAge %&gt;% \n  filter(NAME %in% c(\"Grundy Center city, Iowa\", \"Independence city, Iowa\", \"New Hampton city, Iowa\")) %&gt;% \n  mutate(NAME = str_remove(NAME, \" city, Iowa\"))\n\n# Get data from 2021 5-year American Community Survey for Iowa.\nstateValueAge &lt;- get_acs(\n  geography = \"state\", \n  state = \"IA\", \n  variables = c(\"2020 or later\" = \"B25107_002\", \n                \"2010 to 2019\" = \"B25107_003\", \n                \"2000 to 2009\" = \"B25107_004\",\n                \"1990 to 1999\" = \"B25107_005\",\n                \"1980 to 1989\" = \"B25107_006\",\n                \"1970 to 1979\" = \"B25107_007\",\n                \"1960 to 1969\" = \"B25107_008\",\n                \"1950 to 1959\" = \"B25107_009\",\n                \"1940 to 1949\" = \"B25107_010\",\n                \"1939 or earlier\" = \"B25107_011\"), \n  year = 2021)\n\n# Get data from 2021 5-year American Community Survey for the Midwest.\nregionValueAge &lt;- get_acs(\n  geography = \"region\", \n  variables = c(\"2020 or later\" = \"B25107_002\", \n                \"2010 to 2019\" = \"B25107_003\", \n                \"2000 to 2009\" = \"B25107_004\",\n                \"1990 to 1999\" = \"B25107_005\",\n                \"1980 to 1989\" = \"B25107_006\",\n                \"1970 to 1979\" = \"B25107_007\",\n                \"1960 to 1969\" = \"B25107_008\",\n                \"1950 to 1959\" = \"B25107_009\",\n                \"1940 to 1949\" = \"B25107_010\",\n                \"1939 or earlier\" = \"B25107_011\"), \n  year = 2021)\n# Filter for the Midwest. \nregionValueAge &lt;- regionValueAge %&gt;% \n  filter(NAME == \"Midwest Region\") %&gt;% \n  mutate(NAME = str_remove(NAME, \" Region\"))\n\n# Get data from 2021 5-year American Community Survey for the United States.\nnationValueAge &lt;- get_acs(\n  geography = \"us\", \n  variables = c(\"2020 or later\" = \"B25107_002\", \n                \"2010 to 2019\" = \"B25107_003\", \n                \"2000 to 2009\" = \"B25107_004\",\n                \"1990 to 1999\" = \"B25107_005\",\n                \"1980 to 1989\" = \"B25107_006\",\n                \"1970 to 1979\" = \"B25107_007\",\n                \"1960 to 1969\" = \"B25107_008\",\n                \"1950 to 1959\" = \"B25107_009\",\n                \"1940 to 1949\" = \"B25107_010\",\n                \"1939 or earlier\" = \"B25107_011\"), \n  year = 2021)\n\n# Join all geographies.\ncontextValueAge &lt;- stateValueAge %&gt;% \n  bind_rows(regionValueAge, nationValueAge)\n\n# plot median home value by year structure built                                  PLOT\nhouse_value_by_year &lt;- ggplot() +\n  geom_line(data = contextValueAge, aes(x = variable, y = estimate, group = NAME, linetype = NAME), linewidth = 1, alpha = .6) +\n  geom_col(data = placeValueAge, aes(x = variable, y = estimate, group = NAME, fill = NAME), position = \"dodge\", alpha = .9) +\n  scale_y_continuous(labels = scales::dollar) +\n  theme_fivethirtyeight() +\n  labs(title = \"Median Home Value by Year Structure Built\",\n       subtitle = \"2017-2021 5-Year ACS Estimates\",\n       x = \"\",\n       y = \"ACS estimate\",\n       fill = \"\",\n       linetype = \"\",\n       caption = \"Variables: B25034_002, B25034_003, B25034_004, B25034_005, B25034_006,\\nB25034_007, B25034_008, B25034_009,B25034_010, B25034_011, B25034_001\") +\n  theme(axis.text.x = element_text(angle = 30, hjust = 1))\n\n#Use patchwork library to parse together year built and median value by year built plots.\n\nlibrary(patchwork)\n\nvalue_and_year_built &lt;- house_age +house_value_by_year +\n  plot_layout(ncol = 1)\n\n\n\n\n\n# Median House Value                                                         \n\n# Getting housing value data from the 5-year 2020 American Community Survey.\n# Specify county for just Chickasaw, Grundy, and Buchanan County.\n# The API Code for median home value is \"B25077_001.\"\nhousing_val &lt;- get_acs(\n  geography = \"tract\", \n  variables = \"B25077_001\", \n  state = \"IA\", \n  county = c(\"Chickasaw\",\"Grundy\",\"Buchanan\"\n  ),\n  year = 2020\n)\n# Separate the median home value data into three separate geographies: tract, county, and state.\nhousing_val2 &lt;- separate(\n  housing_val, \n  NAME, \n  into = c(\"tract\", \"county\", \"state\"), \n  sep = \", \"\n)  \n\n# Filter median home value data by census tract. \n# The city of Independence falls into two census tracts: 9505 and 9504.\n# Grundy Center is in tract 9603.\n# New Hampton is in tract 704.\n# Add a new column called \"city\" with the associated city name. \nind_house_val &lt;- housing_val2 %&gt;% \n  filter(tract == c(\"Census Tract 9505\", \"Census Tract 9504\")) %&gt;% \n  mutate(city = \"Independence\")\nhampton_house_val &lt;- housing_val2 %&gt;% \n  filter(tract == \"Census Tract 704\") %&gt;% \n  mutate(city = \"New Hampton\")\ngrundy_house_val &lt;- housing_val2 %&gt;% \n  filter(tract == \"Census Tract 9603\") %&gt;% \n  mutate(city = \"Grundy Center\")\n\n# Bind individual data frames together with bind_rows().\ncities_house_val &lt;- ind_house_val %&gt;% \n  bind_rows(hampton_house_val,grundy_house_val)\n\n# Use the summarize function to find the minimum, maximum, median and mean of the median home value estimates. \ncities_house_val %&gt;%\n  group_by(city) %&gt;%\n  summarize(min = min(estimate, na.rm = TRUE), \n            mean = mean(estimate, na.rm = TRUE), \n            median = median(estimate, na.rm = TRUE), \n            max = max(estimate, na.rm = TRUE)) \n\n# A tibble: 3 x 5\n  city             min   mean median    max\n  &lt;chr&gt;          &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 Grundy Center 135900 135900 135900 135900\n2 Independence  133200 136400 136400 139600\n3 New Hampton   117500 117500 117500 117500\n\n# Cannot visualize cities_house_val using this ggplot method because Grundy Center and New Hampton only have one value.\n# Plot housing value by county instead.\n# Add in a point that displays the median for each city from the 2020 5-Year ACS.\nhousing_val3 &lt;- get_acs(\n  geography = \"place\", \n  variables = \"B25077_001\", \n  state = \"IA\",\n  year = 2020) %&gt;% \n  filter(NAME %in% c(\"Grundy Center city, Iowa\",\"New Hampton city, Iowa\", \"Independence city, Iowa\"))\n\n# grundy center = $130,600\n# new hampton = $112,200\n# independence = $129,900\n\n# Create a density plot for median home value.                                   PLOT\nggplot(housing_val2, aes(x = estimate, fill = county)) + \n  geom_density(alpha = 0.3, linewidth = 1) +\n  geom_point(aes(y = 0.00002074, x = 112200), size = 2) + # New Hampton\n  geom_point(aes(x = 129900, y = .00001405), size = 2) + # Independence\n  geom_point(aes(x = 130600, y = .0000227), size = 2) + # Grundy Center\n  geom_text(aes(y = 0.00002074, x = 112200, label = \"New Hampton\\n$112,200\"), hjust = -.1, vjust = 1) +\n  geom_text(aes(x = 129900, y = .00001405, label = \"Independence\\n$129,900\"), hjust = -.1, vjust = 1) +\n  geom_text(aes(x = 130600, y = .0000227, label = \"Grundy Center\\n$130,600\"), hjust = 1.1, vjust = -.15) +\n  labs(title = \"Median House Values by Census Tract\",\n       subtitle = \"2016-2020 5-Year ACS Estimates\",\n       y = \"\",\n       x = \"Median House Value\",\n       caption = \"Points represent median house value for each city\\nVariable: B25077_001\",\n       fill = \"\")+\n  scale_x_continuous(labels = dollar_format()) +\n  scale_y_continuous(labels = scales::comma,\n                     limits = c(0,.000026))+\n  theme_fivethirtyeight()\n\n\n\n# Now, want to plot all available data for median home value. \n# Getting median home value data from the 5-Year American Community Survey. \n# The median home value code is \"B25077_001.\"\n\n# Create an object called \"years\" that lists the years you want to pull data from. \n# We want all of the years the ACS data is available. \nyears &lt;- 2009:2021\nnames(years) &lt;- years\n\n# Use get_acs() to pull median home value data at the place level.\nplaceValue &lt;- map_dfr(years, ~{\n  get_acs(\n    geography = \"place\",\n    variables = c(\"median_value\" = \"B25077_001\"),\n    state = \"IA\",\n    year = .x,\n    survey = \"acs5\",\n    output = \"wide\"\n  )\n}, .id = \"year\") \n\n# Remove the \" city, Iowa|, Iowa\" from the end of the place names.\nplaceValue &lt;- placeValue %&gt;% \n  mutate(NAME = str_remove(NAME, \" city, Iowa|, Iowa\"))\n\n# Filter placeValue for desired cities.\n# Add a geography column.\nplaceValue &lt;- placeValue %&gt;%\n  filter(NAME %in% c(\"Grundy Center\", \"Independence\", \"New Hampton\")) %&gt;% \n  mutate(geography = \"Place\")\n\n\n# Use get_acs() to pull median home value data at the state level.\nstateValue &lt;- map_dfr(years, ~{\n  get_acs(\n    geography = \"state\",\n    variables = c(\"median_value\" = \"B25077_001\"),\n    state = \"IA\",\n    year = .x,\n    survey = \"acs5\",\n    output = \"wide\"\n  )\n}, .id = \"year\") \n\n# Add a geography column. \nstateValue &lt;- stateValue %&gt;% \n  mutate(geography = \"State\")\n\n\n# Use get_acs() to pull median home value data at the regional level.\nregionValue &lt;- map_dfr(years, ~{\n  get_acs(\n    geography = \"region\",\n    variables = c(\"median_value\" = \"B25077_001\"),\n    year = .x,\n    survey = \"acs5\",\n    output = \"wide\"\n  )\n}, .id = \"year\") \n\n# Remove the \" Region\" from the end of the region names\nregionValue&lt;- regionValue %&gt;% \n  mutate(NAME = str_remove(NAME, \" Region\"))\n\n# Filter regionValue for Midwest.\n# Add a geography column.\nregionValue &lt;- regionValue %&gt;%\n  filter(NAME %in% \"Midwest\") %&gt;% \n  mutate(geography = \"Region\")\n\n\n# Use get_acs() to pull median home value data at the national level.\nnationValue &lt;- map_dfr(years, ~{\n  get_acs(\n    geography = \"us\",\n    variables = c(\"median_value\" = \"B25077_001\"),\n    year = .x,\n    survey = \"acs5\",\n    output = \"wide\"\n  )\n}, .id = \"year\")\n\n# Add a geography column.\nnationValue &lt;- nationValue %&gt;% \n  mutate(geography = \"Nation\")\n\n# Bind all geographies together with bind_rows().\nvalue &lt;- nationValue %&gt;% \n  bind_rows(regionValue, stateValue, placeValue)\n\n# Add a new column specifying if the geography is a nation, region, state, or place. \nvalue &lt;- value %&gt;% \n  mutate(grouping = ifelse(NAME %in% c(\"United States\", \"Midwest\", \"Iowa\"), \"Contextual Area\", NAME))\n\n# Create three separate plots for Grundy Center, Independence and New Hampton.\n# Combine plots together using patchwork library. \n#install.packages(\"patchwork\")\nlibrary(patchwork)\n\n# Plot the median home value for Grundy Center and its contextual geographies.       PLOT\nplot1 &lt;- value[value$NAME %in% c(\"Grundy Center\", \"United States\", \"Midwest\", \"Iowa\"), ] %&gt;% \n  ggplot(aes(x = year, y = median_valueE, group = NAME)) +\n  geom_ribbon(aes(ymax = median_valueE + median_valueM, ymin = median_valueE - median_valueM, fill = geography),\n              alpha = 0.3) + \n  geom_line(aes(color = geography), linewidth = 1)+\n  theme_fivethirtyeight()+\n  scale_y_continuous(labels = label_dollar(scale = .001, suffix = \"k\"),\n                     limits = c(85000,250000))+\n  theme(legend.position = \"none\",\n        axis.text.x = element_text(angle = 45, hjust = 1))+\n  labs(x = \"\",\n       color = \"\",\n       linetype = \"\",\n       subtitle = \"2009-2021 5-Year ACS Estimates\\nGrundy Center\",\n       fill = \"\",\n       title = \"Median Home Value\")\n\n# Plot the median home value for Independence and its contextual geographies.        PLOT \nplot2 &lt;- value[value$NAME %in% c(\"Independence\", \"United States\", \"Midwest\", \"Iowa\"), ] %&gt;% \n  ggplot(aes(x = year, y = median_valueE, group = NAME)) +\n  geom_ribbon(aes(ymax = median_valueE + median_valueM, ymin = median_valueE - median_valueM, fill = geography),\n              alpha = 0.3) + \n  geom_line(aes(color = geography), linewidth = 1)+\n  theme_fivethirtyeight()+\n  scale_y_continuous(labels = label_dollar(scale = .001, suffix = \"k\"),\n                     limits = c(85000,250000))+\n  theme(legend.position = \"none\",\n        axis.text.x = element_text(angle = 45, hjust = 1))+\n  labs(x = \"\",\n       color = \"\",\n       linetype = \"\",\n       subtitle = \"\\nIndependence\",\n       fill = \"\")\n\n# Plot the median value for New Hampton and its contextual geographies.         PLOT \nplot3 &lt;- value[value$NAME %in% c(\"New Hampton\", \"United States\", \"Midwest\", \"Iowa\"), ] %&gt;% \n  ggplot(aes(x = year, y = median_valueE, group = NAME)) +\n  geom_ribbon(aes(ymax = median_valueE + median_valueM, ymin = median_valueE - median_valueM, fill = geography),\n              alpha = 0.3) + \n  geom_line(aes(color = geography), linewidth = 1)+\n  theme_fivethirtyeight()+\n  scale_y_continuous(labels = label_dollar(scale = .001, suffix = \"k\"),\n                     limits = c(85000,250000))+\n  theme(legend.position = \"bottom\",\n        axis.text.x = element_text(angle = 45, hjust = 1))+\n  labs(x = \"\",\n       color = \"\",\n       linetype = \"\",\n       subtitle = \"\\nNew Hampton\",\n       fill = \"\",\n       caption = \"Shaded area represents margin of error around the ACS estimate\\nVariable: B25077_001\")\n\n# Combine plots. \ncombined_plots1 &lt;- wrap_plots(plot1, plot2, plot3)\n\n\n# Plot just the city median home value data.                                     PLOT\nvalue[value$NAME %in% c(\"Grundy Center\", \"New Hampton\", \"Independence\"), ] %&gt;% \n  ggplot(aes(x = year, y = median_valueE, group = NAME, fill = NAME)) + \n  geom_ribbon(aes(ymax = median_valueE + median_valueM, ymin = median_valueE - median_valueM),\n              alpha = 0.3) + \n  geom_line(aes(color = NAME), linewidth = 1) + \n  theme_fivethirtyeight() + \n  scale_y_continuous(labels = label_dollar(scale = .001, suffix = \"k\")) +\n  labs(title = \"Median Home Value\",\n       subtitle = \"2009-2021 5-Year ACS Estimates\",\n       x = \"Year\",\n       y = \"ACS estimate\",\n       fill = \"\",\n       color = \"\",\n       caption = \"Shaded area represents margin of error around the ACS estimate\\nVariable: B25077_001\") +\n  geom_text(aes(x = \"2021\", y =137100, label = \"$137,000\"), vjust = -1)+\n  geom_text(aes(x = \"2021\", y = 133300, label = \"$133,300\"), vjust = 2) +\n  geom_text(aes(x = \"2021\", y = 122600, label = \"$122,600\"), vjust = -1)\n\n\n\n\n\n\n\n```{r}, warning = FALSE, message = FALSE} # Home Ownership, Rental, and Vacancy Rates"
  },
  {
    "objectID": "posts/Week_8/Week_8.html#nation-time",
    "href": "posts/Week_8/Week_8.html#nation-time",
    "title": "Week Eight of Data Science for the Public Good",
    "section": "NATION TIME",
    "text": "NATION TIME"
  },
  {
    "objectID": "posts/Week_8/Week_8.html#demographic-analysis",
    "href": "posts/Week_8/Week_8.html#demographic-analysis",
    "title": "Week Eight of Data Science for the Public Good",
    "section": "Demographic Analysis",
    "text": "Demographic Analysis\nI finished gathering data for the demographic analysis this week. The code for that is below. I made a couple of minor changes to the data from last week. I decided that I wanted to gather all American Community Survey data from all years it was available instead of just for 2021.\nIf you copied any of the code from the week before, I would suggest copy the code below. It is far more accurate to the actual demographic analysis. I will be creating a separate blog that outlines the process of conducting a demographic analysis.\n\nPopulation Data\n\n## starting with POPULATION data for all places in Iowa ##\n##########################################################\n\n# Define the variables before getting the data.\n# The Census API code for total population for 2000 and 2010 is P001001.\npop00 &lt;- c(\"pop\" = \"P001001\")\npop10 &lt;- c(\"pop\" = \"P001001\")\n# The API code for total population changed for 2020.\n# The Census API code for total population is P1_001N for 2020. \npop20 &lt;- c(\"pop\" = \"P1_001N\")\n\n##\n# Getting 2000 total population data for the USA.\npop00 &lt;- get_decennial(geography = \"place\",\n                       state = \"IA\",\n                          year = 2000,\n                          variable = pop00,\n                          output = \"wide\") %&gt;% \n  mutate(year = 2000)\n# Getting 2010 total population data for the USA.\npop10 &lt;- get_decennial(geography = \"place\",\n                          state = \"IA\",\n                          year = 2010,\n                          variable = pop10,\n                          output = \"wide\") %&gt;% \n  mutate(year = 2010)\n# Getting 2020 total population data for the USA.\npop20 &lt;- get_decennial(geography = \"place\",\n                          state = \"IA\",\n                          year = 2020,\n                          variable = pop20,\n                          output = \"wide\") %&gt;% \n  mutate(year = 2020)\n# Bind the years together using bind_rows to create data frame for national context. \npop &lt;- pop20 %&gt;% \n  bind_rows(pop10,pop00) \n\n\n# Create anew column called prc_change.\n# Group by \"NAME\" so that the calculations occur individually for each place. \n# Percent change is calculated by subtracting year2 from year1 and dividing by year2. \npop &lt;- pop %&gt;%\n  group_by(NAME) %&gt;%\n  mutate(prc_change = ifelse(year == 2020, (pop - lead(pop)) / lead(pop),\n                             ifelse(year == 2010, (pop - last(pop)) / last(pop), NA)))\n\n# figure out if the places are growing, shrinking, or stable\n# stable = between -2 and 2\n# increasing &gt; 2\n# decreasing &lt; -2\npop &lt;- pop %&gt;%\n  mutate(change_label = ifelse(prc_change &gt; .02, \"Growing\",\n                             ifelse(prc_change &lt; -.02, \"Shrinking\", \"Stable\"))) %&gt;% \n  mutate(NAME = str_remove(NAME, \" city, Iowa|, Iowa\"))\n\n#rename the variables\npop &lt;- pop %&gt;% \n  rename(Population = pop) %&gt;% \n  rename(Year = year) %&gt;% \n  rename(\"Percent Change\" = prc_change) %&gt;% \n  rename(label = change_label)\n\n\npop %&gt;% write.csv(file = \"population_data.csv\")\n\n\n## age of residents ##\n######################\n\n# adding to pop \n\n# Create an object called \"years\" that lists the years you want to pull data from. \n# We want all of the years the ACS data is available. \nyears &lt;- 2009:2021\nnames(years) &lt;- years\n\n# get the median age of all people in all places in Iowa from ACS\nmedian_age &lt;- map_dfr(years, ~{\n  get_acs(\n    geography = \"place\",\n    variables = c(\"median_age\" = \"B01002_001\"),\n    state = \"IA\",\n    year = .x,\n    survey = \"acs5\",\n    output = \"wide\"\n  )\n}, .id = \"year\") %&gt;% \n  mutate(NAME = str_remove(NAME, \" city, Iowa|, Iowa\"))\n\nGetting data from the 2005-2009 5-year ACS\n\n\nGetting data from the 2006-2010 5-year ACS\n\n\nGetting data from the 2007-2011 5-year ACS\n\n\nGetting data from the 2008-2012 5-year ACS\n\n\nGetting data from the 2009-2013 5-year ACS\n\n\nGetting data from the 2010-2014 5-year ACS\n\n\nGetting data from the 2011-2015 5-year ACS\n\n\nGetting data from the 2012-2016 5-year ACS\n\n\nGetting data from the 2013-2017 5-year ACS\n\n\nGetting data from the 2014-2018 5-year ACS\n\n\nGetting data from the 2015-2019 5-year ACS\n\n\nGetting data from the 2016-2020 5-year ACS\n\n\nGetting data from the 2017-2021 5-year ACS\n\n# rename variables\nmedian_age &lt;- median_age %&gt;% \n  rename(Year = year) %&gt;% \n  rename(\"Median Age Estimate\" = median_ageE) %&gt;% \n  rename(moe = median_ageM)\n\n\n# get the number of people under 18 and over 65\n# API Codes seperated by gender, so have to pull twice\n# starting with Male\nmale &lt;- map_dfr(years, ~{\n  get_acs(\n    geography = \"place\",\n    variable = c(\"under5\" = \"B01001_003\",\n                 \"a5to9\" = \"B01001_004\",\n                 \"a10to14\" = \"B01001_005\",\n                 \"a15to17\" = \"B01001_006\",\n                 \"a65to66\" = \"B01001_020\",\n                 \"a67to69\" = \"B01001_021\",\n                 \"a70to74\" = \"B01001_022\",\n                 \"a75to79\" = \"B01001_023\",\n                 \"a80to84\" = \"B01001_024\",\n                 \"over85\" = \"B01001_025\",\n                 \"total\" = \"B01001_002\"),\n    state = \"IA\",\n    year = .x,\n    survey = \"acs5\",\n    output = \"wide\"\n  )\n}, .id = \"year\") %&gt;% \n  mutate(NAME = str_remove(NAME, \" city, Iowa|, Iowa\"))\n\nGetting data from the 2005-2009 5-year ACS\n\n\nGetting data from the 2006-2010 5-year ACS\n\n\nGetting data from the 2007-2011 5-year ACS\n\n\nGetting data from the 2008-2012 5-year ACS\n\n\nGetting data from the 2009-2013 5-year ACS\n\n\nGetting data from the 2010-2014 5-year ACS\n\n\nGetting data from the 2011-2015 5-year ACS\n\n\nGetting data from the 2012-2016 5-year ACS\n\n\nGetting data from the 2013-2017 5-year ACS\n\n\nGetting data from the 2014-2018 5-year ACS\n\n\nGetting data from the 2015-2019 5-year ACS\n\n\nGetting data from the 2016-2020 5-year ACS\n\n\nGetting data from the 2017-2021 5-year ACS\n\n# now for Female\nfemale &lt;- map_dfr(years, ~{\n  get_acs(\n    geography = \"place\",\n    variable = c(\"under5\" = \"B01001_027\",\n                 \"a5to9\" = \"B01001_028\",\n                 \"a10to14\" = \"B01001_029\",\n                 \"a15to17\" = \"B01001_030\",\n                 \"a65to66\" = \"B01001_044\",\n                 \"a67to69\" = \"B01001_045\",\n                 \"a70to74\" = \"B01001_046\",\n                 \"a75to79\" = \"B01001_047\",\n                 \"a80to84\" = \"B01001_048\",\n                 \"over85\" = \"B01001_049\",\n                 \"total\" = \"B01001_026\"),\n    state = \"IA\",\n    year = .x,\n    survey = \"acs5\",\n    output = \"wide\"\n  )\n}, .id = \"year\") %&gt;% \n  mutate(NAME = str_remove(NAME, \" city, Iowa|, Iowa\"))\n\nGetting data from the 2005-2009 5-year ACS\n\n\nGetting data from the 2006-2010 5-year ACS\n\n\nGetting data from the 2007-2011 5-year ACS\n\n\nGetting data from the 2008-2012 5-year ACS\n\n\nGetting data from the 2009-2013 5-year ACS\n\n\nGetting data from the 2010-2014 5-year ACS\n\n\nGetting data from the 2011-2015 5-year ACS\n\n\nGetting data from the 2012-2016 5-year ACS\n\n\nGetting data from the 2013-2017 5-year ACS\n\n\nGetting data from the 2014-2018 5-year ACS\n\n\nGetting data from the 2015-2019 5-year ACS\n\n\nGetting data from the 2016-2020 5-year ACS\n\n\nGetting data from the 2017-2021 5-year ACS\n\n# create new columns for under18 and over 65 for both male and female\n# create a new column for gender\nmale &lt;- male %&gt;% \n  mutate(under18E = round(under5E + a5to9E + a10to14E + a15to17E)) %&gt;%\n  mutate(under18M = round(sqrt(under5M^2 + a5to9M^2 + a10to14M^2 + a15to17M^2))) %&gt;%\n  mutate(over65E = round(a65to66E + a67to69E + a70to74E + a75to79E + a80to84E + over85E)) %&gt;%\n  mutate(over65M =  round(sqrt(a65to66M^2 + a67to69M^2 + a70to74M^2 + a75to79M^2 + a80to84M^2 + over85M^2))) %&gt;% \n  mutate(gender = \"Male\")\n\nfemale &lt;- female %&gt;% \n  mutate(under18E = round(under5E + a5to9E + a10to14E + a15to17E)) %&gt;%\n  mutate(under18M = round(sqrt(under5M^2 + a5to9M^2 + a10to14M^2 + a15to17M^2))) %&gt;%\n  mutate(over65E = round(a65to66E + a67to69E + a70to74E + a75to79E + a80to84E + over85E)) %&gt;%\n  mutate(over65M =  round(sqrt(a65to66M^2 + a67to69M^2 + a70to74M^2 + a75to79M^2 + a80to84M^2 + over85M^2))) %&gt;% \n  mutate(gender = \"Female\")\n\n\n# combine the data frames\nage &lt;- female %&gt;% \n  bind_rows(male)\n\n# aggregate by city NAME, year, GEOID and gender\n# create new columns for percent under 18 and percent over 65\naggregated_age &lt;- age %&gt;% \n  group_by(year,GEOID, NAME, gender) %&gt;% \n             summarize(prc_under18E = sum(under18E)/sum(totalE),\n                       prc_under18M = sqrt(sum(under18M^2) / sum(totalE)^2 + (sum(under18E)^2 * sum(totalM^2)) / sum(totalE)^4),\n                       prc_over65E = sum(over65E)/sum(totalE),\n                       prc_over65M = sqrt(sum(over65M^2) / sum(totalE)^2 + (sum(over65E)^2 * sum(totalM^2)) / sum(totalE)^4))\n\n`summarise()` has grouped output by 'year', 'GEOID', 'NAME'. You can override\nusing the `.groups` argument.\n\n# add a column that states whether a place is \"aged\", \"stable\" or \"young\"\n# using a 2% difference to gauge a stable population\naggregated_age &lt;- aggregated_age %&gt;%\n  mutate(age_label = ifelse(prc_under18E - prc_over65E &gt; .02, \"Young\",\n                               ifelse(prc_under18E - prc_over65E &lt; -.02, \"Aging\", \"Stable\")))\n\n# left_join aggregated_age to age\nage &lt;- age %&gt;% \n  left_join(aggregated_age, by = c(\"year\",\"GEOID\",\"NAME\",\"gender\"))\n\n# rename variables\nage &lt;- age %&gt;% \n  rename(\"Under 5\" = under5E) %&gt;% \n  rename(\"5 to 9\" = a5to9E) %&gt;% \n  rename(\"10 to 14\" = a10to14E) %&gt;% \n  rename(\"15 to 17\" = a15to17E) %&gt;% \n  rename(\"65 to 66\" = a65to66E) %&gt;% \n  rename(\"67 to 69\" = a67to69E) %&gt;% \n  rename(\"70 to 74\" = a70to74E) %&gt;% \n  rename(\"75 to 79\" = a75to79E) %&gt;% \n  rename(\"80 to 84\" = a80to84E) %&gt;% \n  rename(\"Over 85\" = over85E) %&gt;% \n  rename(\"Total Population Under 18\" = under18E) %&gt;% \n  rename(\"Total Population Over 65\" = over65E) %&gt;% \n  rename(\"Percent Population Under 18\" = prc_under18E) %&gt;% \n  rename(\"Percent Population Over 65\" = prc_over65E) %&gt;% \n  rename(Label = age_label) %&gt;% \n  rename(\"Under 5 moe\" = under5M) %&gt;% \n  rename(\"5 to 9 moe\" = a5to9M) %&gt;% \n  rename(\"10 to 14 moe\" = a10to14M) %&gt;% \n  rename(\"15 to 17 moe\" = a15to17M) %&gt;% \n  rename(\"65 to 66 moe\" = a65to66M) %&gt;% \n  rename(\"67 to 69 moe\" = a67to69M) %&gt;% \n  rename(\"70 to 74 moe\" = a70to74M) %&gt;% \n  rename(\"75 to 79 moe\" = a75to79M) %&gt;% \n  rename(\"80 to 84 moe\" = a80to84M) %&gt;% \n  rename(\"Over 85 moe\" = over85M) %&gt;% \n  rename(\"Total Population Under 18 moe\" = under18M) %&gt;% \n  rename(\"Total Population Over 65 moe\" = over65M) %&gt;% \n  rename(\"Percent Population Under 18 moe\" = prc_under18M) %&gt;% \n  rename(\"Percent Population Over 65 moe\" = prc_over65M)\n\n# create a .csv file for age data and median age data\nage %&gt;% write.csv(file = \"age_data.csv\")\nmedian_age %&gt;% write.csv(file = \"median_age_data.csv\")\n\n\n\nHousing Data\n\n## next is housing information ##\n#################################\n\n# getting from 2021 5-Year ACS\n\n# total housing units = B25001_001\n# owner occupied units = B25003_002\n# total occupied units = B25002_002\n# total vacant units = B25002_003\n# median house value = B25077_001 \n# median house age = B25035_001\n\nhousing &lt;- map_dfr(years, ~{\n  get_acs(\n    geography = \"place\",\n    variable = c(\"total_units\" = \"B25001_001\",\n                 \"occupied_units\" = \"B25002_002\",\n                 \"vacant_units\" = \"B25002_003\",\n                 \"owner_occupied\" = \"B25003_002\",\n                 \"renter_occupied\" = \"B25003_003\",\n                 \"median_house_value\" = \"B25077_001\",\n                 \"median_year_built\" = \"B25035_001\"),\n    state = \"IA\",\n    year = .x,\n    survey = \"acs5\",\n    output = \"wide\"\n  )\n}, .id = \"year\") %&gt;% \n  mutate(NAME = str_remove(NAME, \" city, Iowa|, Iowa\"))\n\n\n## ALL RATES ARE PERCENTAGES\n# calculate home ownership, vacany, and rental rates\nhousing &lt;- housing %&gt;% \n  mutate(\"Home Ownership Rate Estimate\" = (owner_occupiedE / occupied_unitsE)) %&gt;%  # divide owner occupied by occupied units\n  mutate(\"Home Ownership Rate moe\" = (sqrt((owner_occupiedM^2) / (occupied_unitsE^2) + ((owner_occupiedE * occupied_unitsM)^2) / (occupied_unitsE^4)))) %&gt;%  # calculate new moe\n  mutate(\"Rental Rate Estimate\" = (renter_occupiedE / occupied_unitsE)) %&gt;%  # divide renter occupied by occupied units\n  mutate(\"Rental Rate moe\" = (sqrt((renter_occupiedM^2) / (occupied_unitsE^2) + ((renter_occupiedE * occupied_unitsM)^2) / (occupied_unitsE^4)))) %&gt;% # calculate new moe\n  mutate(\"Vacancy Rate Estimate\" = (vacant_unitsE / total_unitsE)) %&gt;%  # divide vacant units by total units\n  mutate(\"Vacancy Rate moe\" = (sqrt((vacant_unitsM^2) / (total_unitsE^2) + ((vacant_unitsE * total_unitsM)^2) / (total_unitsE^4)))) %&gt;% \n  mutate(\"Occupancy Rate Estimate\" = (occupied_unitsE / total_unitsE)) %&gt;% \n  mutate(\"Occupancy Rate moe\" = (sqrt(occupied_unitsM^2) / (total_unitsE^2) + ((occupied_unitsE * total_unitsM^2) / total_unitsE^4)))# calculate new moe\n\n# rename variables\nhousing &lt;- housing %&gt;% \n  rename(\"Total Housing Units\" = total_unitsE) %&gt;% \n  rename(\"Occupied Units\" = occupied_unitsE) %&gt;% \n  rename(\"Owner Occupied Units\" = owner_occupiedE) %&gt;% \n  rename(\"Renter Occupied Units\" = renter_occupiedE) %&gt;% \n  rename(\"Median House Value\" = median_house_valueE) %&gt;% \n  rename(\"Median Year Built\" = median_year_builtE) %&gt;% \n  rename(\"Total Housing Units moe\" = total_unitsM) %&gt;% \n  rename(\"Occupied Units moe\" = occupied_unitsM) %&gt;% \n  rename(\"Owner Occupied Units moe\" = owner_occupiedM) %&gt;% \n  rename(\"Renter Occupied Units moe\" = renter_occupiedM) %&gt;% \n  rename(\"Median House Value moe\" = median_house_valueM) %&gt;% \n  rename(\"Median Year Built moe\" = median_year_builtM)\n\n# create a .csv file with housing data\nhousing %&gt;% write.csv(file = \"housing_data.csv\")\n\n\n\nTaxable Properties Data\n\n## next is Taxable Property Values from Liesl ##\n################################################\n\n#link to data: https://data.iowa.gov/Local-Government-Finance/Taxable-Property-Values-in-Iowa-by-Tax-District-an/ig9g-pba5\n\ntaxable.csv &lt;- read.csv(\"C:/Users/Kailyn Hogan/OneDrive - Iowa State University/Documents/GitHub/Housing/demographics/demographic analysis/Datasets/Taxable_Property_Values_in_Iowa_by_Tax_District_and_Year.csv\")\n# City name is stored in City.Name as all caps\n# for census data, only the first letter is capitalized and city, Iowa is attached\n# need to lowercase taxable_prop_values and remove city, Iowa from housing and pop\n\ntaxable.csv &lt;- taxable.csv %&gt;% \n  mutate(City.Name = str_to_sentence(City.Name)) %&gt;% \n  rename(NAME = City.Name) #str_to_sentence() uses regular sentence formatting where the first letter is capitalized\n                              # could have also used str_to_titletext()\n\n# aggregated the column based on City.Name\n# function = sum to get the sum of all values\n# na.rm = TRUE, means the NAs get ignored\naggregated_tax &lt;- taxable.csv %&gt;% \n  group_by(Assessment.Year,NAME) %&gt;% \n  summarize(Residential = sum(Residential),\n            Commercial = sum(Commercial),\n            Industrial = sum(Industrial),\n            Ag.Land = sum(Ag.Land),\n            Ag.Building = sum(Ag.Building))\n  \n# rename variables \naggregated_tax &lt;- aggregated_tax %&gt;% \n  rename(Year = Assessment.Year)\n\n##########################################################################################################\n\naggregated_tax\n# holds summed values for each type of property for a city\n# needs further transforming for analysis\n# could change aggregation to find the median value for each property type\n# could be valuable to gather data for all years available.\n\n##########################################################################################################\n\n\n\nWorkforce Area Characteristics and Residential Area Characteristics Data\n\n## next is RAC and WAC data from Liesl ##\n#########################################\n\n# link to data structure set: https://lehd.ces.census.gov/data/lodes/LODES8/LODESTechDoc8.0.pdf\n# interested in total number of jobs and ag related industries\n# C000 = total\n# CSN01 = ag related jobs\n\n# WAC = how many people WORK in the city\n# RAC = how many people live in the city AND have jobs\n\n# downloaded the data as .csv\n# need to read in the .csv file with read.csv()\nia_rac.csv &lt;- read.csv(\"C:/Users/Kailyn Hogan/OneDrive - Iowa State University/Documents/GitHub/Housing/demographics/demographic analysis/Datasets/ia_rac_S000_JT00_2020.csv\")\n\n# rename w_geocode to geocode so it can easily be combined with geography2 dataframe\nia_rac.csv &lt;- ia_rac.csv %&gt;%\n  rename(geocode = h_geocode) \n\n# this .csv file contains the geography for the wac and rac data\n# need to join to wac and rac files so we can aggregate by city\ngeography &lt;- read.csv(\"C:/Users/Kailyn Hogan/OneDrive - Iowa State University/Documents/GitHub/Housing/demographics/demographic analysis/Datasets/ia_xwalk.csv\")\n# tabblk2020 = h_geocode \n#ctyname = county\n#cbsaname = metropolitan area name\n#stplc = FIPS state + FIPS Place\n#stplcname = place name\n\n# reduce geography data frame to just h_geocode and NAME\ngeography2 &lt;- geography %&gt;% \n  select(\"tabblk2020\",\"stplc\",\"stplcname\") %&gt;% \n  rename(geocode = tabblk2020) %&gt;% \n  rename(GEOID = stplc) %&gt;% \n  mutate(NAME = str_remove(stplcname, \" city, IA|, IA\")) %&gt;% \n  select(-stplcname)\n# remove all empty rows\ngeography2 &lt;- geography2 %&gt;% \n  filter(NAME != \"\")%&gt;% \n  mutate(year = 2023)\n\n# use geography2 to assign city NAME to ia_rac.csv\nrac_data &lt;- ia_rac.csv %&gt;% \n  left_join(geography2, by = c(\"geocode\"))\n\n# aggregate by city name\n# have to remove h_geocode and GEOID so they don't aggregate\nrac_data &lt;- aggregate(. ~ NAME, data = rac_data, FUN = sum, na.rm = TRUE) %&gt;% \n  select(-c(\"geocode\",\"GEOID\",\"year\",\"createdate\")) %&gt;% \n  mutate(year = 2023)\n\n\n# downloaded the data as .csv\n# need to read in the .csv file with read.csv()\nia_wac.csv &lt;- read.csv(\"C:/Users/Kailyn Hogan/OneDrive - Iowa State University/Documents/GitHub/Housing/demographics/demographic analysis/Datasets/ia_wac_S000_JT00_2020.csv\")\n\n# rename w_geocode to geocode so it can easily be combined with geography2 dataframe\nia_wac.csv &lt;- ia_wac.csv %&gt;%\n  rename(geocode = w_geocode)\n# join to geography2 data frame\nwac_data &lt;- geography2 %&gt;% \n  left_join(ia_wac.csv, by = \"geocode\")\n# remove all empty rows\nwac_data &lt;- wac_data %&gt;% \n  filter(NAME != \"\")\n# aggregate by city name\nwac_data &lt;- aggregate(. ~ NAME, data = wac_data[, !(names(wac_data) %in% c(\"geocode\", \"GEOID\",\"createdate\"))], FUN = sum, na.rm = TRUE) %&gt;% \n  mutate(year = 2023)\n\n\n# rename variables\nrac_data &lt;- rac_data %&gt;% \n  rename(\"Total Number of Jobs\" = C000) %&gt;% \n  rename(\"Number of Jobs in NAICS sector 11 (Agriculture, Forestry, Fishing and Hunting)\" = CNS01) %&gt;% \n  rename(\"Number of Jobs in NAICS sector 21 (Mining, Quarrying, and Oil and Gas Extraction)\" = CNS02) %&gt;% \n  rename(\"Number of Jobs in NAICS sector 22 (Utilities)\" = CNS03) %&gt;% \n  rename(\"Number of Jobs in NAICS sector 23 (Construction)\" = CNS04) %&gt;% \n  rename(\"Number of Jobs in NAICS sector 32-33 (Manufacturing)\" = CNS05) %&gt;% \n  rename(\"Number of Jobs in NAICS sector 42 (Wholesale Trade)\" = CNS06) %&gt;% \n  rename(\"Number of Jobs in NAICS sector 44-45 (Retail Trade)\" = CNS07) %&gt;% \n  rename(\"Number of Jobs in NAICS sector 48-49 (Transportation and Warehousing)\" = CNS08) %&gt;% \n  rename(\"Number of Jobs in NAICS sector 51 (Information)\" = CNS09) %&gt;% \n  rename(\"Number of Jobs in NAICS sector 52 (Finance)\" = CNS10) %&gt;% \n  rename(\"Number of Jobs in NAICS sector 53 (Reale Estate adn Rental and Leasing)\" = CNS11) %&gt;% \n  rename(\"Number of Jobs in NAICS sector 54 (Professional, Scientific, and Technical Services)\" = CNS12) %&gt;% \n  rename(\"Number of Jobs in NAICS sector 55 (Management of Comapanies and Enterprises)\" = CNS13) %&gt;% \n  rename(\"Number of Jobs in NAICS sector 56 (Administrative and Support and Waste Management and Remediation Services)\" = CNS14) %&gt;% \n  rename(\"Number of Jobs in NAICS sector 61 (Educational Services)\" = CNS15) %&gt;% \n  rename(\"Number of Jobs in NAICS sector 62 (Health Care and Social Assistance)\" = CNS16) %&gt;% \n  rename(\"Number of Jobs in NAICS sector 71 (Arts, Entertainment, and Recreation)\" = CNS17) %&gt;% \n  rename(\"Number of Jobs in NAICS sector 72 (Accomodation and Food Service)\" = CNS18) %&gt;% \n  rename(\"Number of Jobs in NAICS sector 81 (Other Serivces, except Public Administratoin)\" = CNS19) %&gt;% \n  rename(\"Number of Jobs in NAICS sector 92 (Public Administration)\" = CNS20)\n  \nwac_data &lt;- wac_data %&gt;% \n  rename(\"Total Number of Jobs\" = C000) %&gt;% \n  rename(\"Number of Jobs in NAICS sector 11 (Agriculture, Forestry, Fishing and Hunting)\" = CNS01) %&gt;% \n  rename(\"Number of Jobs in NAICS sector 21 (Mining, Quarrying, and Oil and Gas Extraction)\" = CNS02) %&gt;% \n  rename(\"Number of Jobs in NAICS sector 22 (Utilities)\" = CNS03) %&gt;% \n  rename(\"Number of Jobs in NAICS sector 23 (Construction)\" = CNS04) %&gt;% \n  rename(\"Number of Jobs in NAICS sector 32-33 (Manufacturing)\" = CNS05) %&gt;% \n  rename(\"Number of Jobs in NAICS sector 42 (Wholesale Trade)\" = CNS06) %&gt;% \n  rename(\"Number of Jobs in NAICS sector 44-45 (Retail Trade)\" = CNS07) %&gt;% \n  rename(\"Number of Jobs in NAICS sector 48-49 (Transportation and Warehousing)\" = CNS08) %&gt;% \n  rename(\"Number of Jobs in NAICS sector 51 (Information)\" = CNS09) %&gt;% \n  rename(\"Number of Jobs in NAICS sector 52 (Finance)\" = CNS10) %&gt;% \n  rename(\"Number of Jobs in NAICS sector 53 (Reale Estate adn Rental and Leasing)\" = CNS11) %&gt;% \n  rename(\"Number of Jobs in NAICS sector 54 (Professional, Scientific, and Technical Services)\" = CNS12) %&gt;% \n  rename(\"Number of Jobs in NAICS sector 55 (Management of Comapanies and Enterprises)\" = CNS13) %&gt;% \n  rename(\"Number of Jobs in NAICS sector 56 (Administrative and Support and Waste Management and Remediation Services)\" = CNS14) %&gt;% \n  rename(\"Number of Jobs in NAICS sector 61 (Educational Services)\" = CNS15) %&gt;% \n  rename(\"Number of Jobs in NAICS sector 62 (Health Care and Social Assistance)\" = CNS16) %&gt;% \n  rename(\"Number of Jobs in NAICS sector 71 (Arts, Entertainment, and Recreation)\" = CNS17) %&gt;% \n  rename(\"Number of Jobs in NAICS sector 72 (Accomodation and Food Service)\" = CNS18) %&gt;% \n  rename(\"Number of Jobs in NAICS sector 81 (Other Serivces, except Public Administratoin)\" = CNS19) %&gt;% \n  rename(\"Number of Jobs in NAICS sector 92 (Public Administration)\" = CNS20)\n\n  \n##########################################################################################################\n\n# wac and rac data need futher transforming for analysis\n# should change data into percents to standardize the data and account for different population sizes\n\n# example of transformation below\n# used earlier when data was held in data frame differently\n\n# rac c000 = total employed residents\n# rac cns01 = total residents employed in ag\n# wac c000 = total jobs in city\n# wac cns01 = total ag jobs in city\n#wac_rac &lt;- wac_rac %&gt;% \n#  rename(total_jobs = C000.x) %&gt;% \n#  rename(workforce_size = C000.y) %&gt;% \n#  rename(workforce_ag = CNS01.y) %&gt;% \n#  rename(ag_jobs = CNS01.x)\n\n## prc_workforce locally employed = wac c000.x / rac c000\n## prc_workforce in ag = rac cns01.y / rac c000.y\n## prc_jobs in ag = wac cns01.x / wac c000.x\n#wac_rac &lt;- wac_rac %&gt;% \n#  mutate(prc_local = total_jobs/workforce_size) %&gt;% \n#  mutate(prc_wrkf_ag = workforce_ag / workforce_size) %&gt;% \n#  mutate(prc_ag_jobs = ag_jobs / total_jobs)\n\n## prc_population in workforce = rac c000.y / pop\n# left_joined to iowa data frame\n# dividing by pop20 because wac and rac data is from 2020\n#iowa &lt;- iowa %&gt;% \n#  mutate(prc_pop_in_wrkf = workforce_size / pop20) %&gt;% \n#  mutate(prc_pop_employed = total_jobs / pop20)\n\n############################################################################################################\n\n# create a new .csv file for both wac and rac data\nrac_data %&gt;% write.csv(file = \"rac_data.csv\")\nwac_data %&gt;% write.csv(file = \"wac_data.csv\")\n\n\n\nEmployment Data\n\n## Unemployment ##\n##################       \n\n# unemployment data is separated by Age and Sex in API Codes\n# pull first for male employment\nemployment_male &lt;- map_dfr(years, ~{\n  get_acs(\n    geography = \"place\",\n    variable = c(\"Total Labor Force\" = \"B23001_001\",\n                 \"Total Labor Force, Male\" = \"B23001_002\",\n                 \"16 to 19\" = \"B23001_003\",\n                 \"16 to 19, In Armed Forces\" = \"B23001_005\",\n                 \"16 to 19, Employed\" = \"B23001_007\",\n                 \"16 to 19, Unemployed\" = \"B23001_008\",\n                 \"20 to 21\" = \"B23001_010\",\n                 \"20 to 21, In Armed Forces\" = \"B23001_012\",\n                 \"20 to 21, Employed\" = \"B23001_014\",\n                 \"20 to 21, Unemployed\" = \"B23001_015\",\n                 \"22 to 24\" = \"B23001_017\",\n                 \"22 to 24, In Armed Forces\" = \"B23001_019\",\n                 \"22 to 24, Employed\" = \"B23001_021\",\n                 \"22 to 24, Unemployed\" = \"B23001_022\",\n                 \"25 to 29\" = \"B23001_024\",\n                 \"25 to 29, In Armed Forces\" = \"B23001_026\",\n                 \"25 to 29, Employed\" = \"B23001_028\",\n                 \"25 to 29, Unemployed\" = \"B23001_029\",\n                 \"30 to 34\" = \"B23001_031\",\n                 \"30 to 34, In Armed Forces\" = \"B23001_033\",\n                 \"30 to 34, Employed\" = \"B23001_035\",\n                 \"30 to 34, Unemployed\" = \"B23001_036\",\n                 \"35 to 44\" = \"B23001_038\",\n                 \"35 to 44, In Armed Forces\" = \"B23001_040\",\n                 \"35 to 44, Employed\" = \"B23001_042\",\n                 \"35 to 44, Unemployed\" = \"B23001_043\",\n                 \"45 to 54\" = \"B23001_045\",\n                 \"45 to 54, In Armed Forces\" = \"B23001_047\",\n                 \"45 to 54, Employed\" = \"B23001_049\",\n                 \"45 to 54, Unemployed\" = \"B23001_050\",\n                 \"55 to 59\" = \"B23001_052\",\n                 \"55 to 59, In Armed Forces\" = \"B23001_054\",\n                 \"55 to 59, Employed\" = \"B23001_056\",\n                 \"55 to 59, Unemployed\" = \"B23001_057\",\n                 \"60 to 61\" = \"B23001_059\",\n                 \"60 to 61, In Armed Forces\" = \"B23001_061\",\n                 \"60 to 61, Employed\" = \"B23001_063\",\n                 \"60 to 61, Unemployed\" = \"B23001_064\",\n                 \"62 to 64\" = \"B23001_066\",\n                 \"62 to 64, In Armed Forces\" = \"B23001_068\",\n                 \"62 to 64, Employed\" = \"B23001_070\",\n                 \"62 to 64, Unemployed\" = \"B23001_071\",\n                 \"65 to 69\" = \"B23001_073\",\n                 \"65 to 69, Employed\" = \"B23001_075\",\n                 \"65 to 69, Unemployed\" = \"B23001_076\",\n                 \"70 to 74\" = \"B23001_078\",\n                 \"70 to 74, Employed\" = \"B23001_080\",\n                 \"70 to 74, Unemployed\" = \"B23001_081\",\n                 \"75 and Over\" = \"B23001_083\",\n                 \"75 and Over, Employed\" = \"B23001_085\",\n                 \"75 and Over, Unemployed\" = \"B23001_086\"\n    ),\n    state = \"IA\",\n    year = .x,\n    survey = \"acs5\",\n    output = \"wide\"\n  )\n}, .id = \"year\") %&gt;% \n  mutate(gender = \"Male\")\n\nemployment_male &lt;- employment_male %&gt;% \n  mutate(NAME = str_remove(NAME, \" city, Iowa| , Iowa\"))\n\n# now for female employment\nemployment_female &lt;- map_dfr(years, ~{\n  get_acs(\n    geography = \"place\",\n    variable = c(\"Total Labor Force\" = \"B23001_001\",\n                 \"Total Labor Force, Female\" = \"B23001_088\",\n                 \"16 to 19\" = \"B23001_089\",\n                 \"16 to 19, In Armed Forces\" = \"B23001_091\",\n                 \"16 to 19, Employed\" = \"B23001_093\",\n                 \"16 to 19, Unemployed\" = \"B23001_094\",\n                 \"20 to 21\" = \"B23001_096\",\n                 \"20 to 21, In Armed Forces\" = \"B23001_098\",\n                 \"20 to 21, Employed\" = \"B23001_100\",\n                 \"20 to 21, Unemployed\" = \"B23001_101\",\n                 \"22 to 24\" = \"B23001_103\",\n                 \"22 to 24, In Armed Forces\" = \"B23001_105\",\n                 \"22 to 24, Employed\" = \"B23001_107\",\n                 \"22 to 24, Unemployed\" = \"B23001_108\",\n                 \"25 to 29\" = \"B23001_110\",\n                 \"25 to 29, In Armed Forces\" = \"B23001_112\",\n                 \"25 to 29, Employed\" = \"B23001_114\",\n                 \"25 to 29, Unemployed\" = \"B23001_115\",\n                 \"30 to 34\" = \"B23001_117\",\n                 \"30 to 34, In Armed Forces\" = \"B23001_119\",\n                 \"30 to 34, Employed\" = \"B23001_121\",\n                 \"30 to 34, Unemployed\" = \"B23001_122\",\n                 \"35 to 44\" = \"B23001_124\",\n                 \"35 to 44, In Armed Forces\" = \"B23001_126\",\n                 \"35 to 44, Employed\" = \"B23001_128\",\n                 \"35 to 44, Unemployed\" = \"B23001_129\",\n                 \"45 to 54\" = \"B23001_131\",\n                 \"45 to 54, In Armed Forces\" = \"B23001_133\",\n                 \"45 to 54, Employed\" = \"B23001_135\",\n                 \"45 to 54, Unemployed\" = \"B23001_136\",\n                 \"55 to 59\" = \"B23001_138\",\n                 \"55 to 59, In Armed Forces\" = \"B23001_140\",\n                 \"55 to 59, Employed\" = \"B23001_142\",\n                 \"55 to 59, Unemployed\" = \"B23001_143\",\n                 \"60 to 61\" = \"B23001_145\",\n                 \"60 to 61, In Armed Forces\" = \"B23001_147\",\n                 \"60 to 61, Employed\" = \"B23001_149\",\n                 \"60 to 61, Unemployed\" = \"B23001_150\",\n                 \"62 to 64\" = \"B23001_152\",\n                 \"62 to 64, In Armed Forces\" = \"B23001_154\",\n                 \"62 to 64, Employed\" = \"B23001_156\",\n                 \"62 to 64, Unemployed\" = \"B23001_157\",\n                 \"65 to 69\" = \"B23001_159\",\n                 \"65 to 69, Employed\" = \"B23001_161\",\n                 \"65 to 69, Unemployed\" = \"B23001_162\",\n                 \"70 to 74\" = \"B23001_164\",\n                 \"70 to 74, Employed\" = \"B23001_166\",\n                 \"70 to 74, Unemployed\" = \"B23001_167\",\n                 \"75 and Over\" = \"B23001_169\",\n                 \"75 and Over, Employed\" = \"B23001_171\",\n                 \"75 and Over, Unemployed\" = \"B23001_172\"\n    ),\n    state = \"IA\",\n    year = .x,\n    survey = \"acs5\",\n    output = \"wide\"\n  )\n}, .id = \"year\") %&gt;% \n  mutate(gender = \"Female\")\n\nemployment_female &lt;- employment_female %&gt;% \n  mutate(NAME = str_remove(NAME, \" city, Iowa| , Iowa\"))\n\n##########################################################################################################\n\nemployment_female\nemployment_male\n# need to combine these data frames and do further transformations\n# should change to percents to standardize and account for different population sizes\n\n##########################################################################################################\n\n\n\nCommuting Data\n\n## Commuting ##\n###############\n\n# pct population traveling outside of city for work\ntravel &lt;- map_dfr(years, ~{\n  get_acs(\n    geography = \"place\",\n    variable = c(\"total\" = \"B08008_001\",\n                 \"travel\" = \"B08008_004\"), \n    state = \"IA\",\n    year = .x,\n    survey = \"acs5\",\n    output = \"wide\"\n  )\n}, .id = \"year\") %&gt;% \n  mutate(prc_travel = travelE / totalE,\n         travel_moe = (moe_ratio(travelE, totalE, travelM, totalM))) %&gt;% \n  mutate(NAME = str_remove(NAME, \" city, Iowa|, Iowa\"))\n\n\n# rename variables \ntravel &lt;- travel %&gt;% \n  rename(Year = year) %&gt;% \n  rename(\"Total Workforce\" = totalE) %&gt;% \n  rename(\"Workforce Commuting\" = travelE) %&gt;% \n  rename(\"Percent Workforce Commuting\" = prc_travel) %&gt;% \n  rename(\"moe\" = travel_moe) %&gt;% \n  rename(\"Total Workforce moe\" = totalM) %&gt;% \n  rename(\"Workforce Commuting moe\" = travelM)\n\n# create a .csv file for travel data\ntravel %&gt;% write.csv(file = \"commuting_data.csv\")\n\n\n\nIncome Data\n\n## Income ##\n############\n\n# median household income = B19013_001\n\n# pct population traveling outside of city for work\nincome &lt;- map_dfr(years, ~{\n  get_acs(\n    geography = \"place\",\n    variable = c(\"median_income\"=\"B19013_001\"), \n    state = \"IA\",\n    year = .x,\n    survey = \"acs5\",\n    output = \"wide\"\n  )\n}, .id = \"year\") %&gt;% \n  mutate(NAME = str_remove(NAME, \" city, Iowa|, Iowa\"))\n\n\n# figure out how income is changing\n# calculate percent income change\nincome &lt;- income %&gt;% \n  group_by(NAME) %&gt;% \n  mutate(prc_change = (median_incomeE - lag(median_incomeE)) / lag(median_incomeE)) %&gt;%\n  mutate(income_change_label = ifelse(prc_change &gt; 0, \"Positive\", \"Negative\"))\n\n# rename variables \nincome &lt;- income %&gt;% \n  rename(Year = year) %&gt;% \n  rename(\"Median Income\" = median_incomeE) %&gt;% \n  rename(\"Percent Median Income Change\" = prc_change) %&gt;% \n  rename(Label = income_change_label) %&gt;% \n  rename(\"Median Income moe\" = median_incomeM) \n\n# create a .csv file for income data\nincome %&gt;% write.csv(file = \"income_data.csv\")"
  },
  {
    "objectID": "posts/Week_9/Week_9_Analysis.html",
    "href": "posts/Week_9/Week_9_Analysis.html",
    "title": "Guide: Performing a Demographic Analysis",
    "section": "",
    "text": "This blog details the steps in performing a demographic analysis using the coding language R in R Studio and visualizing in Tableau. Examples will come from the demographic analysis I conducted for the 2023 AI Housing Project for Data Science for the Public Good.\nIn short, a demographic analysis is a study of demographic characteristics. According to Oxford Languages (2023), demographic characteristics are “statistical data relating to the population and particular groups within it.”\nSo, why conduct a demographic analysis? Demographic analyses are useful for various things, from finding suitable locations for a new factory to discovering patterns and trends in demographic data. The 2023 AI Housing Project demographic analysis was used to discover places in Iowa that could best benefit from an AI application to evaluate the conditions of the housing stock.\nThere are four steps to a demographic analysis:\n\nDetermine analysis criteria.\nGather data.\nTransform data.\nVisualize data.\n\n\n\n\nThis step is entirely personal. Depending on the nature of your analysis, you will want to analyze different types of demographic data. Your options are, but not limited to, data on age, race, ethnicity, gender, marital status, income, education,and employment. More detailed data is available about each.\nFor the 2023 AI Housing Project, I planned to analyze the following demographic data:\n\nAge\nPopulation size\nHousing\nOccupancy rates\nIncome\nJobs and employment\n\nI chose the following demographic characteristics because they can tell something about the condition of a community. For the 2023 AI Housing Project, I was looking for struggling communities. Typically, struggling communities have a declining population. They can have a higher median age if new individuals are not moving into town and having kids and existing, young residents are moving out. A low median house value and high median house age can also indicate a struggling community. A high median house age can reveal that new housing is not being built in the community. A low median income is not a great sign or a low percent change in income. Employment statistics are important because there will only be money to invest in a community if people are employed. I was interested in the percentage of the workforce that commuted to work because that gives us information on where jobs are located. If people are commuting, there needs to be more jobs in town. A low number of jobs does not encourage population growth.\nFor a more comprehensive analysis, I could also analyze the spatial relationship of healthcare options, daycare options, grocery stores, utilities, restaurants, shops, and schools to places in Iowa. Small, thriving, rural towns have access to at least one or more stated features.\n\n\n\nOnce you have decided on the demographic data you will analyze, it is time to start the data collection process. Many demographic data can be found via the United States Decennial Census or the American Community Survey (ACS). The U.S. census is one of the best places to gather demographic data because it counts every resident in the United States. It has a very low inaccuracy, but the U.S. census is only conducted every ten years. For more recent data, the American Community Survey (ACS) is your best bet. The ACS has more detailed demographic data, and is conducted every five years for the entirety of the United States and every year for places with a population over 65,000. The ACS does not count every individual resident in the United States and instead relies on surveying a proportion of the population to create estimates of the demographics. Thus, it can be inaccurate and provides a margin of error. It is best used for data on the changing population, housing, and workforce.\nYou use the get_decennial() and get_acs() functions included in the Tidycensus package to pull from these data sources in R. Both functions operate off the same set of criteria. You must only specify a geography, variable, and year to pull data.\n\n# install.packages(\"tidyverse\")\n# install.packages(\"tidycensus\")\nlibrary(tidyverse)\nlibrary(tidycensus)\n\n# getting total population\ntotal_population &lt;- get_decennial(geography = \"state\",\n                                  variable = \"P001001\",\n                                  year = 2010)\nhead(total_population)\n\n# A tibble: 6 x 4\n  GEOID NAME       variable    value\n  &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt;       &lt;dbl&gt;\n1 01    Alabama    P001001   4779736\n2 02    Alaska     P001001    710231\n3 04    Arizona    P001001   6392017\n4 05    Arkansas   P001001   2915918\n5 06    California P001001  37253956\n6 22    Louisiana  P001001   4533372\n\n# getting median income\nmedian_income &lt;- get_acs(geography = \"state\",\n                          variable = \"B19013_001\",\n                          year = 2010)\nhead(median_income)\n\n# A tibble: 6 x 5\n  GEOID NAME       variable   estimate   moe\n  &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt;         &lt;dbl&gt; &lt;dbl&gt;\n1 01    Alabama    B19013_001    42081   183\n2 02    Alaska     B19013_001    66521   642\n3 04    Arizona    B19013_001    50448   217\n4 05    Arkansas   B19013_001    39267   283\n5 06    California B19013_001    60883   150\n6 08    Colorado   B19013_001    56456   309\n\n\nThe get_acs() example above is pulling median income data from the 2010 5-Year American Community Survey at the state level. By default, get_acs() will pull data from the 5-Year ACS instead of the 1-Year ACS unless specified with the survey = argument.\n\n# pulling from 1-Year ACS\nmedian_income_1year &lt;- get_acs(geography = \"state\",\n                                variable = \"B19013_001\",\n                                year = 2010,\n                                survey = \"acs1\")\n\nGetting data from the 2010 1-year ACS\n\n\nThe 1-year ACS provides data for geographies with populations of 65,000 and greater.\n\n# pulling from 5-Year ACS\nmedian_income_1year &lt;- get_acs(geography = \"state\",\n                                variable = \"B19013_001\",\n                                year = 2010,\n                                survey = \"acs5\")\n\nGetting data from the 2006-2010 5-year ACS\n\n\nA full list of geographies for the Decennial Census and ACS can be found here. The full list of available Census API variable codes can be found here, and the 5-Year ACS API variable codes can be found here. The API variable codes I used for the demographic analysis are located on a different page on my blog. Further modifications can be made to the get_decennial() and get_acs() functions. To learn more, check out Kyle Walker’s textbook on Tidycensus.\nThe Census and ACS are great data sources, but other sources are often available for specific demographic data. If not pulling data using Tidycensus, you can read data from spreadsheets into R Studio. For example, I used the LEHD Origin-Destination Employment Statistics (LODES) 2020 Workforce Area Characteristics (WAC) and the 2020 Residential Area Characteristics (RAC) data to create more detailed analyses for jobs and the workforce. The WAC and RAC data structure information can be found here.\nThe WAC and RAC data are downloaded as CSV files from their respective locations. To view them in R Studio, you use the function read.csv(). The function read.csv() takes the argument file as a file path to read tabular data.\n\nia_wac.csv &lt;- read.csv(\"C:/Users/Kailyn Hogan/OneDrive - Iowa State University/Documents/GitHub/Housing/demographics/demographic analysis/Datasets/ia_wac_S000_JT00_2020.csv\")\n\nhead(ia_wac.csv)\n\n     w_geocode C000 CA01 CA02 CA03 CE01 CE02 CE03 CNS01 CNS02 CNS03 CNS04 CNS05\n1 1.900196e+14   13    1   10    2    6    7    0     0     0     0     0     0\n2 1.900196e+14   13   11    1    1    9    4    0     0     0     0     0    13\n3 1.900196e+14    7    3    2    2    0    4    3     4     0     0     0     0\n4 1.900196e+14    2    0    0    2    0    0    2     0     0     0     0     0\n5 1.900196e+14    8    5    1    2    2    6    0     0     0     0     0     0\n6 1.900196e+14    4    0    3    1    2    2    0     0     0     0     0     0\n  CNS06 CNS07 CNS08 CNS09 CNS10 CNS11 CNS12 CNS13 CNS14 CNS15 CNS16 CNS17 CNS18\n1     0     0     0     0     0     0     0     0     0     0     0     0    13\n2     0     0     0     0     0     0     0     0     0     0     0     0     0\n3     3     0     0     0     0     0     0     0     0     0     0     0     0\n4     0     0     0     0     2     0     0     0     0     0     0     0     0\n5     0     0     0     0     0     0     0     0     0     0     0     0     8\n6     0     0     0     0     0     0     0     0     0     0     4     0     0\n  CNS19 CNS20 CR01 CR02 CR03 CR04 CR05 CR07 CT01 CT02 CD01 CD02 CD03 CD04 CS01\n1     0     0   13    0    0    0    0    0   12    1    2    7    3    0    0\n2     0     0   13    0    0    0    0    0   13    0    0    1    0    1    1\n3     0     0    7    0    0    0    0    0    7    0    1    1    2    0    5\n4     0     0    2    0    0    0    0    0    2    0    0    1    1    0    2\n5     0     0    7    0    0    1    0    0    5    3    2    1    0    0    5\n6     0     0    4    0    0    0    0    0    4    0    1    0    3    0    0\n  CS02 CFA01 CFA02 CFA03 CFA04 CFA05 CFS01 CFS02 CFS03 CFS04 CFS05 createdate\n1   13     0     0     0     0     0     0     0     0     0     0   20230321\n2   12     0     0     0     0     0     0     0     0     0     0   20230321\n3    2     0     0     0     0     0     0     0     0     0     0   20230321\n4    0     0     0     0     0     0     0     0     0     0     0   20230321\n5    3     0     0     0     0     0     0     0     0     0     0   20230321\n6    4     0     0     0     0     0     0     0     0     0     0   20230321\n\n\nOnce the file is read, it acts like any other data frame in R Studio. The data can be transformed and mutated to your liking.\n\n\n\n\n\nWhen conducting a demographic analysis, or any analysis for that matter, making sure to transform the data in a way that leads to easy visualization is important. Even more important is to ensure the transformation is clear from misleading the viewer.\nI worked with places of different sizes for the 2023 AI Housing Project’s demographic analysis. Initial observations can be inaccurate because the data is not standardized. For example, you cannot accurately compare the number of male individuals under five for Des Moines, Iowa, to Alburnett, Iowa. Des Moines appears to have a much larger proportion of male individuals under five than Alburnett because it is a much larger city in comparison.\n\n# pulling 5-Year ACS estimate for Des Moines\ndsm &lt;- get_acs(geography = \"place\",\n               state = \"IA\",\n               variable = \"B01001_003\",\n               year = 2021) %&gt;% \n  filter(NAME == \"Des Moines city, Iowa\")\n\n# pulling 5-Year ACS estimate for Alburnett\nalburnett &lt;- get_acs(geography = \"place\",\n               state = \"IA\",\n               variable = \"B01001_003\",\n               year = 2021) %&gt;% \n  filter(NAME == \"Alburnett city, Iowa\")\n\nprint(dsm[\"estimate\"])\n\n# A tibble: 1 x 1\n  estimate\n     &lt;dbl&gt;\n1     7468\n\nprint(alburnett[\"estimate\"])\n\n# A tibble: 1 x 1\n  estimate\n     &lt;dbl&gt;\n1       11\n\n\nAn accurate comparison can be derived when the data is standardized and turned into percentages of the total male population. We can see that Des Moines only has a slightly larger percentage of their male population under five than Alburnett.\n\n# pulling male estimate under 5 and total male population for Des Moines\ndsm &lt;- get_acs(geography = \"place\",\n                     state = \"IA\",\n                     variable = c(\"total\" = \"B01001_002\",\n                                  \"under5\" = \"B01001_003\"),\n                     year = 2021,\n                     output = \"wide\") %&gt;% \n  filter(NAME == \"Des Moines city, Iowa\") %&gt;% \n  mutate(percent = under5E / totalE * 100)\n\n# pulling male estimate under 5 and total male population for Alburnett\nalburnett &lt;- get_acs(geography = \"place\",\n                     state = \"IA\",\n                     variable = c(\"total\" = \"B01001_002\",\n                                  \"under5\" = \"B01001_003\"),\n                     year = 2021,\n                     output = \"wide\") %&gt;% \n  filter(NAME == \"Alburnett city, Iowa\") %&gt;% \n  mutate(percent = under5E / totalE * 100)\n\nprint(dsm[\"percent\"])\n\n# A tibble: 1 x 1\n  percent\n    &lt;dbl&gt;\n1    7.13\n\nprint(alburnett[\"percent\"])\n\n# A tibble: 1 x 1\n  percent\n    &lt;dbl&gt;\n1    3.03\n\n\nThus, standardization of data is important for an accurate analysis later on. The easiest way to standardize data is to change it into percentages.\n\n\n\nLet’s run through an example of transforming the data. For this example, we will be pulling the variables for Total Population by Age and Sex to create a new data frame that contains only the percentage of the population under eighteen and over sixty-five separated by sex. The Decennial Census and the ACS break up age groups seemingly haphazardly, so there is no easy variable to pull the total population under eighteen and over sixty-five. To get these statistics, we must pull the age groups that fall into these categories and then sum them to get the total. To start, let’s pull the variables from the 5-Year ACS.\n\n# pull ACS estimates for male\nmale &lt;- get_acs(geography = \"place\",\n                state = \"IA\",\n                variable = c(\"under5\" = \"B01001_003\",\n                             \"a5to9\" = \"B01001_004\",\n                             \"a10to14\" = \"B01001_005\",\n                             \"a15to17\" = \"B01001_006\",\n                             \"a65to66\" = \"B01001_020\",\n                             \"a67to69\" = \"B01001_021\",\n                             \"a70to74\" = \"B01001_022\",\n                             \"a75to79\" = \"B01001_023\",\n                             \"a80to84\" = \"B01001_024\",\n                             \"over85\" = \"B01001_025\",\n                             \"total\" = \"B01001_002\"),\n                year = 2021,\n                output = \"wide\") %&gt;% \n  mutate(NAME = str_remove(NAME, \" city, Iowa\"))\n  \n# now pull estimates for female\nfemale &lt;- get_acs(geography = \"place\",\n                state = \"IA\",\n                variable = c(\"under5\" = \"B01001_027\",\n                             \"a5to9\" = \"B01001_028\",\n                             \"a10to14\" = \"B01001_029\",\n                             \"a15to17\" = \"B01001_030\",\n                             \"a65to66\" = \"B01001_044\",\n                             \"a67to69\" = \"B01001_045\",\n                             \"a70to74\" = \"B01001_046\",\n                             \"a75to79\" = \"B01001_047\",\n                             \"a80to84\" = \"B01001_048\",\n                             \"over85\" = \"B01001_049\",\n                             \"total\" = \"B01001_026\"),\n                year = 2021,\n                output = \"wide\")%&gt;% \n  mutate(NAME = str_remove(NAME, \" city, Iowa\"))\n\nI have gone through and named the variables so that finding the total will be more intuitive. Now let’s add the age groups together to get the total population. When summing the variables, we want to remember that ACS data are estimates. They are not full counts of the population and, thus, have margins of error. We must also calculate a margin of error for the total population.\n\n# create new columns for under18 and over 65 for both male and female\n# create new columns for the new margins of error\nmale &lt;- male %&gt;% \n  mutate(under18E = round(under5E + a5to9E + a10to14E + a15to17E)) %&gt;%\n  mutate(under18M = round(sqrt(under5M^2 + a5to9M^2 + a10to14M^2 + a15to17M^2))) %&gt;%\n  mutate(over65E = round(a65to66E + a67to69E + a70to74E + a75to79E + a80to84E + over85E)) %&gt;%\n  mutate(over65M =  round(sqrt(a65to66M^2 + a67to69M^2 + a70to74M^2 + a75to79M^2 + a80to84M^2 + over85M^2)))\n\nfemale &lt;- female %&gt;% \n  mutate(under18E = round(under5E + a5to9E + a10to14E + a15to17E)) %&gt;%\n  mutate(under18M = round(sqrt(under5M^2 + a5to9M^2 + a10to14M^2 + a15to17M^2))) %&gt;%\n  mutate(over65E = round(a65to66E + a67to69E + a70to74E + a75to79E + a80to84E + over85E)) %&gt;%\n  mutate(over65M =  round(sqrt(a65to66M^2 + a67to69M^2 + a70to74M^2 + a75to79M^2 + a80to84M^2 + over85M^2)))\n\nLet’s also add a column for gender so we know what values are which.\n\n# add a new column for gender\nmale &lt;- male %&gt;% mutate(gender = \"Male\")\nfemale &lt;- female %&gt;% mutate(gender= \"Female\")\n\nNow that we have the gender defined and the total populations under eighteen and over sixty-five, we can combine the data frames and calculate the percentages. To calculate the percentages of the population under eighteen and over sixty-five, we will use the summarize() function. We will combine it with the group_by() function to make sure the percentages are calculated by sex.\n\n# combine the data frames\nage &lt;- female %&gt;% \n  bind_rows(male)\n\n# group by gender\n# create new columns for percent under 18 and percent over 65 using summarize()\nsum_age &lt;- age %&gt;% \n  group_by(NAME,gender) %&gt;% \n             summarize(prc_under18E = sum(under18E)/sum(totalE),\n                       prc_under18M = sqrt(sum(under18M^2) / sum(totalE)^2 + (sum(under18E)^2 * sum(totalM^2)) / sum(totalE)^4),\n                       prc_over65E = sum(over65E)/sum(totalE),\n                       prc_over65M = sqrt(sum(over65M^2) / sum(totalE)^2 + (sum(over65E)^2 * sum(totalM^2)) / sum(totalE)^4))\n\n`summarise()` has grouped output by 'NAME'. You can override using the\n`.groups` argument.\n\nsum_age\n\n# A tibble: 2,056 x 6\n# Groups:   NAME [1,028]\n   NAME     gender prc_under18E prc_under18M prc_over65E prc_over65M\n   &lt;chr&gt;    &lt;chr&gt;         &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n 1 Ackley   Female        0.238       0.0604      0.247       0.0627\n 2 Ackley   Male          0.233       0.0648      0.154       0.0400\n 3 Ackworth Female        0.422       0.323       0.144       0.223 \n 4 Ackworth Male          0.207       0.254       0.190       0.352 \n 5 Adair    Female        0.252       0.130       0.204       0.0918\n 6 Adair    Male          0.229       0.121       0.132       0.0686\n 7 Adel     Female        0.242       0.0650      0.135       0.0440\n 8 Adel     Male          0.337       0.0776      0.0911      0.0331\n 9 Afton    Female        0.257       0.115       0.265       0.101 \n10 Afton    Male          0.199       0.0931      0.149       0.0785\n# i 2,046 more rows\n\n\nThe resulting data frame, sum_age, holds the percent population under eighteen and over sixty-five for all places in Iowa.\nWHAT DID I TRANSFORM FOR MY ANALYSIS ??!?!?!?!?!?!?!!\n\n\n\n\nWe will switch to Tableau for the data visualization portion of the demographic analysis. Tableau is a data analytics software used to create visualizations. R Studio can also create visualizations, but it is much more basic. R Studio excels in making standard visualizations, while Tableau can create stories that bring the data visualizations to life, and users can fully interact with them.\nTableau creates visualizations based on data found in spreadsheets. It will accept both Excel files and CSV files. We will turn our collected data into CSV files for further visualization in Tableau.\nTo convert our data frames of collected data into CSV files, we will use the function write.csv(). The function write.csv() takes the arguments x and file. X relates to the object to be written, and file represents the name of the new CSV file.\n\n# write sum_age data frame as a CSV\nwrite.csv(sum_age, file = \"sum_age.csv\")\n\nOpening a CSV file in Tableau is simple. On the start screen of Tableau Desktop, click on File and then click Open. You can search your computer’s files for a CSV or Excel file to import into Tableau.\n\n\n\nOpen a new file in Tableau.\n\n\nOnce the file is opened, your screen should look something like this. The sum_age.csv file is now open in Tableau Desktop, and I can view my data.\n\n\n\nOpened data source screen in Tableau.\n\n\nWe could have given our columns better names when creating the sum_age.csv file. Fortunately, we can go through and rename the variables in Tableau. Double-click a column name to highlight it, then enter the new name. In the example below, I renamed prc_under18E to “Percent Under 18” and prc_over65E to “Percent Over 65”. You can also hide unnecessary columns by right-clicking on them and selecting Hide. For this visualization, I hid prc_under18M and prc_over65M.\n\n\n\nRename and hide variables.\n\n\nNow that our data is more organized, we can start creating visualizations. Visualizations are made in Sheets in Tableau. To create a visualization, click on Sheet 1. Click and drag Percent Over 65 to Tableau’s Rows section and Name to the Columns section. A bar chart will automatically be made. Tableau will aggregate Percent Over 65 as a sum by default. There are other options for aggregation in Tableau - median, average, min, max, etc. - but sum works just fine for this visualization.\n\n\n\nCreate a bar chart.\n\n\nThis bar chart is fine but only tells a little about the data. To add more information, let’s add the Gender to represent the color and shape of the bars.\n\n\n\nAdd gender to the bar chart and represent it by size and color.\n\n\nMuch better! Now we can see how much of the percentage is for the Female and Male populations. Let’s also add a reference line for the median percent of the total population over sixty-five for all places in Iowa. To add a reference line:\n\nGo to the Analytics tab.\nClick and drag Reference Line to the bar chart pane. You will get a pop-up that asks how you want the reference line calculated.\nChoose Table.\n\n\n\n\nAdd a reference line for median percent over sixty-five.\n\n\nA reference line pane will pop up. Leave all values the same, but change the Fill Below section to a light gray. Coloring in the bottom portion of the chart will highlight the places in Iowa that fall below the average percentage of the population over sixty-five.\n\n\n\nShade the lower section of the reference line.\n\n\nWell done! You have created your first visualization in Tableau.\n\n\n\n\n\nYou can create dashboards and stories in Tableau like this one with a little more practice.\n[insert story] !!!!!!!!!!!!!!!!!!!!!!!!!\nCreating visualizations like the one above aid in the demographic process by allowing you to see the patterns and trends in the data. You can draw conclusions about a specific state, place, or location by visualizing multiple demographics.\n\n\n\nwhat can we derive from the created visualization?\nIMAGES OF YOUR VISUALIZATIONS !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
  },
  {
    "objectID": "posts/Week_9/Week_9_Analysis.html#introduction",
    "href": "posts/Week_9/Week_9_Analysis.html#introduction",
    "title": "Guide: Performing a Demographic Analysis",
    "section": "",
    "text": "This blog details the steps in performing a demographic analysis using the coding language R in R Studio and visualizing in Tableau. Examples will come from the demographic analysis I conducted for the 2023 AI Housing Project for Data Science for the Public Good.\nIn short, a demographic analysis is a study of demographic characteristics. According to Oxford Languages (2023), demographic characteristics are “statistical data relating to the population and particular groups within it.”\nSo, why conduct a demographic analysis? Demographic analyses are useful for various things, from finding suitable locations for a new factory to discovering patterns and trends in demographic data. The 2023 AI Housing Project demographic analysis was used to discover places in Iowa that could best benefit from an AI application to evaluate the conditions of the housing stock.\nThere are four steps to a demographic analysis:\n\nDetermine analysis criteria.\nGather data.\nTransform data.\nVisualize data."
  },
  {
    "objectID": "posts/Week_9/Week_9_Analysis.html#determining-analysis-criteria",
    "href": "posts/Week_9/Week_9_Analysis.html#determining-analysis-criteria",
    "title": "Guide: Performing a Demographic Analysis",
    "section": "",
    "text": "This step is entirely personal. Depending on the nature of your analysis, you will want to analyze different types of demographic data. Your options are, but not limited to, data on age, race, ethnicity, gender, marital status, income, education,and employment. More detailed data is available about each.\nFor the 2023 AI Housing Project, I planned to analyze the following demographic data:\n\nAge\nPopulation size\nHousing\nOccupancy rates\nIncome\nJobs and employment\n\nI chose the following demographic characteristics because they can tell something about the condition of a community. For the 2023 AI Housing Project, I was looking for struggling communities. Typically, struggling communities have a declining population. They can have a higher median age if new individuals are not moving into town and having kids and existing, young residents are moving out. A low median house value and high median house age can also indicate a struggling community. A high median house age can reveal that new housing is not being built in the community. A low median income is not a great sign or a low percent change in income. Employment statistics are important because there will only be money to invest in a community if people are employed. I was interested in the percentage of the workforce that commuted to work because that gives us information on where jobs are located. If people are commuting, there needs to be more jobs in town. A low number of jobs does not encourage population growth.\nFor a more comprehensive analysis, I could also analyze the spatial relationship of healthcare options, daycare options, grocery stores, utilities, restaurants, shops, and schools to places in Iowa. Small, thriving, rural towns have access to at least one or more stated features."
  },
  {
    "objectID": "posts/Week_9/Week_9_Analysis.html#gathering-data",
    "href": "posts/Week_9/Week_9_Analysis.html#gathering-data",
    "title": "Guide: Performing a Demographic Analysis",
    "section": "",
    "text": "Once you have decided on the demographic data you will analyze, it is time to start the data collection process. Many demographic data can be found via the United States Decennial Census or the American Community Survey (ACS). The U.S. census is one of the best places to gather demographic data because it counts every resident in the United States. It has a very low inaccuracy, but the U.S. census is only conducted every ten years. For more recent data, the American Community Survey (ACS) is your best bet. The ACS has more detailed demographic data, and is conducted every five years for the entirety of the United States and every year for places with a population over 65,000. The ACS does not count every individual resident in the United States and instead relies on surveying a proportion of the population to create estimates of the demographics. Thus, it can be inaccurate and provides a margin of error. It is best used for data on the changing population, housing, and workforce.\nYou use the get_decennial() and get_acs() functions included in the Tidycensus package to pull from these data sources in R. Both functions operate off the same set of criteria. You must only specify a geography, variable, and year to pull data.\n\n# install.packages(\"tidyverse\")\n# install.packages(\"tidycensus\")\nlibrary(tidyverse)\nlibrary(tidycensus)\n\n# getting total population\ntotal_population &lt;- get_decennial(geography = \"state\",\n                                  variable = \"P001001\",\n                                  year = 2010)\nhead(total_population)\n\n# A tibble: 6 x 4\n  GEOID NAME       variable    value\n  &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt;       &lt;dbl&gt;\n1 01    Alabama    P001001   4779736\n2 02    Alaska     P001001    710231\n3 04    Arizona    P001001   6392017\n4 05    Arkansas   P001001   2915918\n5 06    California P001001  37253956\n6 22    Louisiana  P001001   4533372\n\n# getting median income\nmedian_income &lt;- get_acs(geography = \"state\",\n                          variable = \"B19013_001\",\n                          year = 2010)\nhead(median_income)\n\n# A tibble: 6 x 5\n  GEOID NAME       variable   estimate   moe\n  &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt;         &lt;dbl&gt; &lt;dbl&gt;\n1 01    Alabama    B19013_001    42081   183\n2 02    Alaska     B19013_001    66521   642\n3 04    Arizona    B19013_001    50448   217\n4 05    Arkansas   B19013_001    39267   283\n5 06    California B19013_001    60883   150\n6 08    Colorado   B19013_001    56456   309\n\n\nThe get_acs() example above is pulling median income data from the 2010 5-Year American Community Survey at the state level. By default, get_acs() will pull data from the 5-Year ACS instead of the 1-Year ACS unless specified with the survey = argument.\n\n# pulling from 1-Year ACS\nmedian_income_1year &lt;- get_acs(geography = \"state\",\n                                variable = \"B19013_001\",\n                                year = 2010,\n                                survey = \"acs1\")\n\nGetting data from the 2010 1-year ACS\n\n\nThe 1-year ACS provides data for geographies with populations of 65,000 and greater.\n\n# pulling from 5-Year ACS\nmedian_income_1year &lt;- get_acs(geography = \"state\",\n                                variable = \"B19013_001\",\n                                year = 2010,\n                                survey = \"acs5\")\n\nGetting data from the 2006-2010 5-year ACS\n\n\nA full list of geographies for the Decennial Census and ACS can be found here. The full list of available Census API variable codes can be found here, and the 5-Year ACS API variable codes can be found here. The API variable codes I used for the demographic analysis are located on a different page on my blog. Further modifications can be made to the get_decennial() and get_acs() functions. To learn more, check out Kyle Walker’s textbook on Tidycensus.\nThe Census and ACS are great data sources, but other sources are often available for specific demographic data. If not pulling data using Tidycensus, you can read data from spreadsheets into R Studio. For example, I used the LEHD Origin-Destination Employment Statistics (LODES) 2020 Workforce Area Characteristics (WAC) and the 2020 Residential Area Characteristics (RAC) data to create more detailed analyses for jobs and the workforce. The WAC and RAC data structure information can be found here.\nThe WAC and RAC data are downloaded as CSV files from their respective locations. To view them in R Studio, you use the function read.csv(). The function read.csv() takes the argument file as a file path to read tabular data.\n\nia_wac.csv &lt;- read.csv(\"C:/Users/Kailyn Hogan/OneDrive - Iowa State University/Documents/GitHub/Housing/demographics/demographic analysis/Datasets/ia_wac_S000_JT00_2020.csv\")\n\nhead(ia_wac.csv)\n\n     w_geocode C000 CA01 CA02 CA03 CE01 CE02 CE03 CNS01 CNS02 CNS03 CNS04 CNS05\n1 1.900196e+14   13    1   10    2    6    7    0     0     0     0     0     0\n2 1.900196e+14   13   11    1    1    9    4    0     0     0     0     0    13\n3 1.900196e+14    7    3    2    2    0    4    3     4     0     0     0     0\n4 1.900196e+14    2    0    0    2    0    0    2     0     0     0     0     0\n5 1.900196e+14    8    5    1    2    2    6    0     0     0     0     0     0\n6 1.900196e+14    4    0    3    1    2    2    0     0     0     0     0     0\n  CNS06 CNS07 CNS08 CNS09 CNS10 CNS11 CNS12 CNS13 CNS14 CNS15 CNS16 CNS17 CNS18\n1     0     0     0     0     0     0     0     0     0     0     0     0    13\n2     0     0     0     0     0     0     0     0     0     0     0     0     0\n3     3     0     0     0     0     0     0     0     0     0     0     0     0\n4     0     0     0     0     2     0     0     0     0     0     0     0     0\n5     0     0     0     0     0     0     0     0     0     0     0     0     8\n6     0     0     0     0     0     0     0     0     0     0     4     0     0\n  CNS19 CNS20 CR01 CR02 CR03 CR04 CR05 CR07 CT01 CT02 CD01 CD02 CD03 CD04 CS01\n1     0     0   13    0    0    0    0    0   12    1    2    7    3    0    0\n2     0     0   13    0    0    0    0    0   13    0    0    1    0    1    1\n3     0     0    7    0    0    0    0    0    7    0    1    1    2    0    5\n4     0     0    2    0    0    0    0    0    2    0    0    1    1    0    2\n5     0     0    7    0    0    1    0    0    5    3    2    1    0    0    5\n6     0     0    4    0    0    0    0    0    4    0    1    0    3    0    0\n  CS02 CFA01 CFA02 CFA03 CFA04 CFA05 CFS01 CFS02 CFS03 CFS04 CFS05 createdate\n1   13     0     0     0     0     0     0     0     0     0     0   20230321\n2   12     0     0     0     0     0     0     0     0     0     0   20230321\n3    2     0     0     0     0     0     0     0     0     0     0   20230321\n4    0     0     0     0     0     0     0     0     0     0     0   20230321\n5    3     0     0     0     0     0     0     0     0     0     0   20230321\n6    4     0     0     0     0     0     0     0     0     0     0   20230321\n\n\nOnce the file is read, it acts like any other data frame in R Studio. The data can be transformed and mutated to your liking."
  },
  {
    "objectID": "posts/Week_9/Week_9_Analysis.html#transforming-the-collected-data",
    "href": "posts/Week_9/Week_9_Analysis.html#transforming-the-collected-data",
    "title": "Guide: Performing a Demographic Analysis",
    "section": "",
    "text": "When conducting a demographic analysis, or any analysis for that matter, making sure to transform the data in a way that leads to easy visualization is important. Even more important is to ensure the transformation is clear from misleading the viewer.\nI worked with places of different sizes for the 2023 AI Housing Project’s demographic analysis. Initial observations can be inaccurate because the data is not standardized. For example, you cannot accurately compare the number of male individuals under five for Des Moines, Iowa, to Alburnett, Iowa. Des Moines appears to have a much larger proportion of male individuals under five than Alburnett because it is a much larger city in comparison.\n\n# pulling 5-Year ACS estimate for Des Moines\ndsm &lt;- get_acs(geography = \"place\",\n               state = \"IA\",\n               variable = \"B01001_003\",\n               year = 2021) %&gt;% \n  filter(NAME == \"Des Moines city, Iowa\")\n\n# pulling 5-Year ACS estimate for Alburnett\nalburnett &lt;- get_acs(geography = \"place\",\n               state = \"IA\",\n               variable = \"B01001_003\",\n               year = 2021) %&gt;% \n  filter(NAME == \"Alburnett city, Iowa\")\n\nprint(dsm[\"estimate\"])\n\n# A tibble: 1 x 1\n  estimate\n     &lt;dbl&gt;\n1     7468\n\nprint(alburnett[\"estimate\"])\n\n# A tibble: 1 x 1\n  estimate\n     &lt;dbl&gt;\n1       11\n\n\nAn accurate comparison can be derived when the data is standardized and turned into percentages of the total male population. We can see that Des Moines only has a slightly larger percentage of their male population under five than Alburnett.\n\n# pulling male estimate under 5 and total male population for Des Moines\ndsm &lt;- get_acs(geography = \"place\",\n                     state = \"IA\",\n                     variable = c(\"total\" = \"B01001_002\",\n                                  \"under5\" = \"B01001_003\"),\n                     year = 2021,\n                     output = \"wide\") %&gt;% \n  filter(NAME == \"Des Moines city, Iowa\") %&gt;% \n  mutate(percent = under5E / totalE * 100)\n\n# pulling male estimate under 5 and total male population for Alburnett\nalburnett &lt;- get_acs(geography = \"place\",\n                     state = \"IA\",\n                     variable = c(\"total\" = \"B01001_002\",\n                                  \"under5\" = \"B01001_003\"),\n                     year = 2021,\n                     output = \"wide\") %&gt;% \n  filter(NAME == \"Alburnett city, Iowa\") %&gt;% \n  mutate(percent = under5E / totalE * 100)\n\nprint(dsm[\"percent\"])\n\n# A tibble: 1 x 1\n  percent\n    &lt;dbl&gt;\n1    7.13\n\nprint(alburnett[\"percent\"])\n\n# A tibble: 1 x 1\n  percent\n    &lt;dbl&gt;\n1    3.03\n\n\nThus, standardization of data is important for an accurate analysis later on. The easiest way to standardize data is to change it into percentages.\n\n\n\nLet’s run through an example of transforming the data. For this example, we will be pulling the variables for Total Population by Age and Sex to create a new data frame that contains only the percentage of the population under eighteen and over sixty-five separated by sex. The Decennial Census and the ACS break up age groups seemingly haphazardly, so there is no easy variable to pull the total population under eighteen and over sixty-five. To get these statistics, we must pull the age groups that fall into these categories and then sum them to get the total. To start, let’s pull the variables from the 5-Year ACS.\n\n# pull ACS estimates for male\nmale &lt;- get_acs(geography = \"place\",\n                state = \"IA\",\n                variable = c(\"under5\" = \"B01001_003\",\n                             \"a5to9\" = \"B01001_004\",\n                             \"a10to14\" = \"B01001_005\",\n                             \"a15to17\" = \"B01001_006\",\n                             \"a65to66\" = \"B01001_020\",\n                             \"a67to69\" = \"B01001_021\",\n                             \"a70to74\" = \"B01001_022\",\n                             \"a75to79\" = \"B01001_023\",\n                             \"a80to84\" = \"B01001_024\",\n                             \"over85\" = \"B01001_025\",\n                             \"total\" = \"B01001_002\"),\n                year = 2021,\n                output = \"wide\") %&gt;% \n  mutate(NAME = str_remove(NAME, \" city, Iowa\"))\n  \n# now pull estimates for female\nfemale &lt;- get_acs(geography = \"place\",\n                state = \"IA\",\n                variable = c(\"under5\" = \"B01001_027\",\n                             \"a5to9\" = \"B01001_028\",\n                             \"a10to14\" = \"B01001_029\",\n                             \"a15to17\" = \"B01001_030\",\n                             \"a65to66\" = \"B01001_044\",\n                             \"a67to69\" = \"B01001_045\",\n                             \"a70to74\" = \"B01001_046\",\n                             \"a75to79\" = \"B01001_047\",\n                             \"a80to84\" = \"B01001_048\",\n                             \"over85\" = \"B01001_049\",\n                             \"total\" = \"B01001_026\"),\n                year = 2021,\n                output = \"wide\")%&gt;% \n  mutate(NAME = str_remove(NAME, \" city, Iowa\"))\n\nI have gone through and named the variables so that finding the total will be more intuitive. Now let’s add the age groups together to get the total population. When summing the variables, we want to remember that ACS data are estimates. They are not full counts of the population and, thus, have margins of error. We must also calculate a margin of error for the total population.\n\n# create new columns for under18 and over 65 for both male and female\n# create new columns for the new margins of error\nmale &lt;- male %&gt;% \n  mutate(under18E = round(under5E + a5to9E + a10to14E + a15to17E)) %&gt;%\n  mutate(under18M = round(sqrt(under5M^2 + a5to9M^2 + a10to14M^2 + a15to17M^2))) %&gt;%\n  mutate(over65E = round(a65to66E + a67to69E + a70to74E + a75to79E + a80to84E + over85E)) %&gt;%\n  mutate(over65M =  round(sqrt(a65to66M^2 + a67to69M^2 + a70to74M^2 + a75to79M^2 + a80to84M^2 + over85M^2)))\n\nfemale &lt;- female %&gt;% \n  mutate(under18E = round(under5E + a5to9E + a10to14E + a15to17E)) %&gt;%\n  mutate(under18M = round(sqrt(under5M^2 + a5to9M^2 + a10to14M^2 + a15to17M^2))) %&gt;%\n  mutate(over65E = round(a65to66E + a67to69E + a70to74E + a75to79E + a80to84E + over85E)) %&gt;%\n  mutate(over65M =  round(sqrt(a65to66M^2 + a67to69M^2 + a70to74M^2 + a75to79M^2 + a80to84M^2 + over85M^2)))\n\nLet’s also add a column for gender so we know what values are which.\n\n# add a new column for gender\nmale &lt;- male %&gt;% mutate(gender = \"Male\")\nfemale &lt;- female %&gt;% mutate(gender= \"Female\")\n\nNow that we have the gender defined and the total populations under eighteen and over sixty-five, we can combine the data frames and calculate the percentages. To calculate the percentages of the population under eighteen and over sixty-five, we will use the summarize() function. We will combine it with the group_by() function to make sure the percentages are calculated by sex.\n\n# combine the data frames\nage &lt;- female %&gt;% \n  bind_rows(male)\n\n# group by gender\n# create new columns for percent under 18 and percent over 65 using summarize()\nsum_age &lt;- age %&gt;% \n  group_by(NAME,gender) %&gt;% \n             summarize(prc_under18E = sum(under18E)/sum(totalE),\n                       prc_under18M = sqrt(sum(under18M^2) / sum(totalE)^2 + (sum(under18E)^2 * sum(totalM^2)) / sum(totalE)^4),\n                       prc_over65E = sum(over65E)/sum(totalE),\n                       prc_over65M = sqrt(sum(over65M^2) / sum(totalE)^2 + (sum(over65E)^2 * sum(totalM^2)) / sum(totalE)^4))\n\n`summarise()` has grouped output by 'NAME'. You can override using the\n`.groups` argument.\n\nsum_age\n\n# A tibble: 2,056 x 6\n# Groups:   NAME [1,028]\n   NAME     gender prc_under18E prc_under18M prc_over65E prc_over65M\n   &lt;chr&gt;    &lt;chr&gt;         &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n 1 Ackley   Female        0.238       0.0604      0.247       0.0627\n 2 Ackley   Male          0.233       0.0648      0.154       0.0400\n 3 Ackworth Female        0.422       0.323       0.144       0.223 \n 4 Ackworth Male          0.207       0.254       0.190       0.352 \n 5 Adair    Female        0.252       0.130       0.204       0.0918\n 6 Adair    Male          0.229       0.121       0.132       0.0686\n 7 Adel     Female        0.242       0.0650      0.135       0.0440\n 8 Adel     Male          0.337       0.0776      0.0911      0.0331\n 9 Afton    Female        0.257       0.115       0.265       0.101 \n10 Afton    Male          0.199       0.0931      0.149       0.0785\n# i 2,046 more rows\n\n\nThe resulting data frame, sum_age, holds the percent population under eighteen and over sixty-five for all places in Iowa.\nWHAT DID I TRANSFORM FOR MY ANALYSIS ??!?!?!?!?!?!?!!"
  },
  {
    "objectID": "posts/Week_9/Week_9_Analysis.html#data-visualization",
    "href": "posts/Week_9/Week_9_Analysis.html#data-visualization",
    "title": "Guide: Performing a Demographic Analysis",
    "section": "",
    "text": "We will switch to Tableau for the data visualization portion of the demographic analysis. Tableau is a data analytics software used to create visualizations. R Studio can also create visualizations, but it is much more basic. R Studio excels in making standard visualizations, while Tableau can create stories that bring the data visualizations to life, and users can fully interact with them.\nTableau creates visualizations based on data found in spreadsheets. It will accept both Excel files and CSV files. We will turn our collected data into CSV files for further visualization in Tableau.\nTo convert our data frames of collected data into CSV files, we will use the function write.csv(). The function write.csv() takes the arguments x and file. X relates to the object to be written, and file represents the name of the new CSV file.\n\n# write sum_age data frame as a CSV\nwrite.csv(sum_age, file = \"sum_age.csv\")\n\nOpening a CSV file in Tableau is simple. On the start screen of Tableau Desktop, click on File and then click Open. You can search your computer’s files for a CSV or Excel file to import into Tableau.\n\n\n\nOpen a new file in Tableau.\n\n\nOnce the file is opened, your screen should look something like this. The sum_age.csv file is now open in Tableau Desktop, and I can view my data.\n\n\n\nOpened data source screen in Tableau.\n\n\nWe could have given our columns better names when creating the sum_age.csv file. Fortunately, we can go through and rename the variables in Tableau. Double-click a column name to highlight it, then enter the new name. In the example below, I renamed prc_under18E to “Percent Under 18” and prc_over65E to “Percent Over 65”. You can also hide unnecessary columns by right-clicking on them and selecting Hide. For this visualization, I hid prc_under18M and prc_over65M.\n\n\n\nRename and hide variables.\n\n\nNow that our data is more organized, we can start creating visualizations. Visualizations are made in Sheets in Tableau. To create a visualization, click on Sheet 1. Click and drag Percent Over 65 to Tableau’s Rows section and Name to the Columns section. A bar chart will automatically be made. Tableau will aggregate Percent Over 65 as a sum by default. There are other options for aggregation in Tableau - median, average, min, max, etc. - but sum works just fine for this visualization.\n\n\n\nCreate a bar chart.\n\n\nThis bar chart is fine but only tells a little about the data. To add more information, let’s add the Gender to represent the color and shape of the bars.\n\n\n\nAdd gender to the bar chart and represent it by size and color.\n\n\nMuch better! Now we can see how much of the percentage is for the Female and Male populations. Let’s also add a reference line for the median percent of the total population over sixty-five for all places in Iowa. To add a reference line:\n\nGo to the Analytics tab.\nClick and drag Reference Line to the bar chart pane. You will get a pop-up that asks how you want the reference line calculated.\nChoose Table.\n\n\n\n\nAdd a reference line for median percent over sixty-five.\n\n\nA reference line pane will pop up. Leave all values the same, but change the Fill Below section to a light gray. Coloring in the bottom portion of the chart will highlight the places in Iowa that fall below the average percentage of the population over sixty-five.\n\n\n\nShade the lower section of the reference line.\n\n\nWell done! You have created your first visualization in Tableau.\n\n\n\n\n\nYou can create dashboards and stories in Tableau like this one with a little more practice.\n[insert story] !!!!!!!!!!!!!!!!!!!!!!!!!\nCreating visualizations like the one above aid in the demographic process by allowing you to see the patterns and trends in the data. You can draw conclusions about a specific state, place, or location by visualizing multiple demographics."
  },
  {
    "objectID": "posts/Week_9/Week_9_Analysis.html#final-analysis",
    "href": "posts/Week_9/Week_9_Analysis.html#final-analysis",
    "title": "Guide: Performing a Demographic Analysis",
    "section": "",
    "text": "what can we derive from the created visualization?\nIMAGES OF YOUR VISUALIZATIONS !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
  },
  {
    "objectID": "posts/Week_9/Week_9_Demo.html",
    "href": "posts/Week_9/Week_9_Demo.html",
    "title": "Guide: Creating a Demographic Profile",
    "section": "",
    "text": "This blog will outline creating a demographic profile in R Studio. If you have read my guide on Performing a Demographic Analysis, note that creating a demographic profile is similar. Profiles are similar to analyses because demographic profiles are, in essence, just a different type of demographic analysis. The contrast is that profiles focus on a specific group instead of a broad area.\nFor this guide, I will walk you through creating a demographic profile for the 2023 AI Housing Project for Data Science for the Public Good. The demographic profile comprised three cities: Grundy Center, Independence, and New Hampton.\nThere are five steps in a demographic profile:\n\nDetermine the focus area.\nDecide demographic data.\nGather data.\nTransform data.\nVisualize data.\n\n\n\nThe first step in creating a demographic profile is determining your focus area. For the example profile, the focus area was the cities included in the WINVEST project of Data Science for the Public Good. WINVEST conducted a windshield survey of Grundy Center, Independence, and New Hampton. The demographic profile I created is intended to enhance the data from the windshield survey.\nI decided to add further detail to my demographic analysis by gathering data on the state, region, and nation associated with my focus areas. These additional geographies add context to the original focus area.\nIn total, I decided to gather data on the following areas:\n\nGrundy Center\nIndependence\nNew Hampton\nIowa\nMidwest\nUnited States\n\n\n\n\nThe data you decide to gather for your demographic profile makes the profile. Your options for demographic data are but are not limited to, data on age, race, ethnicity, gender, marital status, income, education, and employment. More detailed data is available about each.\nI decided to gather data on the following demographics for the example profile:\n\nPopulation\nMedian income\nMedian home value\nMedian year home built\nHousing occupancy\nReason for vacancy\n\nData on housing was very important to me. The WINVEST project’s windshield survey was on the housing stock condition in the focus area communities. Thus, I wanted to gather available information on the housing stock from the Decennial Census and the American Community Survey. I chose median home value, median year built, and housing occupancy data because they give a well-rounded analysis of the housing demographics.\n\n\n\nOnce you have decided on the demographic data you want, it is time to start the data collection process. Many demographic data can be found via the United States Decennial Census or the American Community Survey (ACS). The U.S. census is one of the best places to gather demographic data because it counts every resident in the United States. It has a very low inaccuracy, but the U.S. census is only conducted every ten years. The American Community Survey (ACS) is your best bet for more recent data. The ACS has more detailed demographic data and is conducted every five years for the entirety of the United States and every year for places with a population over 65,000. The ACS does not count every individual resident in the United States and instead relies on surveying a proportion of the population to create estimates of the demographics. Thus, it can be inaccurate and provides a margin of error. It is best used for data on the changing population, housing, and workforce.\nTo start data collection in R Studio, I installed the Tidyverse and Tidycensus packages and loaded them with the library() function.\n\ninstall.packages(\"tidyverse\")\ninstall.packages(\"tidycensus\")\n\n\nlibrary(tidyverse)\nlibrary(tidycensus)\n\nThe Tidyverse package includes a range of functions that make coding in R Studio more user-friendly. It is not necessary for data collection, but it certainly does help. In contrast, the Tidycensus package is essential to data collection. The Tidycensus package lets you pull data directly from the Decennial Census and the ACS using the get_decennial() and get_acs() functions. You only need to specify three arguments to pull data: geography, year, and variable.\n\nget_decennial(geography = \"____\",\n              variable = \"____\",\n              year = xxxx)\n\nget_acs(geography = \"____\",\n        variable = \"____\",\n        year = xxxx)\n\nTo keep this blog short, I will not be running through the process of coding the entire demographic profile. Instead, I will be using the population data as an example. Population data is collected most accurately by the Decennial Census, so for the rest of this guide, we will use get_decennial().\nLet’s pull the total population for 2000-2020 at the place, state, region, and nation levels. The Census API variable code for 2000 and 2010 total population is P001001. For the 2020 total population, the API variable code is P1_001N.\n\n# Define the variables before getting the data.\npop00 &lt;- c(\"pop\" = \"P001001\")\npop10 &lt;- c(\"pop\" = \"P001001\")\n# The API code for total population changed for 2020.\npop20 &lt;- c(\"pop\" = \"P1_001N\")\n\n###\n## National Context: nationPop\n# Getting 2000 total population data for the USA.\nnation00 &lt;- get_decennial(geography = \"us\",\n                          year = 2000,\n                          variable = pop00,\n                          output = \"wide\") %&gt;% \n  mutate(year = 2000)\n# Getting 2010 total population data for the USA.\nnation10 &lt;- get_decennial(geography = \"us\",\n                          year = 2010,\n                          variable = pop10,\n                          output = \"wide\") %&gt;% \n  mutate(year = 2010)\n# Getting 2020 total population data for the USA.\nnation20 &lt;- get_decennial(geography = \"us\",\n                          year = 2020,\n                          variable = pop20,\n                          output = \"wide\") %&gt;% \n  mutate(year = 2020)\n\n\n###\n## Regional Context: regionPop\n# Getting 2000 total population data from the Midwest.\nregion00 &lt;- get_decennial(geography = \"region\",\n                          year = 2000,\n                          variable = pop00,\n                          output = \"wide\") %&gt;% \n  mutate(year = 2000)\n# Getting 2010 total population data for the Midwest.\nregion10 &lt;- get_decennial(geography = \"region\",\n                          year = 2010,\n                          variable = pop10,\n                          output = \"wide\") %&gt;% \n  mutate(year = 2010)\n# Getting 2020 total population data for the Midwest.\nregion20 &lt;- get_decennial(geography = \"region\",\n                          year = 2020,\n                          variable = pop20,\n                          output = \"wide\") %&gt;% \n  mutate(year = 2020)\n\n\n###\n## State Context: statePop\n# Getting the 2000 total population data for the state of Iowa from the Decennial Census.\niowa00 &lt;- get_decennial(geography = \"state\",\n                        state = \"IA\",\n                        year = 2000,\n                        output = \"wide\",\n                        variable = pop00) %&gt;% \n  mutate(year = 2000)\n# Getting the 2010 total population data for the state of Iowa from the Decennial Census.\niowa10 &lt;- get_decennial(geography = \"state\",\n                        state = \"IA\",\n                        variable = pop10,\n                        year = 2010,\n                        output = \"wide\") %&gt;% \n  mutate(year = 2010)\n# Getting the 2020 total population data for the state of Iowa from the Decennial Census.\niowa20 &lt;- get_decennial(geography = \"state\",\n                        state = \"IA\",\n                        variable = pop20,\n                        year = 2020,\n                        output = \"wide\") %&gt;% \n  mutate(year = 2020)\n\n\n###\n## Places: \n# Getting 2000 total population data for all places in Iowa.\nplace00 &lt;- get_decennial(geography = \"place\",\n                         state = \"IA\",\n                         year = 2000,\n                         output = \"wide\",\n                         variables = pop00) %&gt;% \n  mutate(year = 2000)\nplace10 &lt;- get_decennial(geography = \"place\",\n                         state = \"IA\",\n                         year = 2010,\n                         output = \"wide\",\n                         variables = pop10) %&gt;% \n  mutate(year = 2010)\nplace20 &lt;- get_decennial(geography = \"place\",\n                         state = \"IA\",\n                         variable = pop20,\n                         year = 2020,\n                         output = \"wide\") %&gt;% \n  mutate(year = 2020)\n\nNow that we have collected our total population data for all geographies from 2000-2020, we can start the data transformation process.\n\n\n\nThe first data transformation we will conduct on our data occurred in the code chunk above. If you look closely, I attached a mutate(year = xxxx) to the end of each pull. mutate() allows you to create new columns and change the contents of existing ones based on arguments. The argument above is year = xxxx.\nThe next data transformation will reuse the mutate() function. We will add a column for geography using the mutate() function. To bind multiple data frames together, use the bind_rows() function.\n\n# Bind the years together using bind_rows to create data frame for national context. \n# Create a new column for geography type.\nnationPop &lt;- nation20 %&gt;% \n  bind_rows(nation10,nation00) %&gt;% \n  mutate(geography = \"Nation\") \n\n# Bind the years together using bind_rows to create data frame for regional context.\n# Create a new column for geography type.\nregionPop &lt;- region20 %&gt;% \n  bind_rows(region10,region00) %&gt;% \n  mutate(geography = \"Region\")\n\n# Bind the years together using bind_rows to create data frame for state context. \n# Create a new column for geography type.\nstatePop &lt;- iowa20 %&gt;% \n  bind_rows(iowa10,iowa00) %&gt;% \n  mutate(geography = \"State\")\n\n# Bind the years together using bind_rows() to create data frame for all places in Iowa. \n# Create a new column for geography type.\nplacePop &lt;- place20 %&gt;% \n  bind_rows(place10,place00) %&gt;% \n  mutate(geography = \"Place\")\n\nThe code chunk above condensed our twelve data frames to just four and added a new column to specify each geography. Suppose you open the regionPop and placepop data frames. In that case, you will notice more regions and places under the NAME column than the Midwest and our focus area cities. We will use the filter() function on regionPop and placePop to remove unnecessary regions and places.\n\n# Filter for Independence, Grundy Center, and New Hampton. \nplacePop &lt;- placePop %&gt;% \n  filter(NAME %in% c(\"Grundy Center city, Iowa\", \"Independence city, Iowa\", \"New Hampton city, Iowa\"))\n\n# Filter for Midwest\nregionPop &lt;- regionPop %&gt;% \n  filter(NAME == \"Midwest Region\") \n\nNow we only have the Midwest and focus area cities in our data frames! The Census sometimes adds unnecessary words behind the names of areas. It is doing so for the regionPop and placePop data frames. In regionPop, the NAME column includes the region and the word “region.” The string “city, Iowa” is included in the NAME column for placePop. Both can be removed. To do so, use the str_remove() function inside mutate().\n\n# Use str_remove() to remove \"city, Iowa\" from behind the place names.\nplacePop &lt;- placePop %&gt;% \n  mutate(NAME = str_remove(NAME, \" city, Iowa|, Iowa\"))\n\n# Use str_remove() to remove \" Region\" from Midwest. \nregionPop &lt;- regionPop %&gt;% \n  mutate(NAME = str_remove(NAME, \" Region\")) \n\nThe final data transformation for the total population data is one we have already done before. The code chunk below combines all geographies in one data frame using bind_rows().\n\n# Combine nationPop, regionPop, statePop, and placePop using bind_rows().\npopulation &lt;- nationPop %&gt;% \n  bind_rows(regionPop,statePop,placePop)\n\nNow that our data is cleaned and organized, we can start making visualizations!\n\n\n\nTo visualize data in R Studio, I installed and loaded more packages: ggplot2, scales, and ggthemes.\n\ninstall.packages(\"ggplot2\")\ninstall.packages(\"scales\")\ninstall.packages(\"ggthemes\")\n\n\nlibrary(ggplot2)\nlibrary(scales)\nlibrary(ggthemes)\n\nThe ggplot2 package is required to create a plot in R Studio. With ggplot2 you get access to the function ggplot(), which allows you to create visualizations. ggplot() takes the arguments data and mapping to create a plot. Mapping refers to the x and y coordinates of our data. There are various geoms included in the ggplot2 package that aid in creating a visualization. Here are some examples:\n\n\n\nGeom\nResult\n\n\n\n\ngeom_line()\nline graph\n\n\ngeom_point()\nscatter plot\n\n\ngeom_histogram()\nhistogram\n\n\ngeom_bar()\nbar chart\n\n\ngeom_col()\ncolumn chart\n\n\n\nLet’s create a simple line graph for our total population data.\n\nggplot(data = population, mapping = aes(x = year, y = pop, group = NAME)) +\n  geom_line()\n\n\n\n\nWhile this is a visualization, it is a bad one. The values on the y-axis are not easily readable, and the lines have no meaning. We know that our data frame has four different geographies, so which one is which? Let’s try adding color to our plot and changing the line type by the geography column.\n\nggplot(population, aes(x = year, y = pop, group = NAME)) +\n  geom_line(aes(color = NAME, linetype = geography))\n\n\n\n\nMuch better, but these lines are a small and hard to read. To improve the visual, change the line size to one and add a log to the y-axis. Add a geom_point() layer to the plot as well.\n\nggplot(population, aes(x = year, y = pop, group = NAME)) +\n  geom_line(aes(color = NAME, linetype = geography), linewidth = 1) +\n  geom_point() +\n  scale_y_log10()\n\n\n\n\nLet’s add some more details to make this plot even better.\n\nggplot(population, aes(x = year, y = pop, group = NAME)) +\n  geom_line(aes(linetype = geography, color = NAME), linewidth = 1)+\n  geom_point(size = 2)+\n  scale_y_log10(label = scales::comma) +\n  scale_x_continuous(limits = c(2000, 2020),\n                     breaks = c(2000,2010,2020))+\n  labs(title = \"Change in Total Population\",\n       y = \"Population (log scale)\",\n       subtitle = \"2000-2020 Decennial Census\",\n       x = \"\",\n       color = \"\", \n       linetype = \"\",\n       caption = \"Variables: P1_001N and P001001\")\n\n\n\n\nCongratulations! You have made a plot in R Studio. You will have a complete demographic profile after gathering data for all other demographics you chose, transforming them, and creating visualizations.\n\n\nHere is an example of the one I created for the 2023 AI Housing Project. Go to week eight of my blog for more information on the code used to create these visualizations."
  },
  {
    "objectID": "posts/Week_9/Week_9_Demo.html#determine-focus-area",
    "href": "posts/Week_9/Week_9_Demo.html#determine-focus-area",
    "title": "Guide: Creating a Demographic Profile",
    "section": "",
    "text": "The first step in creating a demographic profile is determining your focus area. For the example profile, the focus area was the cities included in the WINVEST project of Data Science for the Public Good. WINVEST conducted a windshield survey of Grundy Center, Independence, and New Hampton. The demographic profile I created is intended to enhance the data from the windshield survey.\nI decided to add further detail to my demographic analysis by gathering data on the state, region, and nation associated with my focus areas. These additional geographies add context to the original focus area.\nIn total, I decided to gather data on the following areas:\n\nGrundy Center\nIndependence\nNew Hampton\nIowa\nMidwest\nUnited States"
  },
  {
    "objectID": "posts/Week_9/Week_9_Demo.html#decide-demographic-data",
    "href": "posts/Week_9/Week_9_Demo.html#decide-demographic-data",
    "title": "Guide: Creating a Demographic Profile",
    "section": "",
    "text": "The data you decide to gather for your demographic profile makes the profile. Your options for demographic data are but are not limited to, data on age, race, ethnicity, gender, marital status, income, education, and employment. More detailed data is available about each.\nI decided to gather data on the following demographics for the example profile:\n\nPopulation\nMedian income\nMedian home value\nMedian year home built\nHousing occupancy\nReason for vacancy\n\nData on housing was very important to me. The WINVEST project’s windshield survey was on the housing stock condition in the focus area communities. Thus, I wanted to gather available information on the housing stock from the Decennial Census and the American Community Survey. I chose median home value, median year built, and housing occupancy data because they give a well-rounded analysis of the housing demographics."
  },
  {
    "objectID": "posts/Week_9/Week_9_Demo.html#gather-data",
    "href": "posts/Week_9/Week_9_Demo.html#gather-data",
    "title": "Guide: Creating a Demographic Profile",
    "section": "",
    "text": "Once you have decided on the demographic data you want, it is time to start the data collection process. Many demographic data can be found via the United States Decennial Census or the American Community Survey (ACS). The U.S. census is one of the best places to gather demographic data because it counts every resident in the United States. It has a very low inaccuracy, but the U.S. census is only conducted every ten years. The American Community Survey (ACS) is your best bet for more recent data. The ACS has more detailed demographic data and is conducted every five years for the entirety of the United States and every year for places with a population over 65,000. The ACS does not count every individual resident in the United States and instead relies on surveying a proportion of the population to create estimates of the demographics. Thus, it can be inaccurate and provides a margin of error. It is best used for data on the changing population, housing, and workforce.\nTo start data collection in R Studio, I installed the Tidyverse and Tidycensus packages and loaded them with the library() function.\n\ninstall.packages(\"tidyverse\")\ninstall.packages(\"tidycensus\")\n\n\nlibrary(tidyverse)\nlibrary(tidycensus)\n\nThe Tidyverse package includes a range of functions that make coding in R Studio more user-friendly. It is not necessary for data collection, but it certainly does help. In contrast, the Tidycensus package is essential to data collection. The Tidycensus package lets you pull data directly from the Decennial Census and the ACS using the get_decennial() and get_acs() functions. You only need to specify three arguments to pull data: geography, year, and variable.\n\nget_decennial(geography = \"____\",\n              variable = \"____\",\n              year = xxxx)\n\nget_acs(geography = \"____\",\n        variable = \"____\",\n        year = xxxx)\n\nTo keep this blog short, I will not be running through the process of coding the entire demographic profile. Instead, I will be using the population data as an example. Population data is collected most accurately by the Decennial Census, so for the rest of this guide, we will use get_decennial().\nLet’s pull the total population for 2000-2020 at the place, state, region, and nation levels. The Census API variable code for 2000 and 2010 total population is P001001. For the 2020 total population, the API variable code is P1_001N.\n\n# Define the variables before getting the data.\npop00 &lt;- c(\"pop\" = \"P001001\")\npop10 &lt;- c(\"pop\" = \"P001001\")\n# The API code for total population changed for 2020.\npop20 &lt;- c(\"pop\" = \"P1_001N\")\n\n###\n## National Context: nationPop\n# Getting 2000 total population data for the USA.\nnation00 &lt;- get_decennial(geography = \"us\",\n                          year = 2000,\n                          variable = pop00,\n                          output = \"wide\") %&gt;% \n  mutate(year = 2000)\n# Getting 2010 total population data for the USA.\nnation10 &lt;- get_decennial(geography = \"us\",\n                          year = 2010,\n                          variable = pop10,\n                          output = \"wide\") %&gt;% \n  mutate(year = 2010)\n# Getting 2020 total population data for the USA.\nnation20 &lt;- get_decennial(geography = \"us\",\n                          year = 2020,\n                          variable = pop20,\n                          output = \"wide\") %&gt;% \n  mutate(year = 2020)\n\n\n###\n## Regional Context: regionPop\n# Getting 2000 total population data from the Midwest.\nregion00 &lt;- get_decennial(geography = \"region\",\n                          year = 2000,\n                          variable = pop00,\n                          output = \"wide\") %&gt;% \n  mutate(year = 2000)\n# Getting 2010 total population data for the Midwest.\nregion10 &lt;- get_decennial(geography = \"region\",\n                          year = 2010,\n                          variable = pop10,\n                          output = \"wide\") %&gt;% \n  mutate(year = 2010)\n# Getting 2020 total population data for the Midwest.\nregion20 &lt;- get_decennial(geography = \"region\",\n                          year = 2020,\n                          variable = pop20,\n                          output = \"wide\") %&gt;% \n  mutate(year = 2020)\n\n\n###\n## State Context: statePop\n# Getting the 2000 total population data for the state of Iowa from the Decennial Census.\niowa00 &lt;- get_decennial(geography = \"state\",\n                        state = \"IA\",\n                        year = 2000,\n                        output = \"wide\",\n                        variable = pop00) %&gt;% \n  mutate(year = 2000)\n# Getting the 2010 total population data for the state of Iowa from the Decennial Census.\niowa10 &lt;- get_decennial(geography = \"state\",\n                        state = \"IA\",\n                        variable = pop10,\n                        year = 2010,\n                        output = \"wide\") %&gt;% \n  mutate(year = 2010)\n# Getting the 2020 total population data for the state of Iowa from the Decennial Census.\niowa20 &lt;- get_decennial(geography = \"state\",\n                        state = \"IA\",\n                        variable = pop20,\n                        year = 2020,\n                        output = \"wide\") %&gt;% \n  mutate(year = 2020)\n\n\n###\n## Places: \n# Getting 2000 total population data for all places in Iowa.\nplace00 &lt;- get_decennial(geography = \"place\",\n                         state = \"IA\",\n                         year = 2000,\n                         output = \"wide\",\n                         variables = pop00) %&gt;% \n  mutate(year = 2000)\nplace10 &lt;- get_decennial(geography = \"place\",\n                         state = \"IA\",\n                         year = 2010,\n                         output = \"wide\",\n                         variables = pop10) %&gt;% \n  mutate(year = 2010)\nplace20 &lt;- get_decennial(geography = \"place\",\n                         state = \"IA\",\n                         variable = pop20,\n                         year = 2020,\n                         output = \"wide\") %&gt;% \n  mutate(year = 2020)\n\nNow that we have collected our total population data for all geographies from 2000-2020, we can start the data transformation process."
  },
  {
    "objectID": "posts/Week_9/Week_9_Demo.html#transform-data",
    "href": "posts/Week_9/Week_9_Demo.html#transform-data",
    "title": "Guide: Creating a Demographic Profile",
    "section": "",
    "text": "The first data transformation we will conduct on our data occurred in the code chunk above. If you look closely, I attached a mutate(year = xxxx) to the end of each pull. mutate() allows you to create new columns and change the contents of existing ones based on arguments. The argument above is year = xxxx.\nThe next data transformation will reuse the mutate() function. We will add a column for geography using the mutate() function. To bind multiple data frames together, use the bind_rows() function.\n\n# Bind the years together using bind_rows to create data frame for national context. \n# Create a new column for geography type.\nnationPop &lt;- nation20 %&gt;% \n  bind_rows(nation10,nation00) %&gt;% \n  mutate(geography = \"Nation\") \n\n# Bind the years together using bind_rows to create data frame for regional context.\n# Create a new column for geography type.\nregionPop &lt;- region20 %&gt;% \n  bind_rows(region10,region00) %&gt;% \n  mutate(geography = \"Region\")\n\n# Bind the years together using bind_rows to create data frame for state context. \n# Create a new column for geography type.\nstatePop &lt;- iowa20 %&gt;% \n  bind_rows(iowa10,iowa00) %&gt;% \n  mutate(geography = \"State\")\n\n# Bind the years together using bind_rows() to create data frame for all places in Iowa. \n# Create a new column for geography type.\nplacePop &lt;- place20 %&gt;% \n  bind_rows(place10,place00) %&gt;% \n  mutate(geography = \"Place\")\n\nThe code chunk above condensed our twelve data frames to just four and added a new column to specify each geography. Suppose you open the regionPop and placepop data frames. In that case, you will notice more regions and places under the NAME column than the Midwest and our focus area cities. We will use the filter() function on regionPop and placePop to remove unnecessary regions and places.\n\n# Filter for Independence, Grundy Center, and New Hampton. \nplacePop &lt;- placePop %&gt;% \n  filter(NAME %in% c(\"Grundy Center city, Iowa\", \"Independence city, Iowa\", \"New Hampton city, Iowa\"))\n\n# Filter for Midwest\nregionPop &lt;- regionPop %&gt;% \n  filter(NAME == \"Midwest Region\") \n\nNow we only have the Midwest and focus area cities in our data frames! The Census sometimes adds unnecessary words behind the names of areas. It is doing so for the regionPop and placePop data frames. In regionPop, the NAME column includes the region and the word “region.” The string “city, Iowa” is included in the NAME column for placePop. Both can be removed. To do so, use the str_remove() function inside mutate().\n\n# Use str_remove() to remove \"city, Iowa\" from behind the place names.\nplacePop &lt;- placePop %&gt;% \n  mutate(NAME = str_remove(NAME, \" city, Iowa|, Iowa\"))\n\n# Use str_remove() to remove \" Region\" from Midwest. \nregionPop &lt;- regionPop %&gt;% \n  mutate(NAME = str_remove(NAME, \" Region\")) \n\nThe final data transformation for the total population data is one we have already done before. The code chunk below combines all geographies in one data frame using bind_rows().\n\n# Combine nationPop, regionPop, statePop, and placePop using bind_rows().\npopulation &lt;- nationPop %&gt;% \n  bind_rows(regionPop,statePop,placePop)\n\nNow that our data is cleaned and organized, we can start making visualizations!"
  },
  {
    "objectID": "posts/Week_9/Week_9_Demo.html#visualize-data",
    "href": "posts/Week_9/Week_9_Demo.html#visualize-data",
    "title": "Guide: Creating a Demographic Profile",
    "section": "",
    "text": "To visualize data in R Studio, I installed and loaded more packages: ggplot2, scales, and ggthemes.\n\ninstall.packages(\"ggplot2\")\ninstall.packages(\"scales\")\ninstall.packages(\"ggthemes\")\n\n\nlibrary(ggplot2)\nlibrary(scales)\nlibrary(ggthemes)\n\nThe ggplot2 package is required to create a plot in R Studio. With ggplot2 you get access to the function ggplot(), which allows you to create visualizations. ggplot() takes the arguments data and mapping to create a plot. Mapping refers to the x and y coordinates of our data. There are various geoms included in the ggplot2 package that aid in creating a visualization. Here are some examples:\n\n\n\nGeom\nResult\n\n\n\n\ngeom_line()\nline graph\n\n\ngeom_point()\nscatter plot\n\n\ngeom_histogram()\nhistogram\n\n\ngeom_bar()\nbar chart\n\n\ngeom_col()\ncolumn chart\n\n\n\nLet’s create a simple line graph for our total population data.\n\nggplot(data = population, mapping = aes(x = year, y = pop, group = NAME)) +\n  geom_line()\n\n\n\n\nWhile this is a visualization, it is a bad one. The values on the y-axis are not easily readable, and the lines have no meaning. We know that our data frame has four different geographies, so which one is which? Let’s try adding color to our plot and changing the line type by the geography column.\n\nggplot(population, aes(x = year, y = pop, group = NAME)) +\n  geom_line(aes(color = NAME, linetype = geography))\n\n\n\n\nMuch better, but these lines are a small and hard to read. To improve the visual, change the line size to one and add a log to the y-axis. Add a geom_point() layer to the plot as well.\n\nggplot(population, aes(x = year, y = pop, group = NAME)) +\n  geom_line(aes(color = NAME, linetype = geography), linewidth = 1) +\n  geom_point() +\n  scale_y_log10()\n\n\n\n\nLet’s add some more details to make this plot even better.\n\nggplot(population, aes(x = year, y = pop, group = NAME)) +\n  geom_line(aes(linetype = geography, color = NAME), linewidth = 1)+\n  geom_point(size = 2)+\n  scale_y_log10(label = scales::comma) +\n  scale_x_continuous(limits = c(2000, 2020),\n                     breaks = c(2000,2010,2020))+\n  labs(title = \"Change in Total Population\",\n       y = \"Population (log scale)\",\n       subtitle = \"2000-2020 Decennial Census\",\n       x = \"\",\n       color = \"\", \n       linetype = \"\",\n       caption = \"Variables: P1_001N and P001001\")\n\n\n\n\nCongratulations! You have made a plot in R Studio. You will have a complete demographic profile after gathering data for all other demographics you chose, transforming them, and creating visualizations.\n\n\nHere is an example of the one I created for the 2023 AI Housing Project. Go to week eight of my blog for more information on the code used to create these visualizations."
  },
  {
    "objectID": "posts/Week_9/Week_9_Variale_Codes.html",
    "href": "posts/Week_9/Week_9_Variale_Codes.html",
    "title": "Guide: API Variable Codes",
    "section": "",
    "text": "The API variable codes listed on this page were used in the demographic analysis I conducted for the 2021 AI Housing Project for Data Science for the Public Good. The API variable codes are organized in tables by variable name and API code and further separate by survey type.\nDecennial Census\n\n\n\nVariable\nAPI Code\n\n\n\n\nTotal Population, 2000\nP001001\n\n\nTotal Population, 2010\nP001001\n\n\nTotal Population, 2020\nP1_001N\n\n\n\n5-Year American Community Survey - Age Variables\n\n\n\nVariable\nAPI Code\n\n\n\n\nMedian Age\nB01002_001\n\n\nTotal Population by Age and Sex, Male\nB01001_002\n\n\nUnder 5, Male\nB01001_003\n\n\n5 to 9, Male\nB01001_004\n\n\n10 to 14, Male\nB01001_005\n\n\n15 to 17, Male\nB01001_006\n\n\n65 to 66, Male\nB01001_020\n\n\n67 to 69, Male\nB01001_021\n\n\n70 to 74, Male\nB01001_022\n\n\n75 to 79, Male\nB01001_023\n\n\n80 to 84, Male\nB01001_024\n\n\nOver 85, Male\nB01001_025\n\n\nTotal Population by Age and Sex, Female\nB01001_026\n\n\nUnder 5, Female\nB01001_027\n\n\n5 to 9, Female\nB01001_028\n\n\n10 to 14, Female\nB01001_029\n\n\n15 to 17, Female\nB01001_030\n\n\n65 to 66, Female\nB01001_044\n\n\n67 to 69, Female\nB01001_045\n\n\n70 to 74, Female\nB01001_046\n\n\n75 to 79, Female\nB01001_047\n\n\n80 to 84, Female\nB01001_048\n\n\nOver 85, Female\nB01001_049\n\n\n\n5-Year American Community Survey - Housing Variables\n\n\n\nVariable\nAPI Code\n\n\n\n\nTotal Housing Units\nB25001_001\n\n\nOccupied Units\nB25002_002\n\n\nOwner Occupied Units\nB25003_002\n\n\nRenter Occupied Units\nB25003_003\n\n\nVacant Units\nB25002_003\n\n\nMedian Home Value\nB25077_001\n\n\nMedian Year Built\nB25035_001\n\n\n\n5-Year American Community Survey - Workforce Variables\n\n\n\nVariable\nAPI Code\n\n\n\n\nMedian Income\nB19013_001\n\n\nTotal Labor Force by Commute\nB08008_001\n\n\nCommute to Work\nB08008_004\n\n\nTotal Labor Force\nB23001_001\n\n\nTotal Labor Force, Male\nB23001_002\n\n\nTotal Labor Force 16 to 19, Male\nB23001_003\n\n\nTotal Labor Force 16 to 19, In Armed Forces, Male\nB23001_005\n\n\nTotal Labor Force 16 to 19, Employed, Male\nB23001_007\n\n\nTotal Labor Force 16 to 19, Unemployed, Male\nB23001_008\n\n\nTotal Labor Force 20 to 21, Male\nB23001_010\n\n\nTotal Labor Force 20 to 21, In Armed Forces, Male\nB23001_012\n\n\nTotal Labor Force 20 to 21, Employed, Male\nB23001_014\n\n\nTotal Labor Force 20 to 21, Unemployed, Male\nB23001_015\n\n\nTotal Labor Force 22 to 24, Male\nB23001_017\n\n\nTotal Labor Force 22 to 24, In Armed Forces, Male\nB23001_019\n\n\nTotal Labor Force 22 to 24, Employed, Male\nB23001_021\n\n\nTotal Labor Force 22 to 24, Unemployed, Male\nB23001_022\n\n\nTotal Labor Force 25 to 29, Male\nB23001_024\n\n\nTotal Labor Force 25 to 29, In Armed Forces, Male\nB23001_026\n\n\nTotal Labor Force 25 to 29, Employed, Male\nB23001_028\n\n\nTotal Labor Force 25 to 29, Unemployed, Male\nB23001_029\n\n\nTotal Labor Force 30 to 34, Male\nB23001_031\n\n\nTotal Labor Force 30 to 34, In Armed Forces, Male\nB23001_033\n\n\nTotal Labor Force 30 to 34, Employed, Male\nB23001_035\n\n\nTotal Labor Force 30 to 34, Unemployed, Male\nB23001_036\n\n\nTotal Labor Force 35 to 44, Male\nB23001_038\n\n\nTotal Labor Force 35 to 44, In Armed Forces, Male\nB23001_040\n\n\nTotal Labor Force 35 to 44, Employed, Male\nB23001_042\n\n\nTotal Labor Force 35 to 44, Unemployed, Male\nB23001_043\n\n\nTotal Labor Force 45 to 54, Male\nB23001_045\n\n\nTotal Labor Force 45 to 54, In Armed Forces, Male\nB23001_047\n\n\nTotal Labor Force 45 to 54, Employed, Male\nB23001_049\n\n\nTotal Labor Force 45 to 54, Unemployed, Male\nB23001_050\n\n\nTotal Labor Force 55 to 59, Male\nB23001_052\n\n\nTotal Labor Force 55 to 59, In Armed Forces, Male\nB23001_054\n\n\nTotal Labor Force 55 to 59, Employed, Male\nB23001_056\n\n\nTotal Labor Force 55 to 59, Unemployed, Male\nB23001_057\n\n\nTotal Labor Force 60 to 61, Male\nB23001_059\n\n\nTotal Labor Force 60 to 61, In Armed Forces, Male\nB23001_061\n\n\nTotal Labor Force 60 to 61, Employed, Male\nB23001_063\n\n\nTotal Labor Force 60 to 61, Unemployed, Male\nB23001_064\n\n\nTotal Labor Force 62 to 64, Male\nB23001_066\n\n\nTotal Labor Force 62 to 64, In Armed Forces, Male\nB23001_068\n\n\nTotal Labor Force 62 to 64, Employed, Male\nB23001_070\n\n\nTotal Labor Force 62 to 64, Unemployed, Male\nB23001_071\n\n\nTotal Labor Force 65 to 69, Male\nB23001_073\n\n\nTotal Labor Force 65 to 69, Employed, Male\nB23001_075\n\n\nTotal Labor Force 65 to 69, Unemployed, Male\nB23001_076\n\n\nTotal Labor Force 70 to 74, Male\nB23001_078\n\n\nTotal Labor Force 70 to 74, Employed, Male\nB23001_080\n\n\nTotal Labor Force 70 to 74, Unemployed, Male\nB23001_081\n\n\nTotal Labor Force Over 75, Male\nB23001_083\n\n\nTotal Labor Force Over 75, Employed, Male\nB23001_085\n\n\nTotal Labor Force Over 75, Unemployed, Male\nB23001_086\n\n\nTotal Labor Force, Female\nB23001_088\n\n\nTotal Labor Force 16 to 19, Female\nB23001_089\n\n\nTotal Labor Force 16 to 19, In Armed Forces, Female\nB23001_091\n\n\nTotal Labor Force 16 to 19, Employed, Female\nB23001_093\n\n\nTotal Labor Force 16 to 19, Unemployed, Female\nB23001_094\n\n\nTotal Labor Force 20 to 21, Female\nB23001_096\n\n\nTotal Labor Force 20 to 21, In Armed Forces, Female\nB23001_098\n\n\nTotal Labor Force 20 to 21, Employed, Female\nB23001_099\n\n\nTotal Labor Force 20 to 21, Unemployed, Female\nB23001_101\n\n\nTotal Labor Force 22 to 24, Female\nB23001_103\n\n\nTotal Labor Force 22 to 24, In Armed Forces, Female\nB23001_105\n\n\nTotal Labor Force 22 to 24, Employed, Female\nB23001_107\n\n\nTotal Labor Force 22 to 24, Unemployed, Female\nB23001_108\n\n\nTotal Labor Force 25 to 29, Female\nB23001_110\n\n\nTotal Labor Force 25 to 29, In Armed Forces, Female\nB23001_112\n\n\nTotal Labor Force 25 to 29, Employed, Female\nB23001_114\n\n\nTotal Labor Force 25 to 29, Unemployed, Female\nB23001_115\n\n\nTotal Labor Force 30 to 34, Female\nB23001_117\n\n\nTotal Labor Force 30 to 34, In Armed Forces, Female\nB23001_119\n\n\nTotal Labor Force 30 to 34, Employed, Female\nB23001_121\n\n\nTotal Labor Force 30 to 34, Unemployed, Female\nB23001_122\n\n\nTotal Labor Force 35 to 44, Female\nB23001_124\n\n\nTotal Labor Force 35 to 44, In Armed Forces, Female\nB23001_126\n\n\nTotal Labor Force 35 to 44, Employed, Female\nB23001_128\n\n\nTotal Labor Force 35 to 44, Unemployed, Female\nB23001_129\n\n\nTotal Labor Force 45 to 54, Female\nB23001_131\n\n\nTotal Labor Force 45 to 54, In Armed Forces, Female\nB23001_133\n\n\nTotal Labor Force 45 to 54, Employed, Female\nB23001_135\n\n\nTotal Labor Force 45 to 54, Unemployed, Female\nB23001_136\n\n\nTotal Labor Force 55 to 59, Female\nB23001_138\n\n\nTotal Labor Force 55 to 59, In Armed Forces, Female\nB23001_140\n\n\nTotal Labor Force 55 to 59, Employed, Female\nB23001_142\n\n\nTotal Labor Force 55 to 59, Unemployed, Female\nB23001_143\n\n\nTotal Labor Force 60 to 61, Female\nB23001_145\n\n\nTotal Labor Force 60 to 61, In Armed Forces, Female\nB23001_147\n\n\nTotal Labor Force 60 to 61, Employed, Female\nB23001_149\n\n\nTotal Labor Force 60 to 61, Unemployed, Female\nB23001_150\n\n\nTotal Labor Force 62 to 64, Female\nB23001_152\n\n\nTotal Labor Force 62 to 64, In Armed Forces, Female\nB23001_154\n\n\nTotal Labor Force 62 to 64, Employed, Female\nB23001_156\n\n\nTotal Labor Force 62 to 64, Unemployed, Female\nB23001_157\n\n\nTotal Labor Force 65 to 69, Female\nB23001_159\n\n\nTotal Labor Force 65 to 69, Employed, Female\nB23001_161\n\n\nTotal Labor Force 65 to 69, Unemployed, Female\nB23001_162\n\n\nTotal Labor Force 70 to 74, Female\nB23001_164\n\n\nTotal Labor Force 70 to 74, Employed, Female\nB23001_166\n\n\nTotal Labor Force 70 to 74, Unemployed, Female\nB23001_167\n\n\nTotal Labor Force Over 75, Female\nB23001_169\n\n\nTotal Labor Force Over 75, Employed, Female\nB23001_171\n\n\nTotal Labor Force Over 75, Unemployed, Female\nB23001_172"
  },
  {
    "objectID": "posts/Week_Four/Week_4.html",
    "href": "posts/Week_Four/Week_4.html",
    "title": "Week Four of Data Science for the Public Good",
    "section": "",
    "text": "On Monday this week, we met with the Director of the Community and Economic Development department at Iowa State University Extension and Outreach, Erin Olson-Douglas. She is one of our stakeholders for the Housing Project, and we had a great meeting with her. The agenda of the meeting was to update her on where we are at with the project. As of Monday, we were gathering data and ideas for the AI Image Model.\nShe had a couple of questions:\n\nIf the image gathered from Google Street View is bad, can the model be told to look at a different site for a better image?\nHow will the model choose one of the photos?\n\nIs the image chosen on a rating scale (good, usable, not usable)?\nIs the image chosen based on a simple yes or no?\n\n\nI ended the meeting with a question myself:\n\nHow do we get the model to work off of websites, not already available, pre-loaded images?\n\nThis is something I had not thought about yet. So far, we have been making, training, and testing models on images that we gathered and put into a database ourselves. I am not sure how we would get an AI Model to gather its own images, or if that is something we even need it to do.\nWe also ended the meeting with some knowledge on how we are presenting our final project. We need to keep in mind how our project can be picked up and used by others. We also need to make sure we are documenting and explaining our process so the next years of DSPG interns can continue this housing project.\nFinally, Erin Olson-Douglas is going to be arranging a meeting with a county assesor for us. We are very curious how assessors complete their jobs with houses. We want to know what it is that they look at and look for when completing the assessment. Erin thinks we will be meeting with the Polk County assessor.\n\n\n\nOn Monday, I also helped my team assemble Excel spreadsheets with all the addresses for Slater, Grundy Center, Independence, and New Hampton. I was in charge of the Slater data and part of the Grundy Center and Independence data sets.\nWe needed to first gather the addresses for each city. Gavin and Angelina used a spatial tool on Vanguard and Beacon to do this. On the map for the websites, the second tool from the left is called the Selection Tool. When you drag it over a section of properties, the list of parcels shows up in a “Results” section on the right.\nGavin used a web scraper attached to a Chrome Extension to then scrape the parcel information listed in “Results” from Beacon. Angelina was lucky and could download the parcel information as a .csv file from Vanguard.\n\n\n\n\n\nOnce the parcel information was scraped for Beacon, we had to go in and clean the data. Below is a sample of what the .csv file looked like after Gavin scraped it. The first thing we had to do was get the data all on one line. We used the following function in Excel to transform the street addresses onto one line:\n\n=TRIM(CLEAN(SUBSTITUTE(cell, CHAR(160), ” “)))\n\n\n\n\n\n\nWe then used the the “Text to Columns” tool in Excel to separate the data into Parcel ID, Street Address, and Owner. We used the “-” as a delimiter. We cleaned the data to remove any addresses that were obviously non-residential, and we also narrowed the data down to just the Parcel ID and address.\n\n\n\n\n\nFrom there, we created the URLs to gather Google Street View images.\nWe used the following function in Excel to transform the street addresses into workable addresses for Google Street View:\n\n=SUBSTITUTE(TRIM(cell),” “,”+“))\n\nThis function removes all spaces and replaces them with + signs.\nHere is the output of the cleaned Slater data:"
  },
  {
    "objectID": "posts/Week_Four/Week_4.html#monday",
    "href": "posts/Week_Four/Week_4.html#monday",
    "title": "Week Four of Data Science for the Public Good",
    "section": "",
    "text": "On Monday this week, we met with the Director of the Community and Economic Development department at Iowa State University Extension and Outreach, Erin Olson-Douglas. She is one of our stakeholders for the Housing Project, and we had a great meeting with her. The agenda of the meeting was to update her on where we are at with the project. As of Monday, we were gathering data and ideas for the AI Image Model.\nShe had a couple of questions:\n\nIf the image gathered from Google Street View is bad, can the model be told to look at a different site for a better image?\nHow will the model choose one of the photos?\n\nIs the image chosen on a rating scale (good, usable, not usable)?\nIs the image chosen based on a simple yes or no?\n\n\nI ended the meeting with a question myself:\n\nHow do we get the model to work off of websites, not already available, pre-loaded images?\n\nThis is something I had not thought about yet. So far, we have been making, training, and testing models on images that we gathered and put into a database ourselves. I am not sure how we would get an AI Model to gather its own images, or if that is something we even need it to do.\nWe also ended the meeting with some knowledge on how we are presenting our final project. We need to keep in mind how our project can be picked up and used by others. We also need to make sure we are documenting and explaining our process so the next years of DSPG interns can continue this housing project.\nFinally, Erin Olson-Douglas is going to be arranging a meeting with a county assesor for us. We are very curious how assessors complete their jobs with houses. We want to know what it is that they look at and look for when completing the assessment. Erin thinks we will be meeting with the Polk County assessor.\n\n\n\nOn Monday, I also helped my team assemble Excel spreadsheets with all the addresses for Slater, Grundy Center, Independence, and New Hampton. I was in charge of the Slater data and part of the Grundy Center and Independence data sets.\nWe needed to first gather the addresses for each city. Gavin and Angelina used a spatial tool on Vanguard and Beacon to do this. On the map for the websites, the second tool from the left is called the Selection Tool. When you drag it over a section of properties, the list of parcels shows up in a “Results” section on the right.\nGavin used a web scraper attached to a Chrome Extension to then scrape the parcel information listed in “Results” from Beacon. Angelina was lucky and could download the parcel information as a .csv file from Vanguard.\n\n\n\n\n\nOnce the parcel information was scraped for Beacon, we had to go in and clean the data. Below is a sample of what the .csv file looked like after Gavin scraped it. The first thing we had to do was get the data all on one line. We used the following function in Excel to transform the street addresses onto one line:\n\n=TRIM(CLEAN(SUBSTITUTE(cell, CHAR(160), ” “)))\n\n\n\n\n\n\nWe then used the the “Text to Columns” tool in Excel to separate the data into Parcel ID, Street Address, and Owner. We used the “-” as a delimiter. We cleaned the data to remove any addresses that were obviously non-residential, and we also narrowed the data down to just the Parcel ID and address.\n\n\n\n\n\nFrom there, we created the URLs to gather Google Street View images.\nWe used the following function in Excel to transform the street addresses into workable addresses for Google Street View:\n\n=SUBSTITUTE(TRIM(cell),” “,”+“))\n\nThis function removes all spaces and replaces them with + signs.\nHere is the output of the cleaned Slater data:"
  },
  {
    "objectID": "posts/Week_Four/Week_4.html#tuesday",
    "href": "posts/Week_Four/Week_4.html#tuesday",
    "title": "Week Four of Data Science for the Public Good",
    "section": "Tuesday",
    "text": "Tuesday\nOn Tuesday morning, the entire DSPG group went to Slater to get some practice for the WINVEST project. We walked around with a city council member so we would have some local knowledge of the town while we were practicing. The local knowledge was very helpful, as we would not have known what some of the downtown commercial buildings were used for without the city council member.\nWe discovered on Tuesday that gutters are not the best test of our AI Model because most houses in Slater either had perfectly fine gutters or had no gutters at all. We do not think we will be able to get enough images to successfully train an AI Model to identify damaged gutters.\nTuesday afternoon was spent web scraping. I did the DataCamp training for web scraping in R about a week and a half ago, which was understandable then. It could have been better when applying it in real-world scenarios. Angelina and I have done a lot of Googleing to find other examples to help us. We were tasked earlier with scraping county housing assessor data. Independence in Buchanan County is on Vanguard. Slater in Story County, Grundy Center in Grundy County, and New Hampton in Chickasaw County are all on Beacon. We needed help figuring out how to scrape from these sites this week.\nI successfully scraped the categories of shoes from my favorite shoe site, Jonak, though.\n\nlibrary(rvest)\n\nWarning: package 'rvest' was built under R version 4.1.3\n\njonak = \"https://www.jonak-paris.com/collection/shoes/sandals.html\"\ncategories &lt;- read_html(jonak) %&gt;% html_elements(\".categ_itm_name\") %&gt;% html_text2()\nhead(categories)\n\n[1] \"New in\"              \"Mules, Clogs\"        \"Sandals\"            \n[4] \"Beach sandals\"       \"Wedges, Espadrilles\" \"Babies, salomes\"    \n\n\nI wanted to know if Beacon and Vanguard had anti-web scraping protections on them, and that’s why Angelina and I were unsuccessful in scraping them. I found a function online called paths_allowed() in the robotstxt package that checks to see if there are protections. Both Beacon and Vanguard have protections from running the URLs through the function. Jonak doesn’t, so it was easy to scrape from the site. Zillow doesn’t have any protections, either.\n\nlibrary(robotstxt)\n\nWarning: package 'robotstxt' was built under R version 4.1.3\n\n#TRUE = web scraping allowed, FALSE = web scraping not allowed\npaths_allowed(\"https://beacon.schneidercorp.com/Application.aspx?AppID=165&LayerID=2145&PageTypeID=3&PageID=1107&Q=1818183221\")\n\n\n beacon.schneidercorp.com                      \n\n\n[1] FALSE\n\npaths_allowed(\"https://buchanan.iowaassessors.com/results.php?mode=basic&history=-1&ipin=%25&idba=&ideed=&icont=&ihnum=&iaddr=&ilegal=&iacre1=&iacre2=&iphoto=0\")\n\n\n buchanan.iowaassessors.com                      \n\n\n[1] FALSE\n\npaths_allowed(\"https://www.zillow.com/homedetails/2925-Arbor-St-Ames-IA-50014/93961907_zpid/\")\n\n\n www.zillow.com                      \n\n\n[1] TRUE\n\npaths_allowed(\"https://www.jonak-paris.com/collection/shoes/sandals.html\")\n\n\n www.jonak-paris.com                      \n\n\n[1] TRUE\n\n\nBecause Zillow doesn’t have protections, the housing team decided to switch tactics. The Housing Team had decided earlier to scrape Zillow and Trulia alongside Vanguard and Beacon for housing data. When we started the scraping of Trulia, we learned that Zillow owns Trulia. This was a huge win for us because that meant we only had to scrape one of the sites. We chose Zillow because it provides Zestimates, estimates of housing price based on external factors, and Trulia does not."
  },
  {
    "objectID": "posts/Week_Four/Week_4.html#wednesday-and-thursday",
    "href": "posts/Week_Four/Week_4.html#wednesday-and-thursday",
    "title": "Week Four of Data Science for the Public Good",
    "section": "Wednesday and Thursday",
    "text": "Wednesday and Thursday\nOn Wednesday, I was tasked with scraping the houses in Slater, IA. I made this data frame in R with the data I scraped from Zillow.\n\nlibrary(rvest)\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.1.3\n\n\nWarning: package 'ggplot2' was built under R version 4.1.3\n\n\nWarning: package 'tibble' was built under R version 4.1.3\n\n\nWarning: package 'tidyr' was built under R version 4.1.3\n\n\nWarning: package 'readr' was built under R version 4.1.3\n\n\nWarning: package 'purrr' was built under R version 4.1.3\n\n\nWarning: package 'dplyr' was built under R version 4.1.3\n\n\nWarning: package 'stringr' was built under R version 4.1.3\n\n\nWarning: package 'forcats' was built under R version 4.1.3\n\n\nWarning: package 'lubridate' was built under R version 4.1.3\n\n\n-- Attaching core tidyverse packages ------------------------ tidyverse 2.0.0 --\nv dplyr     1.1.2     v readr     2.1.4\nv forcats   1.0.0     v stringr   1.5.0\nv ggplot2   3.4.2     v tibble    3.2.1\nv lubridate 1.9.2     v tidyr     1.3.0\nv purrr     1.0.1     \n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter()         masks stats::filter()\nx readr::guess_encoding() masks rvest::guess_encoding()\nx dplyr::lag()            masks stats::lag()\ni Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n#### Pulling recently SOLD houses ######\n########################################\n\nsold = \"https://www.zillow.com/slater-ia/sold/?searchQueryState=%7B%22mapBounds%22%3A%7B%22north%22%3A41.930365556704984%2C%22east%22%3A-93.55027834838869%2C%22south%22%3A41.782563414617314%2C%22west%22%3A-93.76760165161134%7D%2C%22isMapVisible%22%3Atrue%2C%22filterState%22%3A%7B%22sort%22%3A%7B%22value%22%3A%22days%22%7D%2C%22ah%22%3A%7B%22value%22%3Atrue%7D%2C%22sche%22%3A%7B%22value%22%3Afalse%7D%2C%22schm%22%3A%7B%22value%22%3Afalse%7D%2C%22schh%22%3A%7B%22value%22%3Afalse%7D%2C%22schp%22%3A%7B%22value%22%3Afalse%7D%2C%22schr%22%3A%7B%22value%22%3Afalse%7D%2C%22schc%22%3A%7B%22value%22%3Afalse%7D%2C%22schu%22%3A%7B%22value%22%3Afalse%7D%2C%22land%22%3A%7B%22value%22%3Afalse%7D%2C%22rs%22%3A%7B%22value%22%3Atrue%7D%2C%22fsba%22%3A%7B%22value%22%3Afalse%7D%2C%22fsbo%22%3A%7B%22value%22%3Afalse%7D%2C%22nc%22%3A%7B%22value%22%3Afalse%7D%2C%22cmsn%22%3A%7B%22value%22%3Afalse%7D%2C%22auc%22%3A%7B%22value%22%3Afalse%7D%2C%22fore%22%3A%7B%22value%22%3Afalse%7D%7D%2C%22isListVisible%22%3Atrue%2C%22mapZoom%22%3A12%2C%22regionSelection%22%3A%5B%7B%22regionId%22%3A20522%2C%22regionType%22%3A6%7D%5D%2C%22pagination%22%3A%7B%7D%7D\"\n# read the html in the url\nss = read_html(sold)\n\n# lists how many records there are to pull from\nhousesold &lt;- read_html(sold) %&gt;% html_elements(\"article\")\n\n#create a dataframe with addresses, prices, bathrooms, bedrooms, and square footage of all SOLD houses\nres_ss &lt;- tibble(\n      address= ss %&gt;% html_nodes(xpath = \"/html/body/div[1]/div[5]/div/div/div/div[1]/ul/li//div/div/article/div/div[1]/a/address\") %&gt;% html_text(),\n      price = ss %&gt;% html_nodes(xpath = '/html/body/div[1]/div[5]/div/div/div/div[1]/ul/li//div/div/article/div/div[1]/div/div/span') %&gt;% html_text(),\n      bedrooms = ss %&gt;% html_nodes(xpath = '/html/body/div[1]/div[5]/div/div/div/div[1]/ul/li//div/div/article/div/div[1]/div[3]/ul/li[1]/b') %&gt;% \n        html_text(),\n      bathrooms = ss %&gt;% html_nodes(xpath = '/html/body/div[1]/div[5]/div/div/div/div[1]/ul/li//div/div/article/div/div[1]/div[3]/ul/li[2]/b') %&gt;% \n        html_text(),\n      sqft = ss %&gt;% html_nodes(xpath = '/html/body/div[1]/div[5]/div/div/div/div[1]/ul/li//div/div/article/div/div[1]/div[3]/ul/li[3]/b') %&gt;% \n        html_text()\n    ) \n\n    \n##### Pulling FOR SALE houses #####\n######################################\n\nsale = \"https://www.zillow.com/slater-ia/?searchQueryState=%7B%22mapBounds%22%3A%7B%22north%22%3A41.930365556704984%2C%22east%22%3A-93.55027834838869%2C%22south%22%3A41.782563414617314%2C%22west%22%3A-93.76760165161134%7D%2C%22isMapVisible%22%3Atrue%2C%22filterState%22%3A%7B%22sort%22%3A%7B%22value%22%3A%22days%22%7D%2C%22ah%22%3A%7B%22value%22%3Atrue%7D%2C%22sche%22%3A%7B%22value%22%3Afalse%7D%2C%22schm%22%3A%7B%22value%22%3Afalse%7D%2C%22schh%22%3A%7B%22value%22%3Afalse%7D%2C%22schp%22%3A%7B%22value%22%3Afalse%7D%2C%22schr%22%3A%7B%22value%22%3Afalse%7D%2C%22schc%22%3A%7B%22value%22%3Afalse%7D%2C%22schu%22%3A%7B%22value%22%3Afalse%7D%2C%22land%22%3A%7B%22value%22%3Afalse%7D%7D%2C%22isListVisible%22%3Atrue%2C%22mapZoom%22%3A12%2C%22regionSelection%22%3A%5B%7B%22regionId%22%3A20522%2C%22regionType%22%3A6%7D%5D%2C%22pagination%22%3A%7B%7D%7D\"\n# read the html in the webpage\npg = read_html(sale)\n\n# get list of houses for sale that appears on the page\n# each property card is called an article when you inspect the webpage\nhousesale &lt;- read_html(sale)%&gt;%html_elements(\"article\")\n\n# create a dataframe for the FOR SALE houses\nres_pg &lt;- tibble(\n  address= pg %&gt;% html_nodes(xpath = \"/html/body/div[1]/div[5]/div/div/div[1]/div[1]/ul/li//div/div/article/div/div[1]/a/address\") %&gt;% html_text(),\n  price = pg %&gt;% html_nodes(xpath = '/html/body/div[1]/div[5]/div/div/div/div[1]/ul/li//div/div/article/div/div[1]/div/div/span') %&gt;% html_text(),\n  bedrooms = pg %&gt;% html_nodes(xpath = '/html/body/div[1]/div[5]/div/div/div/div[1]/ul/li//div/div/article/div/div[1]/div[3]/ul/li[1]/b') %&gt;% \n    html_text(),\n  bathrooms = pg %&gt;% html_nodes(xpath = '/html/body/div[1]/div[5]/div/div/div/div[1]/ul/li//div/div/article/div/div[1]/div[3]/ul/li[2]/b') %&gt;% \n    html_text(),\n  sqft = pg %&gt;% html_nodes(xpath = '/html/body/div[1]/div[5]/div/div/div/div[1]/ul/li//div/div/article/div/div[1]/div[3]/ul/li[3]/b') %&gt;% \n    html_text()\n) \n\n# combine recently SOLD and FOR SALE houses in one data frame\nresults &lt;- res_pg %&gt;% bind_rows(res_ss)\nprint(results)\n\n# A tibble: 12 x 5\n   address                             price    bedrooms bathrooms sqft \n   &lt;chr&gt;                               &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;\n 1 201 10th Ave, Slater, IA 50244      $295,000 3        2         924  \n 2 50287 210th Hwy, Slater, IA 50244   $475,000 4        2         2,147\n 3 1013 Redbud Dr, Slater, IA 50244    $429,900 4        3         1,884\n 4 506 8th Ave, Slater, IA 50244       $328,000 4        3         1,180\n 5 604 Story St, Slater, IA 50244      $200,000 3        1         1,359\n 6 611 1st Ave N, Slater, IA 50244     $265,000 4        2         1,116\n 7 101 Main St, Slater, IA 50244       $255,000 5        3         1,896\n 8 1015 Redbud Dr, Slater, IA 50244    $397,732 2        3         1,325\n 9 107 Main St, Slater, IA 50244       $242,500 4        2         1,515\n10 52898 Highway 210, Slater, IA 50244 $400,000 4        1.75      2,550\n11 604 Marshall St, Slater, IA 50244   $135,000 3        1         1,166\n12 104 N Benton St, Slater, IA 50244   $210,000 3        2         1,056\n\n\nThis web scraping was really hard. I spent a lot of time understanding the xpaths and why I was using them. I think this was beneficial to me though. I got the xpaths for my code by inspecting the Zillow webpage. To inspect, you right click on the web page and then select “Inspect.” This will open up a screen that shows you the HTML in the web page.\nIf you right click on any element in the HTML you can select “Copy” and then “Full xpath” to copy the xpath of an element. There were some minor changes that needed to be made to the xpaths. Below is an example:\n\n/html/body/div[1]/div[5]/div/div/div/div/div[1]/ul/li[1]/div/div/article/div/div[1]/a/address\nv.\n/html/body/div[1]/div[5]/div/div/div/div/div[1]/ul/li//div/div/article/div/div[1]/a/address\n\nThe difference in these two xpaths is what comes after the li element. The first xpath selects only the first li in the HTML. The second xpath selects all li elements in the HTML. The second version allows you to get all of the children of all li elements as well."
  },
  {
    "objectID": "posts/Week_Four/Week_4.html#friday",
    "href": "posts/Week_Four/Week_4.html#friday",
    "title": "Week Four of Data Science for the Public Good",
    "section": "Friday",
    "text": "Friday\nI spent a lot of time on Thursday creating the Team blog for this week. We gave a presentation to an outside individual from Oklahoma State University Friday morning, so I made sure to put a lot of my attention towards that.\nAfter the presentation on Friday morning, I got back to web scraping. Gavin was able to scrape some images from Zillow on Thursday night, and he shared the code he used with Angelina and me. The code is below:\n\n# webpage to scrape. This specific link brings you to the grundy center houses for sale.\nzillow_url_grundy &lt;- \"https://www.zillow.com/grundy-center-ia/?searchQueryState=%7B%22pagination%22%3A%7B%7D%2C%22usersSearchTerm%22%3A%22Grundy%20Center%2C%20IA%22%2C%22mapBounds%22%3A%7B%22west%22%3A-93.21166512207031%2C%22east%22%3A-92.40828987792969%2C%22south%22%3A42.153050722920995%2C%22north%22%3A42.55594363773797%7D%2C%22regionSelection%22%3A%5B%7B%22regionId%22%3A24980%2C%22regionType%22%3A6%7D%5D%2C%22isMapVisible%22%3Afalse%2C%22filterState%22%3A%7B%22sort%22%3A%7B%22value%22%3A%22days%22%7D%2C%22ah%22%3A%7B%22value%22%3Atrue%7D%2C%22land%22%3A%7B%22value%22%3Afalse%7D%7D%2C%22isListVisible%22%3Atrue%2C%22mapZoom%22%3A11%7D\"\nwebpage_grundy &lt;- read_html(zillow_url_grundy)\n\n# gathers addresses. This xpath can be obtained by right clicking on the address you want and clicking inspect.\n# you then must navigate to the html section that contains the text. right click again and go to copy -&gt; full xpath\n# to gather all addresses on page the full xpath must be altered for example this xpath below has li// which signifies select all children where the original xpath would just have li/...\naddresses &lt;- webpage_grundy %&gt;%\n  html_nodes(xpath = \"/html/body/div[1]/div[5]/div/div/div[1]/div[1]/ul/li//div/div/article/div/div[1]/a/address\") %&gt;%\n  html_text()\nprint(addresses)\n\n\n# gathers image links. Similair method as above\nimage_urls &lt;- webpage_grundy %&gt;%\n  html_nodes(xpath = '//*[@id=\"swipeable\"]/div[1]/a/div/img') %&gt;%\n  html_attr(\"src\")\n\nprint(image_urls)\n\n#downloads first item\n#download.file(image_urls[1], \"image.png\", mode = \"wb\")\n\n# creates folder for images scraped then iterativly names each image (1-9 in this case).\n# More specifically it takes the image links gathered above, goes to each link, and downloads the image\n# dir.create makes a new folder. You only need to run this once.Everytime you do file.path to that folder it will add newly downloaded images to that folder\n# This method simply names each image 1 - number of images\ndir.create(\"images_grundy_sale\")\nfor (i in seq_along(image_urls)) {\n  file_path &lt;- file.path(\"images_grundy_sale\", paste0(\"image_\", i, \".png\"))\n  download.file(image_urls[i], file_path, mode = \"wb\")\n  print(file_path)\n}\n\n#creates folder for images scraped then names them based on address they were scraped with\n# same as above except for how the images are named. for each image the address grabbed earlier is printed as the name.\n# this returns (image_ 123 main st) for example\n# you can alter this to return our naming convention (source_city_address_) by replacing \"image_\" with the source and city\n# for example if you are pulling slater images from zillow it will be paste0(\"Z_S_\", address, \"_.png\") which will print the titles of images as Z_S_123 main st_.png\n# Z (Zillow) G (Google) V (Vanguard) B (Beacon) :: S (Slater) H (New Hampton) D (Independence) G (Grundy Center)\ndir.create(\"images_grundy_sale_addresses\")\nfor (j in seq_along(image_urls)) {\n  address &lt;- addresses[j]\n  file_name &lt;- paste0(\"image_\", address, \".png\")\n  file_path &lt;- file.path(\"images_grundy_sale_addresses\", file_name)\n  download.file(image_urls[j], file_path, mode = \"wb\")\n  print(file_path)\n}\n\nNext week, I will get around the anti-web scraping protections Beacon and Vanguard have on their sites. Beacon and Vanguard have information on houses that aren’t listed on Zillow, and more pictures aren’t listed on Zillow or Google Street View.\n\nNotes to self:\ngit pull\ngit add .\ngit commit -m “message”\ngit push"
  }
]